gin-gonic/website,455498869,76,,"[{'action': 'opened', 'author': 'thinkerou', 'comment_id': None, 'datetime': '2019-06-13 01:55:49+00:00', 'masked_author': 'username_0', 'text': 'So, we could remove it, or use other instead.', 'title': 'website have many ad when use Disqus.', 'type': 'issue'}
 {'action': 'created', 'author': 'VincentTam', 'comment_id': 505609559.0, 'datetime': '2019-06-25 20:28:04+00:00', 'masked_author': 'username_1', 'text': ""Hi, this is the maintainer of @staticmanlab, a public GitLab instance of [Staicman](https://staticman.net). Disqus has a plethora of shortcomings that deter many bloggers, say\r\n\r\n1. privacy issues\r\n2. slow load speed\r\n3. no markdown support\r\n4. poor SEO\r\n5. high cost of migration\r\n\r\nYou may avoid these problems by switching to static comments powered by Staticman, which makes use of GitHub/GitLab Pull/Merge Requests. Under Staticman's model, static comments are YML/JSON files stored in the remote GitHub/GitLab repo (usually under data/comments, configurable through the path parameter in root-level staticman.yml), and through a static blog generator (Jekyll/Hugo/etc), the stored data are rendered as part of the content. This gives a total ownership of a static site's comments.\r\n\r\nFor working examples of Staticman, you may see\r\n\r\n1. a popular Jekyll theme called [Beautiful Jekyll](https://github.com/daattali/beautiful-jekyll/), which has incorporated my port of [Minimal Mistake](https://github.com/mmistakes/minimal-mistakes/)'s Staticman integration.\r\n1. [zcrc.me](https://zcrc.me/) [Source](https://gitlab.com/pcercuei/pcercuei.gitlab.io): a personal Jekyll blog with Markdown support and preview.\r\n2. [my personal blog](https://lstu.fr/3s) [Source](https://gitlab.com/vincenttam/vincenttam.gitlab.io) powered by my tweaked Beautiful Hugo, with nested comments and comments preview.\r\n3. a group of my [Staticman demo sites on Framagit](https://framagit.org/staticman-gitlab-pages).\r\n\r\n:information_source: There're many ways to Rome, say JAMstack, Netlify comments, etc."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'thinkerou', 'comment_id': 505720128.0, 'datetime': '2019-06-26 05:07:36+00:00', 'masked_author': 'username_0', 'text': '@username_1 thanks, I will check it later on.', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: website have many ad when use Disqus.
username_0: So, we could remove it, or use other instead.
<issue_comment>username_1: Hi, this is the maintainer of @staticmanlab, a public GitLab instance of [Staicman](https://staticman.net). Disqus has a plethora of shortcomings that deter many bloggers, say

1. privacy issues
2. slow load speed
3. no markdown support
4. poor SEO
5. high cost of migration

You may avoid these problems by switching to static comments powered by Staticman, which makes use of GitHub/GitLab Pull/Merge Requests. Under Staticman's model, static comments are YML/JSON files stored in the remote GitHub/GitLab repo (usually under data/comments, configurable through the path parameter in root-level staticman.yml), and through a static blog generator (Jekyll/Hugo/etc), the stored data are rendered as part of the content. This gives a total ownership of a static site's comments.

For working examples of Staticman, you may see

1. a popular Jekyll theme called [Beautiful Jekyll](https://github.com/daattali/beautiful-jekyll/), which has incorporated my port of [Minimal Mistake](https://github.com/mmistakes/minimal-mistakes/)'s Staticman integration.
1. [zcrc.me](https://zcrc.me/) [Source](https://gitlab.com/pcercuei/pcercuei.gitlab.io): a personal Jekyll blog with Markdown support and preview.
2. [my personal blog](https://lstu.fr/3s) [Source](https://gitlab.com/vincenttam/vincenttam.gitlab.io) powered by my tweaked Beautiful Hugo, with nested comments and comments preview.
3. a group of my [Staticman demo sites on Framagit](https://framagit.org/staticman-gitlab-pages).

:information_source: There're many ways to Rome, say JAMstack, Netlify comments, etc.
<issue_comment>username_0: @username_1 thanks, I will check it later on."
KiCad/kicad-website,328784150,288,,"[{'action': 'opened', 'author': 'Ratfink', 'comment_id': None, 'datetime': '2018-06-02 23:02:20+00:00', 'masked_author': 'username_0', 'text': '[KLC]: http://kicad-pcb.org/libraries/klc/ ""KiCad Library Convention""\r\n[G1.1]: http://kicad-pcb.org/libraries/klc/G1.1/ ""Only standard characters are used for naming libraries and components""\r\n[G1.2]: http://kicad-pcb.org/libraries/klc/G1.2/ ""Each library is limited to 250 items""\r\n[G1.3]: http://kicad-pcb.org/libraries/klc/G1.3/ ""Libraries are organized by functionality""\r\n[G1.4]: http://kicad-pcb.org/libraries/klc/G1.4/ ""English language should be used throughout libraries""\r\n[G1.5]: http://kicad-pcb.org/libraries/klc/G1.5/ ""Plural naming is to be avoided""\r\n[G1.6]: http://kicad-pcb.org/libraries/klc/G1.6/ ""Capitalization conventions""\r\n[G1.7]: http://kicad-pcb.org/libraries/klc/G1.7/ ""Library files use Unix style line endings""\r\n[G1.8]: http://kicad-pcb.org/libraries/klc/G1.8/ ""Components can only contain features supported in latest stable release""\r\n[G1.9]: http://kicad-pcb.org/libraries/klc/G1.9/ ""Dimensional units""\r\n[G2.1]: http://kicad-pcb.org/libraries/klc/G2.1/ ""Defining generic and atomic parts""\r\n[S1.1]: http://kicad-pcb.org/libraries/klc/S1.1/ ""Symbol libraries should be categorized by function""\r\n[S2.1]: http://kicad-pcb.org/libraries/klc/S2.1/ ""General symbol naming guidelines""\r\n[S2.2]: http://kicad-pcb.org/libraries/klc/S2.2/ ""Non-functional variations in part number should be replaced with wildcard""\r\n[S2.3]: http://kicad-pcb.org/libraries/klc/S2.3/ ""Where atomic parts are available in multiple footprint options, a separate symbol must be drawn for each footprint""\r\n[S3.1]: http://kicad-pcb.org/libraries/klc/S3.1/ ""Origin is centered on the middle of the symbol""\r\n[S3.2]: http://kicad-pcb.org/libraries/klc/S3.2/ ""Text fields should use a common text size of 50mils""\r\n[S3.3]: http://kicad-pcb.org/libraries/klc/S3.3/ ""Symbol outline and fill requirements""\r\n[S3.4]: http://kicad-pcb.org/libraries/klc/S3.4/ ""Symbols with complex functionality may incorporate simple functional diagrams""\r\n[S3.5]: http://kicad-pcb.org/libraries/klc/S3.5/ ""Pin connection points must be placed outside of the symbol""\r\n[S3.6]: http://kicad-pcb.org/libraries/klc/S3.6/ ""Pin name position offset""\r\n[S3.7]: http://kicad-pcb.org/libraries/klc/S3.7/ ""Pin numbering for exposed pads""\r\n[S3.8]: http://kicad-pcb.org/libraries/klc/S3.8/ ""Multi unit symbols""\r\n[S4.1]: http://kicad-pcb.org/libraries/klc/S4.1/ ""General pin requirements""\r\n[S4.2]: http://kicad-pcb.org/libraries/klc/S4.2/ ""Pins should be grouped by function""\r\n[S4.3]: http://kicad-pcb.org/libraries/klc/S4.3/ ""Rules for pin stacking""\r\n[S4.4]: http://kicad-pcb.org/libraries/klc/S4.4/ ""Pin electrical type""\r\n[S4.5]: http://kicad-pcb.org/libraries/klc/S4.5/ ""Pins not connected on the footprint may be omitted from the symbol""\r\n[S4.6]: http://kicad-pcb.org/libraries/klc/S4.6/ ""Hidden pins""\r\n[S4.7]: http://kicad-pcb.org/libraries/klc/S4.7/ ""Active low pins should be designated using a bar above the symbol name""\r\n[S5.1]: http://kicad-pcb.org/libraries/klc/S5.1/ ""Symbols with a default footprint link to a valid footprint file""\r\n[S5.2]: http://kicad-pcb.org/libraries/klc/S5.2/ ""Footprint filters should match all appropriate footprints""\r\n[S6.1]: http://kicad-pcb.org/libraries/klc/S6.1/ ""Component Reference Designator (RefDes)""\r\n[S6.2]: http://kicad-pcb.org/libraries/klc/S6.2/ ""Component fields must be filled appropriately""\r\n[S6.3]: http://kicad-pcb.org/libraries/klc/S6.3/ ""Component metadata is added to symbol (and all aliases)""\r\n[S7.1]: http://kicad-pcb.org/libraries/klc/S7.1/ ""Power flag symbols""\r\n[S7.2]: http://kicad-pcb.org/libraries/klc/S7.2/ ""Graphical symbols""\r\n[F1.1]: http://kicad-pcb.org/libraries/klc/F1.1/ ""Footprint libraries are categorized by function""\r\n[F1.2]: http://kicad-pcb.org/libraries/klc/F1.2/ ""Connector footprint libraries""\r\n[F2.1]: http://kicad-pcb.org/libraries/klc/F2.1/ ""General footprint naming conventions""\r\n[F2.2]: http://kicad-pcb.org/libraries/klc/F2.2/ ""Footprint naming field prefixes""\r\n[F2.3]: http://kicad-pcb.org/libraries/klc/F2.3/ ""Manufacturer specific version of generic footprints""\r\n[F2.4]: http://kicad-pcb.org/libraries/klc/F2.4/ ""Footprint naming for non-standard pin numbering""\r\n[F2.5]: http://kicad-pcb.org/libraries/klc/F2.5/ ""Footprint naming conventions for specific components""\r\n[F3.1]: http://kicad-pcb.org/libraries/klc/F3.1/ ""SMD chip package naming conventions""\r\n[F3.2]: http://kicad-pcb.org/libraries/klc/F3.2/ ""Resistor naming conventions""\r\n[F3.3]: http://kicad-pcb.org/libraries/klc/F3.3/ ""Capacitor naming conventions""\r\n[F3.4]: http://kicad-pcb.org/libraries/klc/F3.4/ ""SMD IC package naming conventions""\r\n[F3.5]: http://kicad-pcb.org/libraries/klc/F3.5/ ""THT IC package naming conventions""\r\n[F3.6]: http://kicad-pcb.org/libraries/klc/F3.6/ ""Connector naming conventions""\r\n[F3.7]: http://kicad-pcb.org/libraries/klc/F3.7/ ""Fuse naming conventions""\r\n[F4.1]: http://kicad-pcb.org/libraries/klc/F4.1/ ""Datasheet recommendations take priority""\r\n[F4.2]: http://kicad-pcb.org/libraries/klc/F4.2/ ""Pin 1 should be located at the top left""\r\n[F4.3]: http://kicad-pcb.org/libraries/klc/F4.3/ ""Connected copper elements have the same pad number""\r\n[F4.4]: http://kicad-pcb.org/libraries/klc/F4.4/ ""Thermal pads""\r\n[F4.5]: http://kicad-pcb.org/libraries/klc/F4.5/ ""Specifying footprint keepout areas""\r\n[F4.6]: http://kicad-pcb.org/libraries/klc/F4.6/ ""Local clearance and settings should be set to zero""\r\n[F5.1]: http://kicad-pcb.org/libraries/klc/F5.1/ ""Silkscreen layer requirements""\r\n[F5.2]: http://kicad-pcb.org/libraries/klc/F5.2/ ""Fabrication layer requirements""\r\n[F5.3]: http://kicad-pcb.org/libraries/klc/F5.3/ ""Courtyard layer requirements""\r\n[F6.1]: http://kicad-pcb.org/libraries/klc/F6.1/ ""Footprint placement type must be set to surface mount""\r\n[F6.2]: http://kicad-pcb.org/libraries/klc/F6.2/ ""Footprint anchor should be placed in the middle of the component body""\r\n[F6.3]: http://kicad-pcb.org/libraries/klc/F6.3/ ""Pad requirements for SMD footprints""\r\n[F7.1]: http://kicad-pcb.org/libraries/klc/F7.1/ ""Footprint placement type must be set to Through Hole""\r\n[F7.2]: http://kicad-pcb.org/libraries/klc/F7.2/ ""Footprint anchor should placed at the location of Pin-1""\r\n[F7.3]: http://kicad-pcb.org/libraries/klc/F7.3/ ""Pin 1 should be rectangular, and other pads circular or oval""\r\n[F7.4]: http://kicad-pcb.org/libraries/klc/F7.4/ ""Pad requirements for THT footprints""\r\n[F7.5]: http://kicad-pcb.org/libraries/klc/F7.5/ ""Minimum annular ring width""\r\n[F7.6]: http://kicad-pcb.org/libraries/klc/F7.6/ ""Minimum hole diameter""\r\n[F8.1]: http://kicad-pcb.org/libraries/klc/F8.1/ ""Virtual components""\r\n[F9.1]: http://kicad-pcb.org/libraries/klc/F9.1/ ""Footprint meta-data is filled in as appropriate""\r\n[F9.2]: http://kicad-pcb.org/libraries/klc/F9.2/ ""Footprint properties are as default values unless otherwise required in datasheet""\r\n[F9.3]: http://kicad-pcb.org/libraries/klc/F9.3/ ""Footprint 3D model requirements""\r\n[M1.1]: http://kicad-pcb.org/libraries/klc/M1.1/ ""Models should be created by contributor""\r\n[M1.2]: http://kicad-pcb.org/libraries/klc/M1.2/ ""Manufacturer models should not be duplicated""\r\n[M1.3]: http://kicad-pcb.org/libraries/klc/M1.3/ ""Source files for 3D models should be supplied""\r\n[M2.1]: http://kicad-pcb.org/libraries/klc/M2.1/ ""Permitted 3D model file types""\r\n[M2.2]: http://kicad-pcb.org/libraries/klc/M2.2/ ""Model alignment and scaling""\r\n\r\nAs noted in https://github.com/KiCad/kicad-footprints/pull/621#issuecomment-394118979, it currently isn\'t obvious to someone scanning KLC that a footprint needs a 3D model link regardless of whether it has a 3D model yet or not.  This requirement is written in rule [F9.3], but only at the very bottom.  I think it would make sense to move this point to the very top of the list, perhaps re-wording it to something like this:\r\n\r\n1. All non-virtual footprints must have 3D model references, even if the 3D model is missing (does not yet exist).  This allows the 3D model to be added later without requiring the footprint to be edited again.\r\n\r\nCompared to the old wording:\r\n\r\n7. If the 3D model is missing (does not yet exist), the 3D model reference should still be added. This means that the footprint does not have to be edited again once the 3D model is added.', 'title': 'KLC: Re-order items of rule F9.3', 'type': 'issue'}
 {'action': 'closed', 'author': 'marekr', 'comment_id': None, 'datetime': '2018-12-22 00:09:40+00:00', 'masked_author': 'username_1', 'text': '', 'title': None, 'type': 'issue'}]","<issue_start><issue_comment>Title: KLC: Re-order items of rule F9.3
username_0: [KLC]: http://kicad-pcb.org/libraries/klc/ ""KiCad Library Convention""
[G1.1]: http://kicad-pcb.org/libraries/klc/G1.1/ ""Only standard characters are used for naming libraries and components""
[G1.2]: http://kicad-pcb.org/libraries/klc/G1.2/ ""Each library is limited to 250 items""
[G1.3]: http://kicad-pcb.org/libraries/klc/G1.3/ ""Libraries are organized by functionality""
[G1.4]: http://kicad-pcb.org/libraries/klc/G1.4/ ""English language should be used throughout libraries""
[G1.5]: http://kicad-pcb.org/libraries/klc/G1.5/ ""Plural naming is to be avoided""
[G1.6]: http://kicad-pcb.org/libraries/klc/G1.6/ ""Capitalization conventions""
[G1.7]: http://kicad-pcb.org/libraries/klc/G1.7/ ""Library files use Unix style line endings""
[G1.8]: http://kicad-pcb.org/libraries/klc/G1.8/ ""Components can only contain features supported in latest stable release""
[G1.9]: http://kicad-pcb.org/libraries/klc/G1.9/ ""Dimensional units""
[G2.1]: http://kicad-pcb.org/libraries/klc/G2.1/ ""Defining generic and atomic parts""
[S1.1]: http://kicad-pcb.org/libraries/klc/S1.1/ ""Symbol libraries should be categorized by function""
[S2.1]: http://kicad-pcb.org/libraries/klc/S2.1/ ""General symbol naming guidelines""
[S2.2]: http://kicad-pcb.org/libraries/klc/S2.2/ ""Non-functional variations in part number should be replaced with wildcard""
[S2.3]: http://kicad-pcb.org/libraries/klc/S2.3/ ""Where atomic parts are available in multiple footprint options, a separate symbol must be drawn for each footprint""
[S3.1]: http://kicad-pcb.org/libraries/klc/S3.1/ ""Origin is centered on the middle of the symbol""
[S3.2]: http://kicad-pcb.org/libraries/klc/S3.2/ ""Text fields should use a common text size of 50mils""
[S3.3]: http://kicad-pcb.org/libraries/klc/S3.3/ ""Symbol outline and fill requirements""
[S3.4]: http://kicad-pcb.org/libraries/klc/S3.4/ ""Symbols with complex functionality may incorporate simple functional diagrams""
[S3.5]: http://kicad-pcb.org/libraries/klc/S3.5/ ""Pin connection points must be placed outside of the symbol""
[S3.6]: http://kicad-pcb.org/libraries/klc/S3.6/ ""Pin name position offset""
[S3.7]: http://kicad-pcb.org/libraries/klc/S3.7/ ""Pin numbering for exposed pads""
[S3.8]: http://kicad-pcb.org/libraries/klc/S3.8/ ""Multi unit symbols""
[S4.1]: http://kicad-pcb.org/libraries/klc/S4.1/ ""General pin requirements""
[S4.2]: http://kicad-pcb.org/libraries/klc/S4.2/ ""Pins should be grouped by function""
[S4.3]: http://kicad-pcb.org/libraries/klc/S4.3/ ""Rules for pin stacking""
[S4.4]: http://kicad-pcb.org/libraries/klc/S4.4/ ""Pin electrical type""
[S4.5]: http://kicad-pcb.org/libraries/klc/S4.5/ ""Pins not connected on the footprint may be omitted from the symbol""
[S4.6]: http://kicad-pcb.org/libraries/klc/S4.6/ ""Hidden pins""
[S4.7]: http://kicad-pcb.org/libraries/klc/S4.7/ ""Active low pins should be designated using a bar above the symbol name""
[S5.1]: http://kicad-pcb.org/libraries/klc/S5.1/ ""Symbols with a default footprint link to a valid footprint file""
[S5.2]: http://kicad-pcb.org/libraries/klc/S5.2/ ""Footprint filters should match all appropriate footprints""
[S6.1]: http://kicad-pcb.org/libraries/klc/S6.1/ ""Component Reference Designator (RefDes)""
[S6.2]: http://kicad-pcb.org/libraries/klc/S6.2/ ""Component fields must be filled appropriately""
[S6.3]: http://kicad-pcb.org/libraries/klc/S6.3/ ""Component metadata is added to symbol (and all aliases)""
[S7.1]: http://kicad-pcb.org/libraries/klc/S7.1/ ""Power flag symbols""
[S7.2]: http://kicad-pcb.org/libraries/klc/S7.2/ ""Graphical symbols""
[F1.1]: http://kicad-pcb.org/libraries/klc/F1.1/ ""Footprint libraries are categorized by function""
[F1.2]: http://kicad-pcb.org/libraries/klc/F1.2/ ""Connector footprint libraries""
[F2.1]: http://kicad-pcb.org/libraries/klc/F2.1/ ""General footprint naming conventions""
[F2.2]: http://kicad-pcb.org/libraries/klc/F2.2/ ""Footprint naming field prefixes""
[F2.3]: http://kicad-pcb.org/libraries/klc/F2.3/ ""Manufacturer specific version of generic footprints""
[F2.4]: http://kicad-pcb.org/libraries/klc/F2.4/ ""Footprint naming for non-standard pin numbering""
[F2.5]: http://kicad-pcb.org/libraries/klc/F2.5/ ""Footprint naming conventions for specific components""
[F3.1]: http://kicad-pcb.org/libraries/klc/F3.1/ ""SMD chip package naming conventions""
[F3.2]: http://kicad-pcb.org/libraries/klc/F3.2/ ""Resistor naming conventions""
[F3.3]: http://kicad-pcb.org/libraries/klc/F3.3/ ""Capacitor naming conventions""
[F3.4]: http://kicad-pcb.org/libraries/klc/F3.4/ ""SMD IC package naming conventions""
[F3.5]: http://kicad-pcb.org/libraries/klc/F3.5/ ""THT IC package naming conventions""
[F3.6]: http://kicad-pcb.org/libraries/klc/F3.6/ ""Connector naming conventions""
[F3.7]: http://kicad-pcb.org/libraries/klc/F3.7/ ""Fuse naming conventions""
[F4.1]: http://kicad-pcb.org/libraries/klc/F4.1/ ""Datasheet recommendations take priority""
[F4.2]: http://kicad-pcb.org/libraries/klc/F4.2/ ""Pin 1 should be located at the top left""
[F4.3]: http://kicad-pcb.org/libraries/klc/F4.3/ ""Connected copper elements have the same pad number""
[F4.4]: http://kicad-pcb.org/libraries/klc/F4.4/ ""Thermal pads""
[F4.5]: http://kicad-pcb.org/libraries/klc/F4.5/ ""Specifying footprint keepout areas""
[F4.6]: http://kicad-pcb.org/libraries/klc/F4.6/ ""Local clearance and settings should be set to zero""
[F5.1]: http://kicad-pcb.org/libraries/klc/F5.1/ ""Silkscreen layer requirements""
[F5.2]: http://kicad-pcb.org/libraries/klc/F5.2/ ""Fabrication layer requirements""
[F5.3]: http://kicad-pcb.org/libraries/klc/F5.3/ ""Courtyard layer requirements""
[F6.1]: http://kicad-pcb.org/libraries/klc/F6.1/ ""Footprint placement type must be set to surface mount""
[F6.2]: http://kicad-pcb.org/libraries/klc/F6.2/ ""Footprint anchor should be placed in the middle of the component body""
[F6.3]: http://kicad-pcb.org/libraries/klc/F6.3/ ""Pad requirements for SMD footprints""
[F7.1]: http://kicad-pcb.org/libraries/klc/F7.1/ ""Footprint placement type must be set to Through Hole""
[F7.2]: http://kicad-pcb.org/libraries/klc/F7.2/ ""Footprint anchor should placed at the location of Pin-1""
[F7.3]: http://kicad-pcb.org/libraries/klc/F7.3/ ""Pin 1 should be rectangular, and other pads circular or oval""
[F7.4]: http://kicad-pcb.org/libraries/klc/F7.4/ ""Pad requirements for THT footprints""
[F7.5]: http://kicad-pcb.org/libraries/klc/F7.5/ ""Minimum annular ring width""
[F7.6]: http://kicad-pcb.org/libraries/klc/F7.6/ ""Minimum hole diameter""
[F8.1]: http://kicad-pcb.org/libraries/klc/F8.1/ ""Virtual components""
[F9.1]: http://kicad-pcb.org/libraries/klc/F9.1/ ""Footprint meta-data is filled in as appropriate""
[F9.2]: http://kicad-pcb.org/libraries/klc/F9.2/ ""Footprint properties are as default values unless otherwise required in datasheet""
[F9.3]: http://kicad-pcb.org/libraries/klc/F9.3/ ""Footprint 3D model requirements""
[M1.1]: http://kicad-pcb.org/libraries/klc/M1.1/ ""Models should be created by contributor""
[M1.2]: http://kicad-pcb.org/libraries/klc/M1.2/ ""Manufacturer models should not be duplicated""
[M1.3]: http://kicad-pcb.org/libraries/klc/M1.3/ ""Source files for 3D models should be supplied""
[M2.1]: http://kicad-pcb.org/libraries/klc/M2.1/ ""Permitted 3D model file types""
[M2.2]: http://kicad-pcb.org/libraries/klc/M2.2/ ""Model alignment and scaling""

As noted in https://github.com/KiCad/kicad-footprints/pull/621#issuecomment-394118979, it currently isn't obvious to someone scanning KLC that a footprint needs a 3D model link regardless of whether it has a 3D model yet or not.  This requirement is written in rule [F9.3], but only at the very bottom.  I think it would make sense to move this point to the very top of the list, perhaps re-wording it to something like this:

1. All non-virtual footprints must have 3D model references, even if the 3D model is missing (does not yet exist).  This allows the 3D model to be added later without requiring the footprint to be edited again.

Compared to the old wording:

7. If the 3D model is missing (does not yet exist), the 3D model reference should still be added. This means that the footprint does not have to be edited again once the 3D model is added.<issue_closed>"
gohugoio/hugo,65713270,1026,"{'number': 1026.0, 'repo': 'hugo', 'user_login': 'gohugoio'}","[{'action': 'opened', 'author': 'mdhender', 'comment_id': None, 'datetime': '2015-04-01T15:35:56Z', 'masked_author': 'username_0', 'text': 'Template developers frequently need to show variable values while \ndebugging templates. Issue #1009 requests better support for this.\n\nThe `printf ""%#v""` idiom is powerful but requires some knowledge\nof Hugo\'s internal representation of Go value types. Not all\ntemplate designers will have that knowledge. The two functions\n`inspect` and `typeOf` provide a path towards easier to use and\nunderstand printing of variables and values.\n\nThe `inspect` function replaces the `printf` call. This version\nrelies on the default `string` conversion for the result. This\nprovides a path towards pretty-printing variables and values.\n\nTemplates may use `typeOf` to determine the best formatting\nfor variables and values.', 'title': 'Add template debugging functions', 'type': 'issue'}]","<issue_start><issue_comment>Title: Add template debugging functions
username_0: Template developers frequently need to show variable values while 
debugging templates. Issue #1009 requests better support for this.

The `printf ""%#v""` idiom is powerful but requires some knowledge
of Hugo's internal representation of Go value types. Not all
template designers will have that knowledge. The two functions
`inspect` and `typeOf` provide a path towards easier to use and
understand printing of variables and values.

The `inspect` function replaces the `printf` call. This version
relies on the default `string` conversion for the result. This
provides a path towards pretty-printing variables and values.

Templates may use `typeOf` to determine the best formatting
for variables and values."
newrelic/docs-website,948630058,3180,"{'number': 3180.0, 'repo': 'docs-website', 'user_login': 'newrelic'}","[{'action': 'opened', 'author': 'paologallinaharbur', 'comment_id': None, 'datetime': '2021-07-20T13:00:44Z', 'masked_author': 'username_0', 'text': 'For sure we will add some screenshots as soon as the dashboard are published', 'title': 'feat(powerDNS): add initial docs', 'type': 'issue'}
 {'action': 'created', 'author': 'paologallinaharbur', 'comment_id': 883444005.0, 'datetime': '2021-07-20 14:34:06+00:00', 'masked_author': 'username_0', 'text': 'This should not be merged till the integration is released. Moreover we will need a beta watermark (I forgot about that)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'urbiz-nr', 'comment_id': 921556868.0, 'datetime': '2021-09-17 07:13:57+00:00', 'masked_author': 'username_1', 'text': 'Update - the team is working again on this, and it should be ready in 2-3 weeks.', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: feat(powerDNS): add initial docs
username_0: For sure we will add some screenshots as soon as the dashboard are published
<issue_comment>username_0: This should not be merged till the integration is released. Moreover we will need a beta watermark (I forgot about that)
<issue_comment>username_1: Update - the team is working again on this, and it should be ready in 2-3 weeks."
facebook/docusaurus,942940653,5156,"{'number': 5156.0, 'repo': 'docusaurus', 'user_login': 'facebook'}","[{'action': 'opened', 'author': 'pranabdas', 'comment_id': None, 'datetime': '2021-07-13T08:01:08Z', 'masked_author': 'username_0', 'text': '## Motivation\r\n\r\n- With current code line highlight colours for the classic theme, it is sometimes hard to infer which is highlighted line and which is not especially when there are several consecutive highlighted and non-highlighted lines are present. \r\n- For the classic dark theme, the code line highlight colour is very close to the page background colour. Hence, it might appear the highlighted line dividing the code block vertically.\r\n\r\n### Have you read the [Contributing Guidelines on pull requests](https://github.com/facebook/docusaurus/blob/master/CONTRIBUTING.md#pull-requests)?\r\n\r\nYes\r\n\r\n## Test Plan\r\n\r\n![code-highlight](https://user-images.githubusercontent.com/31024886/125412464-88ff7a80-e3f1-11eb-9513-c494ce4cea4a.png)', 'title': 'polish(v2): more suitable code block line highlight color', 'type': 'issue'}
 {'action': 'created', 'author': 'slorber', 'comment_id': 878888968.0, 'datetime': '2021-07-13 08:31:31+00:00', 'masked_author': 'username_1', 'text': ""Thanks\r\n\r\nAgree we should do something about this problem. Not liking so much your dark mode color though.\r\n\r\nI have bad UI tastes so I'd rather have feedback from multiple persons before merging this 🤪"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'pranabdas', 'comment_id': 878917750.0, 'datetime': '2021-07-13 09:11:56+00:00', 'masked_author': 'username_0', 'text': 'Sure 👌\r\n\r\n**Option 2** for dark theme: rgb(68, 73, 80)\r\n\r\n<img width=""1280"" alt=""line-highlight-color-dark"" src=""https://user-images.githubusercontent.com/31024886/125424467-da905dc3-8317-4428-9dc1-771ae5aab378.png"">', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Josh-Cena', 'comment_id': 878918042.0, 'datetime': '2021-07-13 09:12:16+00:00', 'masked_author': 'username_2', 'text': ""This palette doesn't quite fit with the Docusaurus style, but I don't object it :D\r\n\r\nShould we use transparent colors instead so the contrast may look less sharp? (e.g. `rgba(66, 80, 80, 0.7)`)\r\n\r\n(Also, I think a more urgent UI fix is the admonitions. They just look _broken_ compared to other documentation sites🙃)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Josh-Cena', 'comment_id': 880346962.0, 'datetime': '2021-07-15 02:47:16+00:00', 'masked_author': 'username_2', 'text': 'Also if the website is updated, the init template should be synced as well to keep identical behaviors.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'slorber', 'comment_id': 885490168.0, 'datetime': '2021-07-23 08:40:07+00:00', 'masked_author': 'username_1', 'text': ""Useful links to compare before/after:\r\n- https://deploy-preview-5156--docusaurus-2.netlify.app/docs/markdown-features/code-blocks/\r\n- https://docusaurus.io/docs/markdown-features/code-blocks\r\n\r\nI agree that this will make highlighted lines more visible (particularly for the dark mode) but must say I'm not too fan of the result. It does not look pretty to me. I don't have good tastes so we only merge this if the community agrees that this PR is an improvement and not a regression :)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'slorber', 'comment_id': 889770735.0, 'datetime': '2021-07-30 09:37:29+00:00', 'masked_author': 'username_1', 'text': 'Personally, I like the way code blocks are displayed on this blog\r\n\r\nhttps://blog.maximeheckel.com/posts/the-power-of-composition-with-css-variables/\r\n\r\n![image](https://user-images.githubusercontent.com/749374/127633779-7d7e1846-54ee-4b40-84d2-c07ba241bba5.png)\r\n\r\n\r\nDisplay line numbers + use primary color variant for border and background color with alpha.\r\n\r\nMaybe such thing could be done in core instead of the init template?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'lex111', 'comment_id': 903333733.0, 'datetime': '2021-08-22 21:36:00+00:00', 'masked_author': 'username_3', 'text': 'Unfortunately in my opinion,  this change only worsens default highlighting of code lines, so it is better to leave the current version.', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: polish(v2): more suitable code block line highlight color
username_0: ## Motivation

- With current code line highlight colours for the classic theme, it is sometimes hard to infer which is highlighted line and which is not especially when there are several consecutive highlighted and non-highlighted lines are present. 
- For the classic dark theme, the code line highlight colour is very close to the page background colour. Hence, it might appear the highlighted line dividing the code block vertically.

### Have you read the [Contributing Guidelines on pull requests](https://github.com/facebook/docusaurus/blob/master/CONTRIBUTING.md#pull-requests)?

Yes

## Test Plan

![code-highlight](https://user-images.githubusercontent.com/31024886/125412464-88ff7a80-e3f1-11eb-9513-c494ce4cea4a.png)
<issue_comment>username_1: Thanks

Agree we should do something about this problem. Not liking so much your dark mode color though.

I have bad UI tastes so I'd rather have feedback from multiple persons before merging this 🤪
<issue_comment>username_0: Sure 👌

**Option 2** for dark theme: rgb(68, 73, 80)

<img width=""1280"" alt=""line-highlight-color-dark"" src=""https://user-images.githubusercontent.com/31024886/125424467-da905dc3-8317-4428-9dc1-771ae5aab378.png"">
<issue_comment>username_2: This palette doesn't quite fit with the Docusaurus style, but I don't object it :D

Should we use transparent colors instead so the contrast may look less sharp? (e.g. `rgba(66, 80, 80, 0.7)`)

(Also, I think a more urgent UI fix is the admonitions. They just look _broken_ compared to other documentation sites🙃)
<issue_comment>username_2: Also if the website is updated, the init template should be synced as well to keep identical behaviors.
<issue_comment>username_1: Useful links to compare before/after:
- https://deploy-preview-5156--docusaurus-2.netlify.app/docs/markdown-features/code-blocks/
- https://docusaurus.io/docs/markdown-features/code-blocks

I agree that this will make highlighted lines more visible (particularly for the dark mode) but must say I'm not too fan of the result. It does not look pretty to me. I don't have good tastes so we only merge this if the community agrees that this PR is an improvement and not a regression :)
<issue_comment>username_1: Personally, I like the way code blocks are displayed on this blog

https://blog.maximeheckel.com/posts/the-power-of-composition-with-css-variables/

![image](https://user-images.githubusercontent.com/749374/127633779-7d7e1846-54ee-4b40-84d2-c07ba241bba5.png)


Display line numbers + use primary color variant for border and background color with alpha.

Maybe such thing could be done in core instead of the init template?
<issue_comment>username_3: Unfortunately in my opinion,  this change only worsens default highlighting of code lines, so it is better to leave the current version."
conda-forge/conda-forge.github.io,389797510,683,,"[{'action': 'opened', 'author': 'jdblischak', 'comment_id': None, 'datetime': '2018-12-11 14:44:47+00:00', 'masked_author': 'username_0', 'text': ""Why are noarch recipes submitted to staged-recipes built on Travis and AppVeyor? I couldn't find this discussed anywhere, so I wasn't sure if this was deliberate or if it is a problem of finding the time to update the build scripts.\r\n\r\nNot only do these builds unnecessarily use CI time, but they can also fail. Currently any noarch R recipe submitted to conda-forge fails on AppVeyor. This is because we remove a Windows-specific selector to pass the linter checks.\r\n\r\nThis is happening to all recent noarch R recipes, but here is the PR where I discovered this: https://github.com/conda-forge/staged-recipes/pull/7128"", 'title': 'noarch recipes are built on all 3 platforms in Pull Requests to staged-recipes', 'type': 'issue'}
 {'action': 'created', 'author': 'CJ-Wright', 'comment_id': 446271802.0, 'datetime': '2018-12-11 16:41:16+00:00', 'masked_author': 'username_1', 'text': ""I don't know if we currently have a good mechanism to stop noarch recipes from being built on all the platforms. Maybe we could have a fast fail clause in the CI for noarch recipes, though."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jdblischak', 'comment_id': 446302229.0, 'datetime': '2018-12-11 18:07:20+00:00', 'masked_author': 'username_0', 'text': 'How about checking for the presence of `noarch` in `meta.yaml` and removing the recipe directory if it does? Similar to how recipes that are already merged into master are removed:\r\n\r\nhttps://github.com/conda-forge/staged-recipes/blob/fbea79267840338092e2eb2e94bf28ead67328c4/.appveyor.yml#L25', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'CJ-Wright', 'comment_id': 446304118.0, 'datetime': '2018-12-11 18:13:10+00:00', 'masked_author': 'username_1', 'text': 'Any interest in putting in a PR to that effect?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jdblischak', 'comment_id': 446304669.0, 'datetime': '2018-12-11 18:14:47+00:00', 'masked_author': 'username_0', 'text': 'Of course. Wanted to make sure it was a reasonable option before I attempted it.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jdblischak', 'comment_id': 446374813.0, 'datetime': '2018-12-11 21:47:58+00:00', 'masked_author': 'username_0', 'text': ""@isuruf I'd also be fine with that solution. If someone updates the linter, I'll update the R helper script to add back `{{posix}}zip` to the noarch R recipes."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jdblischak', 'comment_id': 446631376.0, 'datetime': '2018-12-12 15:37:46+00:00', 'masked_author': 'username_0', 'text': '@isuruf Would you like me to work on the linter update? Both new recipes and PRs to existing R feedstocks are removing `{{posix}}zip` from the recipe because of the linter.\r\n\r\nMy plan would be to edit the linter [here](https://github.com/conda-forge/conda-smithy/blob/master/conda_smithy/lint_recipe.py#L270). Should I remove the entire thing or try to make an exception for R recipes?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'CJ-Wright', 'comment_id': 446632499.0, 'datetime': '2018-12-12 15:40:46+00:00', 'masked_author': 'username_1', 'text': 'Do we need to be specific that selectors can exist on runtime deps? (Can they exist on runtime deps?)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jdblischak', 'comment_id': 447030482.0, 'datetime': '2018-12-13 16:23:51+00:00', 'masked_author': 'username_0', 'text': ""I'm going to give it a try. Runtime deps definitely shouldn't have selectors. Build/host deps are more complicated since they can [export runtime deps](https://conda.io/docs/user-guide/tasks/build-packages/define-metadata.html?highlight=host#export-runtime-requirements). I assume that `{{posix}}zip` doesn't export any runtime requirements (no idea how I would check that though), so this should be safe for the R recipes. Unclear how other potentially more complicated recipes will behave, but presumably any noarch recipe shouldn't be that complicated in the first place."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'CJ-Wright', 'comment_id': 447062902.0, 'datetime': '2018-12-13 18:00:31+00:00', 'masked_author': 'username_1', 'text': '@isuruf I\'m confused by ""check that other platforms worked with the same recipe"". What do you mean exactly? I don\'t know if this is a valid check for noarch packages. Some noarch packages have arched deps (some of which don\'t exist for that arch) so I don\'t know if the package will build on other archs.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 447583433.0, 'datetime': '2018-12-15 17:15:59+00:00', 'masked_author': 'username_2', 'text': 'Admittedly I’m not terribly worried about the decision made here. However historically we have only required that the `noarch` packages build on Linux as this is how we handle them in the feedstocks.\n\nAs to how one builds the packages on their platform, there are two strands of thought to consider. First we’ve generally not put too much effort into supporting users, who want to build the package outside of conda-forge, which this seems to fall under. Second `noarch` packages can be built using the same Docker image and build scripts locally to build on any platform. So this doesn’t really seem like an issue IMHO and am a little worried we are (slightly) diverting people’s efforts without a clear reason.\n\nWith `staged-recipes` CI checks, nothing intentional has been done here. This is really just the typical story of a task that has not moved to high priority and is probably not too difficult. We have dealt with this historically by either ignoring the CIs that are irrelevant or adding `[ci skip]` to commit messages, which only CircleCI ignores (though this disables the linter). Agree with others that better solutions are welcome here.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jdblischak', 'comment_id': 448684301.0, 'datetime': '2018-12-19 17:46:55+00:00', 'masked_author': 'username_0', 'text': 'Does anyone have any suggestions?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'CJ-Wright', 'comment_id': 451191451.0, 'datetime': '2019-01-03 16:11:38+00:00', 'masked_author': 'username_1', 'text': 'As a counter point to https://github.com/conda-forge/conda-forge.github.io/issues/683#issuecomment-446368514 I think that checking the build on all platforms only on staged-recipes might send the wrong message. Changes to the feedstock might prevent the package from working on noarch, which is not something we check. If we want to check that noarch packages work on all platforms we should do this on feedstocks and staged-recipes to maintain parity.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jdblischak', 'comment_id': 451192674.0, 'datetime': '2019-01-03 16:15:40+00:00', 'masked_author': 'username_0', 'text': '**Resolution for R noarch recipes:** The linter will ignore selectors in build requirements once a new version of conda-smithy is released (https://github.com/conda-forge/conda-smithy/pull/966). This will allow R noarch recipes to build successfully on Windows, thus easing the staged-recipes review process. The corresponding update to the R recipe helper is also in process (https://github.com/bgruening/conda_r_skeleton_helper/pull/37).\r\n\r\n**Still unresolved**: Should noarch recipes be built for staged-recipes PRs? I had started a PR to do this (https://github.com/conda-forge/staged-recipes/pull/7239), but it would first require 1) consensus to make this change, and 2) someone knowledgeable of PowerShell to fix my initial prototype.', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: noarch recipes are built on all 3 platforms in Pull Requests to staged-recipes
username_0: Why are noarch recipes submitted to staged-recipes built on Travis and AppVeyor? I couldn't find this discussed anywhere, so I wasn't sure if this was deliberate or if it is a problem of finding the time to update the build scripts.

Not only do these builds unnecessarily use CI time, but they can also fail. Currently any noarch R recipe submitted to conda-forge fails on AppVeyor. This is because we remove a Windows-specific selector to pass the linter checks.

This is happening to all recent noarch R recipes, but here is the PR where I discovered this: https://github.com/conda-forge/staged-recipes/pull/7128
<issue_comment>username_1: I don't know if we currently have a good mechanism to stop noarch recipes from being built on all the platforms. Maybe we could have a fast fail clause in the CI for noarch recipes, though.
<issue_comment>username_0: How about checking for the presence of `noarch` in `meta.yaml` and removing the recipe directory if it does? Similar to how recipes that are already merged into master are removed:

https://github.com/conda-forge/staged-recipes/blob/fbea79267840338092e2eb2e94bf28ead67328c4/.appveyor.yml#L25
<issue_comment>username_1: Any interest in putting in a PR to that effect?
<issue_comment>username_0: Of course. Wanted to make sure it was a reasonable option before I attempted it.
<issue_comment>username_0: @isuruf I'd also be fine with that solution. If someone updates the linter, I'll update the R helper script to add back `{{posix}}zip` to the noarch R recipes.
<issue_comment>username_0: @isuruf Would you like me to work on the linter update? Both new recipes and PRs to existing R feedstocks are removing `{{posix}}zip` from the recipe because of the linter.

My plan would be to edit the linter [here](https://github.com/conda-forge/conda-smithy/blob/master/conda_smithy/lint_recipe.py#L270). Should I remove the entire thing or try to make an exception for R recipes?
<issue_comment>username_1: Do we need to be specific that selectors can exist on runtime deps? (Can they exist on runtime deps?)
<issue_comment>username_0: I'm going to give it a try. Runtime deps definitely shouldn't have selectors. Build/host deps are more complicated since they can [export runtime deps](https://conda.io/docs/user-guide/tasks/build-packages/define-metadata.html?highlight=host#export-runtime-requirements). I assume that `{{posix}}zip` doesn't export any runtime requirements (no idea how I would check that though), so this should be safe for the R recipes. Unclear how other potentially more complicated recipes will behave, but presumably any noarch recipe shouldn't be that complicated in the first place.
<issue_comment>username_1: @isuruf I'm confused by ""check that other platforms worked with the same recipe"". What do you mean exactly? I don't know if this is a valid check for noarch packages. Some noarch packages have arched deps (some of which don't exist for that arch) so I don't know if the package will build on other archs.
<issue_comment>username_2: Admittedly I’m not terribly worried about the decision made here. However historically we have only required that the `noarch` packages build on Linux as this is how we handle them in the feedstocks.

As to how one builds the packages on their platform, there are two strands of thought to consider. First we’ve generally not put too much effort into supporting users, who want to build the package outside of conda-forge, which this seems to fall under. Second `noarch` packages can be built using the same Docker image and build scripts locally to build on any platform. So this doesn’t really seem like an issue IMHO and am a little worried we are (slightly) diverting people’s efforts without a clear reason.

With `staged-recipes` CI checks, nothing intentional has been done here. This is really just the typical story of a task that has not moved to high priority and is probably not too difficult. We have dealt with this historically by either ignoring the CIs that are irrelevant or adding `[ci skip]` to commit messages, which only CircleCI ignores (though this disables the linter). Agree with others that better solutions are welcome here.
<issue_comment>username_0: Does anyone have any suggestions?
<issue_comment>username_1: As a counter point to https://github.com/conda-forge/conda-forge.github.io/issues/683#issuecomment-446368514 I think that checking the build on all platforms only on staged-recipes might send the wrong message. Changes to the feedstock might prevent the package from working on noarch, which is not something we check. If we want to check that noarch packages work on all platforms we should do this on feedstocks and staged-recipes to maintain parity.
<issue_comment>username_0: **Resolution for R noarch recipes:** The linter will ignore selectors in build requirements once a new version of conda-smithy is released (https://github.com/conda-forge/conda-smithy/pull/966). This will allow R noarch recipes to build successfully on Windows, thus easing the staged-recipes review process. The corresponding update to the R recipe helper is also in process (https://github.com/bgruening/conda_r_skeleton_helper/pull/37).

**Still unresolved**: Should noarch recipes be built for staged-recipes PRs? I had started a PR to do this (https://github.com/conda-forge/staged-recipes/pull/7239), but it would first require 1) consensus to make this change, and 2) someone knowledgeable of PowerShell to fix my initial prototype."
kentcdodds/glamorous-website,241745004,222,,"[{'action': 'opened', 'author': 'kentcdodds', 'comment_id': None, 'datetime': '2017-07-10 15:04:02+00:00', 'masked_author': 'username_0', 'text': ""<!--\r\nThanks for your interest in the project. We appreciate bugs filed and PRs submitted!\r\nPlease make sure that you are familiar with and follow the Code of Conduct for\r\nthis project (found in the CODE_OF_CONDUCT.md file).\r\n\r\nYou'll probably be asked to make a pull request to implement/fix this yourself\r\n(after we've decided on what to do). If you've never done that before, that's\r\ngreat! Check this free short video tutorial to learn how: http://kcd.im/pull-request\r\n-->\r\n\r\n**Problem Description:**\r\n\r\nSometimes it's useful\r\n\r\n**Suggested Solution:**\r\n\r\nDocument how you'd do that. See examples in https://github.com/paypal/glamorous/issues/136 and https://github.com/paypal/glamorous/issues/183 (also use cases in https://github.com/paypal/glamorous/issues/202)"", 'title': 'Make example for component as selector', 'type': 'issue'}
 {'action': 'created', 'author': 'goodmind', 'comment_id': 321031745.0, 'datetime': '2017-08-08 17:50:43+00:00', 'masked_author': 'username_1', 'text': '@username_0 any progress here?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kentcdodds', 'comment_id': 321032207.0, 'datetime': '2017-08-08 17:52:33+00:00', 'masked_author': 'username_0', 'text': 'Here\'s an example of one thing you could do:\r\n\r\n```javascript\r\nconst redDivClassName = \'my-own-unique-class-name-i-made-up\'\r\nconst RedDiv = glamorous.div(redDivClassName, {color: \'red\'})\r\nRedDiv.className = redDivClassName\r\n\r\n// elsewhere...\r\nconst ContainerDiv = glamorous.div({\r\n  [`& ${RedDiv.className}`]: {\r\n    color: \'blue\',\r\n  }\r\n})\r\n\r\n<ContainerDiv><RedDiv>Hello</RedDiv></ContainerDiv>\r\n\r\n// Renders <div><div>Hello</div></div>\r\n// with ""color: blue"" applied to <div>Hello</div>\r\n```\r\n\r\nWould you like to make a real example to add to the docs? This would be great as an interactive example :+1:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'goodmind', 'comment_id': 321042491.0, 'datetime': '2017-08-08 18:30:22+00:00', 'masked_author': 'username_1', 'text': ""@username_0 I don't see why this `className` can't be autogenerated?"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kentcdodds', 'comment_id': 321043077.0, 'datetime': '2017-08-08 18:32:28+00:00', 'masked_author': 'username_0', 'text': ""I suppose it could, but generated class names that are non-deterministic are generally not good for server-side rendering. And honestly, this isn't really a practice that we want to encourage."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'goodmind', 'comment_id': 321047403.0, 'datetime': '2017-08-08 18:48:44+00:00', 'masked_author': 'username_1', 'text': '@username_0 I wonder how `styled-components` doing this', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kentcdodds', 'comment_id': 321064029.0, 'datetime': '2017-08-08 19:56:10+00:00', 'masked_author': 'username_0', 'text': ""I'm not sure, but you can look at my attempt: https://github.com/paypal/glamorous/pull/183/files\r\n\r\nIt worked great, but it added complexity to the codebase to support a pattern we don't want to encourage anyway so I backed out of it. You should hopefully not be doing this a whole lot..."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'goodmind', 'comment_id': 321064647.0, 'datetime': '2017-08-08 19:58:32+00:00', 'masked_author': 'username_1', 'text': ""Well, I don't know how to do styling with props in my case \r\n```js\r\nstyled.div({\r\n  [`&:not(:first-child) ${AuthorName}`]: {\r\n    display: 'none',\r\n  },\r\n  [`&:not(:last-child) ${Avatar}`]: {\r\n    visibility: 'hidden',\r\n}),\r\n```"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kentcdodds', 'comment_id': 321064934.0, 'datetime': '2017-08-08 19:59:38+00:00', 'masked_author': 'username_0', 'text': ""Sorry @username_1. Could you make an example of what you're trying to do and share it here? Can base it on this: https://help.glamorous.rocks"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'goodmind', 'comment_id': 321069070.0, 'datetime': '2017-08-08 20:16:06+00:00', 'masked_author': 'username_1', 'text': '@username_0 https://codesandbox.io/s/j2P5JVwo4', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kentcdodds', 'comment_id': 321070811.0, 'datetime': '2017-08-08 20:22:51+00:00', 'masked_author': 'username_0', 'text': ""I see, and I agree that it does look a little clumsy. But not enough to justify complicating the API/implementation. I don't think that people will be doing this all that frequently... What do you suggest?"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kentcdodds', 'comment_id': 321071270.0, 'datetime': '2017-08-08 20:24:42+00:00', 'masked_author': 'username_0', 'text': ""In addition, there are other ways to do what you're doing there which do not require you to reference components in your selectors (like, just don't render the avatar multiple times in any group). This would actually be more performant and probably more readable as well..."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'stoikerty', 'comment_id': 324891142.0, 'datetime': '2017-08-25 11:19:00+00:00', 'masked_author': 'username_2', 'text': ""Our team is in the process of migrating our small-but-growing app from sass to glamorous (it's been awesome so far!) and we've come across an issue where we need to style a child component based on the hover of a parent component. It sounds a lot like what you guys are talking about here.\r\n\r\nThis is the snippet of the original sass-implementation:\r\n```scss\r\n.carousel-item {\r\n  z-index: 1;\r\n  position: relative;\r\n  padding: $grid;\r\n\r\n  &:hover {\r\n    .carousel-item__title {\r\n      color: $cerulean;\r\n      cursor: pointer;\r\n    }\r\n\r\n    .carousel-item__image-container {\r\n      &:after {\r\n        opacity: 1;\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n```js\r\nconst Item = g.div({\r\n  zIndex: 1,\r\n  position: 'relative',\r\n  padding: grid,\r\n  boxSizing: 'border-box',\r\n\r\n  // ... how do we modify Title and ImageContainer components?\r\n  `:hover ${ ? }`: { ... }\r\n});\r\n\r\nconst Title = g.div({ ... });\r\n\r\nconst ImageContainer = g.div({ ... });\r\n```"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'istarkov', 'comment_id': 325160605.0, 'datetime': '2017-08-26 20:38:44+00:00', 'masked_author': 'username_3', 'text': ""@username_2 see the example below, \r\nTake careful about  `// here space is necessary`\r\n\r\n```javascript\r\nconst footerHeaderClassName = `app-footer-header`;\r\nconst FooterHeader = glamorous.div(footerHeaderClassName, { color: 'red' });\r\n\r\nconst Footer = glamorous.div({\r\n  height: '2rem',\r\n  display: 'flex',\r\n  alignItems: 'center',\r\n  backgroundColor: 'rgba(0,0,0,0.2)',\r\n  ':hover': {\r\n    backgroundColor: 'rgba(0,0,0,0.8)',\r\n    // here space is necessary\r\n    [` .${footerHeaderClassName}`]: {\r\n      color: 'white',\r\n    },\r\n  },\r\n});\r\n```\r\n\r\nin render \r\n\r\n```javascript\r\n        <Footer>\r\n          <div>\r\n            <FooterHeader>Footer</FooterHeader>\r\n          </div>\r\n        </Footer>\r\n```"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'stoikerty', 'comment_id': 325220426.0, 'datetime': '2017-08-27 19:54:20+00:00', 'masked_author': 'username_2', 'text': 'Thanks @username_3 but this solution is not ideal and not scalable as it now requires me to track down and know all places where classnames are used which is arguably one of the things that brought me to `glamorous` and similar solutions like `styled-components` in the first place, not having to worry about classname collisions.\r\n\r\nFor modifiers via props I can just use the prop on both components where the modifier should have effect, however for things like `:hover` and `:focus` this is not possible.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'istarkov', 'comment_id': 325221287.0, 'datetime': '2017-08-27 20:09:57+00:00', 'masked_author': 'username_3', 'text': ""Seems like it's the only solution now, so does it scalable or ideal doesn't matter ;-)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'stoikerty', 'comment_id': 325230726.0, 'datetime': '2017-08-27 23:06:02+00:00', 'masked_author': 'username_2', 'text': ""Maybe for now it doesn't matter but for the future it matters, I believe there can be a better way to do this and it's important for people to express the need, especially if [an attempt](https://github.com/username_0/glamorous-website/issues/222#issuecomment-321064029) at solving this issue has already been made.\r\n\r\nNothing is set in stone ;)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kentcdodds', 'comment_id': 325392899.0, 'datetime': '2017-08-28 15:50:01+00:00', 'masked_author': 'username_0', 'text': '""Not ideal"" I agree with. As indicated in the attempt PR, it\'s a trade-off of choosing to not complicate the implementation in favor of enabling an infrequently and generally avoidable/undesirable pattern.\r\n\r\n""not scalable"" confuses me a little bit. One thing that you could do to improve that example @username_3 kindly provided would be:\r\n\r\n```javascript\r\nconst footerHeaderClassName = `app-footer-header`;\r\nconst FooterHeader = glamorous.div(footerHeaderClassName, { color: \'red\' });\r\nFooterHeader.className = footerHeaderClassName\r\n\r\nconst Footer = glamorous.div({\r\n  height: \'2rem\',\r\n  display: \'flex\',\r\n  alignItems: \'center\',\r\n  backgroundColor: \'rgba(0,0,0,0.2)\',\r\n  \':hover\': {\r\n    backgroundColor: \'rgba(0,0,0,0.8)\',\r\n    // here space is necessary, also I suggest using the & to make things more explicit\r\n    [`& .${FooterHeader.className}`]: {\r\n      color: \'white\',\r\n    },\r\n  },\r\n});\r\n```', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'stoikerty', 'comment_id': 325782469.0, 'datetime': '2017-08-29 20:00:02+00:00', 'masked_author': 'username_2', 'text': ""Thanks for further improving @username_3's example.\r\n\r\nWhat I mean by it not being scalable is that the hashing that glamourous is leveraging internally is not being used in this case, but it would be useful. Off the top of my head, there are 2 scenarios that I can think of why this matters.\r\n\r\n_Scenario 1_ is a large application with about 10 people working on it where hoverable items are used extensively, both in old and newly commited code. In this case, understanding why your new component might have the wrong style is an unexpected issue. This can easily be fixed by using a different classname, but it's time and effort wasted on debugging and understanding the issue and fixing it once does not prevent future issues.\r\n\r\n_Scenario 2_ is two 3rd-party components clashing. Ok, sure you're going to say this is far-fetched but hear me out. I have an app that I'm building for a company and I need to integrate 2 components that I found on NPM, they're really good and there's hardly any alternatives that I can use. There is a catch though, they both use `galmorous` and for some reason they both thought that using the class of `.button` on their component was a good idea to style their hover-state. Not only that but another developer has previously built a component inside the app I'm working on with the `.button`-class. The only way I can work around this issue is to first fix not using the `.button`-class in the app, but after I've done that, I still need to file an issue or create PR to at least one of the other 3rd-party components and hope that they agree to merge or fix the change in my favour.\r\n\r\n@username_0 I very much made this up but these things really happen. As my team is moving towards shareable components with NPM, we're discussing of using glamorous to power that. Therefore I'm naturally inclined to thing about more complex use-cases."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kentcdodds', 'comment_id': 325786907.0, 'datetime': '2017-08-29 20:13:16+00:00', 'masked_author': 'username_0', 'text': ""Thanks for the scenarios @username_2. I appreciate the shareable components use case, and I'm glad that you're considering glamorous for that. I think that it'll serve you extremely well.\r\n\r\nHere's the way I feel about it:\r\n\r\n1. Something has to be pretty compelling to add to the existing glamorous API\r\n2. This pattern is not something we should encourage, so that reduces how compelling it is\r\n3. This pattern is not something folks need to deal with all that frequently (depends on your use cases, but really not very often, many apps have no use cases for it at all, others have just one or two). So this also reduces how compelling it is.\r\n4. The scenarios you shared are really only a problem if people use generic class names.\r\n5. When we create an example on the website, we can call out the importance of making the class name non-generic.\r\n\r\nWhat do you think?"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'istarkov', 'comment_id': 325791097.0, 'datetime': '2017-08-29 20:23:20+00:00', 'masked_author': 'username_3', 'text': 'About 3 its frequent use case at my work. We are using css modules with support of themr library, and having a daily changing requirements we just cant extend components api forever. Solutions like current allows us to make changes without making any interventions in controls api. Imo this is really needed feature.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'istarkov', 'comment_id': 325792281.0, 'datetime': '2017-08-29 20:25:56+00:00', 'masked_author': 'username_3', 'text': 'BTW current solution is enougth for me even it does not solve all the edge cases, it solves mine', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kentcdodds', 'comment_id': 325793602.0, 'datetime': '2017-08-29 20:29:06+00:00', 'masked_author': 'username_0', 'text': ""Ok, it's pretty clear folks want this feature. If someone wants to create a PR on the main repo to add it I'm happy to review (no promises). It needs to be well tested and as simple as possible. Please use [my original PR](https://github.com/paypal/glamorous/pull/183) as a reference because there were a few decisions I made in that PR that I think are important.\r\n\r\nThanks for the discussion everyone!"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'stoikerty', 'comment_id': 325929105.0, 'datetime': '2017-08-30 09:00:40+00:00', 'masked_author': 'username_2', 'text': ""Sounds good @username_0. I would love to contribute, might take me a while to parse the old PR and figure out contributing etc. Wouldn't be surprised if someone gets it done before me but I'm up for it, love creating simple API's :)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kentcdodds', 'comment_id': 326095950.0, 'datetime': '2017-08-30 19:35:18+00:00', 'masked_author': 'username_0', 'text': ""Ok, I'm more positive that folks want this so: https://github.com/paypal/glamorous/issues/316"", 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'kentcdodds', 'comment_id': None, 'datetime': '2017-10-15 03:48:44+00:00', 'masked_author': 'username_0', 'text': '', 'title': None, 'type': 'issue'}]","<issue_start><issue_comment>Title: Make example for component as selector
username_0: <!--
Thanks for your interest in the project. We appreciate bugs filed and PRs submitted!
Please make sure that you are familiar with and follow the Code of Conduct for
this project (found in the CODE_OF_CONDUCT.md file).

You'll probably be asked to make a pull request to implement/fix this yourself
(after we've decided on what to do). If you've never done that before, that's
great! Check this free short video tutorial to learn how: http://kcd.im/pull-request
-->

**Problem Description:**

Sometimes it's useful

**Suggested Solution:**

Document how you'd do that. See examples in https://github.com/paypal/glamorous/issues/136 and https://github.com/paypal/glamorous/issues/183 (also use cases in https://github.com/paypal/glamorous/issues/202)
<issue_comment>username_1: @username_0 any progress here?
<issue_comment>username_0: Here's an example of one thing you could do:

```javascript
const redDivClassName = 'my-own-unique-class-name-i-made-up'
const RedDiv = glamorous.div(redDivClassName, {color: 'red'})
RedDiv.className = redDivClassName

// elsewhere...
const ContainerDiv = glamorous.div({
  [`& ${RedDiv.className}`]: {
    color: 'blue',
  }
})

<ContainerDiv><RedDiv>Hello</RedDiv></ContainerDiv>

// Renders <div><div>Hello</div></div>
// with ""color: blue"" applied to <div>Hello</div>
```

Would you like to make a real example to add to the docs? This would be great as an interactive example :+1:
<issue_comment>username_1: @username_0 I don't see why this `className` can't be autogenerated?
<issue_comment>username_0: I suppose it could, but generated class names that are non-deterministic are generally not good for server-side rendering. And honestly, this isn't really a practice that we want to encourage.
<issue_comment>username_1: @username_0 I wonder how `styled-components` doing this
<issue_comment>username_0: I'm not sure, but you can look at my attempt: https://github.com/paypal/glamorous/pull/183/files

It worked great, but it added complexity to the codebase to support a pattern we don't want to encourage anyway so I backed out of it. You should hopefully not be doing this a whole lot...
<issue_comment>username_1: Well, I don't know how to do styling with props in my case 
```js
styled.div({
  [`&:not(:first-child) ${AuthorName}`]: {
    display: 'none',
  },
  [`&:not(:last-child) ${Avatar}`]: {
    visibility: 'hidden',
}),
```
<issue_comment>username_0: Sorry @username_1. Could you make an example of what you're trying to do and share it here? Can base it on this: https://help.glamorous.rocks
<issue_comment>username_1: @username_0 https://codesandbox.io/s/j2P5JVwo4
<issue_comment>username_0: I see, and I agree that it does look a little clumsy. But not enough to justify complicating the API/implementation. I don't think that people will be doing this all that frequently... What do you suggest?
<issue_comment>username_0: In addition, there are other ways to do what you're doing there which do not require you to reference components in your selectors (like, just don't render the avatar multiple times in any group). This would actually be more performant and probably more readable as well...
<issue_comment>username_2: Our team is in the process of migrating our small-but-growing app from sass to glamorous (it's been awesome so far!) and we've come across an issue where we need to style a child component based on the hover of a parent component. It sounds a lot like what you guys are talking about here.

This is the snippet of the original sass-implementation:
```scss
.carousel-item {
  z-index: 1;
  position: relative;
  padding: $grid;

  &:hover {
    .carousel-item__title {
      color: $cerulean;
      cursor: pointer;
    }

    .carousel-item__image-container {
      &:after {
        opacity: 1;
      }
    }
  }
}
```

```js
const Item = g.div({
  zIndex: 1,
  position: 'relative',
  padding: grid,
  boxSizing: 'border-box',

  // ... how do we modify Title and ImageContainer components?
  `:hover ${ ? }`: { ... }
});

const Title = g.div({ ... });

const ImageContainer = g.div({ ... });
```
<issue_comment>username_3: @username_2 see the example below, 
Take careful about  `// here space is necessary`

```javascript
const footerHeaderClassName = `app-footer-header`;
const FooterHeader = glamorous.div(footerHeaderClassName, { color: 'red' });

const Footer = glamorous.div({
  height: '2rem',
  display: 'flex',
  alignItems: 'center',
  backgroundColor: 'rgba(0,0,0,0.2)',
  ':hover': {
    backgroundColor: 'rgba(0,0,0,0.8)',
    // here space is necessary
    [` .${footerHeaderClassName}`]: {
      color: 'white',
    },
  },
});
```

in render 

```javascript
        <Footer>
          <div>
            <FooterHeader>Footer</FooterHeader>
          </div>
        </Footer>
```
<issue_comment>username_2: Thanks @username_3 but this solution is not ideal and not scalable as it now requires me to track down and know all places where classnames are used which is arguably one of the things that brought me to `glamorous` and similar solutions like `styled-components` in the first place, not having to worry about classname collisions.

For modifiers via props I can just use the prop on both components where the modifier should have effect, however for things like `:hover` and `:focus` this is not possible.
<issue_comment>username_3: Seems like it's the only solution now, so does it scalable or ideal doesn't matter ;-)
<issue_comment>username_2: Maybe for now it doesn't matter but for the future it matters, I believe there can be a better way to do this and it's important for people to express the need, especially if [an attempt](https://github.com/username_0/glamorous-website/issues/222#issuecomment-321064029) at solving this issue has already been made.

Nothing is set in stone ;)
<issue_comment>username_0: ""Not ideal"" I agree with. As indicated in the attempt PR, it's a trade-off of choosing to not complicate the implementation in favor of enabling an infrequently and generally avoidable/undesirable pattern.

""not scalable"" confuses me a little bit. One thing that you could do to improve that example @username_3 kindly provided would be:

```javascript
const footerHeaderClassName = `app-footer-header`;
const FooterHeader = glamorous.div(footerHeaderClassName, { color: 'red' });
FooterHeader.className = footerHeaderClassName

const Footer = glamorous.div({
  height: '2rem',
  display: 'flex',
  alignItems: 'center',
  backgroundColor: 'rgba(0,0,0,0.2)',
  ':hover': {
    backgroundColor: 'rgba(0,0,0,0.8)',
    // here space is necessary, also I suggest using the & to make things more explicit
    [`& .${FooterHeader.className}`]: {
      color: 'white',
    },
  },
});
```
<issue_comment>username_2: Thanks for further improving @username_3's example.

What I mean by it not being scalable is that the hashing that glamourous is leveraging internally is not being used in this case, but it would be useful. Off the top of my head, there are 2 scenarios that I can think of why this matters.

_Scenario 1_ is a large application with about 10 people working on it where hoverable items are used extensively, both in old and newly commited code. In this case, understanding why your new component might have the wrong style is an unexpected issue. This can easily be fixed by using a different classname, but it's time and effort wasted on debugging and understanding the issue and fixing it once does not prevent future issues.

_Scenario 2_ is two 3rd-party components clashing. Ok, sure you're going to say this is far-fetched but hear me out. I have an app that I'm building for a company and I need to integrate 2 components that I found on NPM, they're really good and there's hardly any alternatives that I can use. There is a catch though, they both use `galmorous` and for some reason they both thought that using the class of `.button` on their component was a good idea to style their hover-state. Not only that but another developer has previously built a component inside the app I'm working on with the `.button`-class. The only way I can work around this issue is to first fix not using the `.button`-class in the app, but after I've done that, I still need to file an issue or create PR to at least one of the other 3rd-party components and hope that they agree to merge or fix the change in my favour.

@username_0 I very much made this up but these things really happen. As my team is moving towards shareable components with NPM, we're discussing of using glamorous to power that. Therefore I'm naturally inclined to thing about more complex use-cases.
<issue_comment>username_0: Thanks for the scenarios @username_2. I appreciate the shareable components use case, and I'm glad that you're considering glamorous for that. I think that it'll serve you extremely well.

Here's the way I feel about it:

1. Something has to be pretty compelling to add to the existing glamorous API
2. This pattern is not something we should encourage, so that reduces how compelling it is
3. This pattern is not something folks need to deal with all that frequently (depends on your use cases, but really not very often, many apps have no use cases for it at all, others have just one or two). So this also reduces how compelling it is.
4. The scenarios you shared are really only a problem if people use generic class names.
5. When we create an example on the website, we can call out the importance of making the class name non-generic.

What do you think?
<issue_comment>username_3: About 3 its frequent use case at my work. We are using css modules with support of themr library, and having a daily changing requirements we just cant extend components api forever. Solutions like current allows us to make changes without making any interventions in controls api. Imo this is really needed feature.
<issue_comment>username_3: BTW current solution is enougth for me even it does not solve all the edge cases, it solves mine
<issue_comment>username_0: Ok, it's pretty clear folks want this feature. If someone wants to create a PR on the main repo to add it I'm happy to review (no promises). It needs to be well tested and as simple as possible. Please use [my original PR](https://github.com/paypal/glamorous/pull/183) as a reference because there were a few decisions I made in that PR that I think are important.

Thanks for the discussion everyone!
<issue_comment>username_2: Sounds good @username_0. I would love to contribute, might take me a while to parse the old PR and figure out contributing etc. Wouldn't be surprised if someone gets it done before me but I'm up for it, love creating simple API's :)
<issue_comment>username_0: Ok, I'm more positive that folks want this so: https://github.com/paypal/glamorous/issues/316<issue_closed>"
sindresorhus/pageres,261423735,318,,"[{'action': 'opened', 'author': 'unknXwn', 'comment_id': None, 'datetime': '2017-09-28 18:52:58+00:00', 'masked_author': 'username_0', 'text': 'Hi; new to contributing to GitHub. \r\n\r\nEverything was going fine with pageres with the three test pages I tried, but then I tried the following site- jalopnik.com- and it attempted to do it, creating a temp output file, but then said ""Couldn\'t load url: http://jalopnik.com"" so I went to the site in a browser, and noticed it\'s https, so I tried using https://www.jalopnik.com and it returned the same error. \r\n\r\nThoughts?\r\n\r\nUsing a daily build of Ubuntu 17.10 from a few days ago, in a VM. \r\n\r\nAlso, as an aside, is there anyway, I can load a txt file containing a list of URLs to pageres to grab screens from?\r\n\r\nThank you,\r\n-Ryan', 'title': ""Couldn't load url"", 'type': 'issue'}
 {'action': 'created', 'author': 'SamVerschueren', 'comment_id': 333064855.0, 'datetime': '2017-09-29 08:27:48+00:00', 'masked_author': 'username_1', 'text': 'Have you tried another URL? This one is failing for me as well, no idea why but seems like a PhantomJS issue.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'SamVerschueren', 'comment_id': 333065028.0, 'datetime': '2017-09-29 08:28:33+00:00', 'masked_author': 'username_1', 'text': 'You can also use [pageres-cli](https://github.com/username_2/pageres-cli) and use CLI commands to read and pass the data to pageres.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'unknXwn', 'comment_id': 333172947.0, 'datetime': '2017-09-29 16:24:54+00:00', 'masked_author': 'username_0', 'text': 'I tried your suggestion: \r\n\r\n$ pageres < urls.txt\r\n\r\nHowever, it did nothing. See below.  That file had 2 URLs in it. \r\n![screenshot from 2017-09-29 12-13-52](https://user-images.githubusercontent.com/32371748/31025281-13aeaacc-a510-11e7-81ee-fd256e8d62c8.png)\r\n\r\nAs for another URL to try, I tried the parent company of Jalopnik, Kinja.com and that couldn\'t load either.  Whatever they\'re doing, it\'s causing failure with this tool.  That said, prob safe to assume that any site powered with Kinja will not work.... lifehacker.com doesn\'t work and it\'s powered by Kinja. \r\n\r\nThankfully, Kinja-based sites are not my goal.  The goal is to load a txt file with numerous URLs and have that processed.  I currently have a 180MB txt file filled with URLs.  Yes, MB. Just looking to grab screenshots of homepages so I can use them as initial profile/cover pics. \r\n\r\nI don\'t mind splitting the file up, but I just want to be able to load ""a"" file into pageres to be processed. \r\n\r\nthanks for help. \r\n-ryan', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'unknXwn', 'comment_id': 333205818.0, 'datetime': '2017-09-29 18:40:02+00:00', 'masked_author': 'username_0', 'text': ""I started trying part of the list of URLs, literally by copy pasting like 4 into the command line, and since one URL couldn't load, it broke the operation and the other 3 were not rendered.   I tried this with another batch and I deleted each URL it didn't like one by one til I only had 2 URLs that it was able to render, so 50% success rate. \r\n\r\nA site from that list it couldn't load is manpower.com .  I found that the other site that didn't load actually couldn't load in a browser, so I think the site is dead or just a bad URL. \r\n\r\nAnyway, that said, I need to find a way to have pageres skip errors and carry on, using txt files as input and if it could then use a batch of txt files, great, if not, no problem; I'll just have to manually start it again for the next file, for all 35 of them."", 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'sindresorhus', 'comment_id': None, 'datetime': '2019-02-09 13:49:22+00:00', 'masked_author': 'username_2', 'text': '', 'title': None, 'type': 'issue'}]","<issue_start><issue_comment>Title: Couldn't load url
username_0: Hi; new to contributing to GitHub. 

Everything was going fine with pageres with the three test pages I tried, but then I tried the following site- jalopnik.com- and it attempted to do it, creating a temp output file, but then said ""Couldn't load url: http://jalopnik.com"" so I went to the site in a browser, and noticed it's https, so I tried using https://www.jalopnik.com and it returned the same error. 

Thoughts?

Using a daily build of Ubuntu 17.10 from a few days ago, in a VM. 

Also, as an aside, is there anyway, I can load a txt file containing a list of URLs to pageres to grab screens from?

Thank you,
-Ryan
<issue_comment>username_1: Have you tried another URL? This one is failing for me as well, no idea why but seems like a PhantomJS issue.
<issue_comment>username_1: You can also use [pageres-cli](https://github.com/username_2/pageres-cli) and use CLI commands to read and pass the data to pageres.
<issue_comment>username_0: I tried your suggestion: 

$ pageres < urls.txt

However, it did nothing. See below.  That file had 2 URLs in it. 
![screenshot from 2017-09-29 12-13-52](https://user-images.githubusercontent.com/32371748/31025281-13aeaacc-a510-11e7-81ee-fd256e8d62c8.png)

As for another URL to try, I tried the parent company of Jalopnik, Kinja.com and that couldn't load either.  Whatever they're doing, it's causing failure with this tool.  That said, prob safe to assume that any site powered with Kinja will not work.... lifehacker.com doesn't work and it's powered by Kinja. 

Thankfully, Kinja-based sites are not my goal.  The goal is to load a txt file with numerous URLs and have that processed.  I currently have a 180MB txt file filled with URLs.  Yes, MB. Just looking to grab screenshots of homepages so I can use them as initial profile/cover pics. 

I don't mind splitting the file up, but I just want to be able to load ""a"" file into pageres to be processed. 

thanks for help. 
-ryan
<issue_comment>username_0: I started trying part of the list of URLs, literally by copy pasting like 4 into the command line, and since one URL couldn't load, it broke the operation and the other 3 were not rendered.   I tried this with another batch and I deleted each URL it didn't like one by one til I only had 2 URLs that it was able to render, so 50% success rate. 

A site from that list it couldn't load is manpower.com .  I found that the other site that didn't load actually couldn't load in a browser, so I think the site is dead or just a bad URL. 

Anyway, that said, I need to find a way to have pageres skip errors and carry on, using txt files as input and if it could then use a batch of txt files, great, if not, no problem; I'll just have to manually start it again for the next file, for all 35 of them.<issue_closed>"
gitpod-io/website,680625099,716,"{'number': 716.0, 'repo': 'website', 'user_login': 'gitpod-io'}","[{'action': 'opened', 'author': 'nisarhassan12', 'comment_id': None, 'datetime': '2020-08-18T01:39:06Z', 'masked_author': 'username_0', 'text': '', 'title': 'WIP: update the messaging + design', 'type': 'issue'}
 {'action': 'created', 'author': 'ChristinFrohne', 'comment_id': 678945336.0, 'datetime': '2020-08-24 07:01:12+00:00', 'masked_author': 'username_1', 'text': 'Great! Just some small nits:\r\n\r\n- [ ] The name of the plans are ""Free"" & ""Professional"" \r\n\r\n- [ ] Please move both buttons a bit further down so there is some spacing above ""contact sales""\r\n<img width=""854"" alt=""Bildschirmfoto 2020-08-24 um 08 36 00"" src=""https://user-images.githubusercontent.com/46345125/91011621-ed9cc580-e5e4-11ea-8051-697adc555f59.png"">\r\n\r\n- [ ] Could you use the lighter gray for  ""works with"". I think it\'s #8f8f8f that you\'re using. \r\n<img width=""274"" alt=""Bildschirmfoto 2020-08-24 um 08 37 55"" src=""https://user-images.githubusercontent.com/46345125/91011727-1fae2780-e5e5-11ea-9edb-a8bf9b1e4c50.png"">\r\n\r\n- [ ] It\'s free for unlimited users \r\n<img width=""718"" alt=""Bildschirmfoto 2020-08-24 um 08 34 29"" src=""https://user-images.githubusercontent.com/46345125/91011489-ae6e7480-e5e4-11ea-8909-0b481ed9a48d.png"">\r\n\r\nMobile:\r\n\r\n- [ ] the logo section is still broken on iphone\r\n\r\n- [ ] move ""with gitpod"" ""usual way"" buttons a bit further up so it\'s displayed on the same screen\r\n\r\n- [ ] I think it\'d be nicer if the boxes with the structure would cover the sides as well (No vertical white space)\r\nLike this:\r\n<img width=""377"" alt=""Bildschirmfoto 2020-08-24 um 08 52 03"" src=""https://user-images.githubusercontent.com/46345125/91012868-1a51dc80-e5e7-11ea-9bc6-16939254cd8e.png"">\r\n\r\n- [ ] please layout the open-source box & secure-box like this in mobile:\r\n<img width=""377"" alt=""Bildschirmfoto 2020-08-24 um 08 56 05"" src=""https://user-images.githubusercontent.com/46345125/91013374-e4f9be80-e5e7-11ea-8da4-9ed85732f5a1.png"">', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'meysholdt', 'comment_id': 679021408.0, 'datetime': '2020-08-24 09:38:23+00:00', 'masked_author': 'username_2', 'text': 'regarding https://deploy-preview-716--gitpod-website.netlify.app/self-hosted/\r\n* ""Free for up to 5 Users."" --> ""Free for unlimited Users""\r\n* ""Install Gitpod Self-Hosted"" --> There we would additionally have an AWS box. We also support AWS now.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'meysholdt', 'comment_id': 679024516.0, 'datetime': '2020-08-24 09:41:54+00:00', 'masked_author': 'username_2', 'text': 'regarding https://deploy-preview-716--gitpod-website.netlify.app/pricing/#self-hosted\r\n""Obtain your trial license here and get started by installing Gitpod Self-Hosted."" --> remove.\r\n""How can I install Self-Hosted?"" -> AWS is now officially supported.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChristinFrohne', 'comment_id': 679079600.0, 'datetime': '2020-08-24 11:49:36+00:00', 'masked_author': 'username_1', 'text': 'Please add ""billed annually at $240"" or ""€216"" depending on the location settings to the self-hosted pricing\r\n<img width=""961"" alt=""Bildschirmfoto 2020-08-24 um 13 47 45"" src=""https://user-images.githubusercontent.com/46345125/91041578-990f3f80-e610-11ea-9b7c-331c05b9dd3c.png"">', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'nisarhassan12', 'comment_id': 679200716.0, 'datetime': '2020-08-24 15:34:29+00:00', 'masked_author': 'username_0', 'text': '@username_4 is working on fixing that.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChristinFrohne', 'comment_id': 679229469.0, 'datetime': '2020-08-24 16:22:44+00:00', 'masked_author': 'username_1', 'text': 'Please update the screenshot for ""where teams code together"" with this one\r\n<img width=""878"" alt=""Bildschirmfoto 2020-08-24 um 18 18 56"" src=""https://user-images.githubusercontent.com/46345125/91070190-bbb44f00-e636-11ea-957e-1350899c0b07.png"">', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'nisarhassan12', 'comment_id': 679262789.0, 'datetime': '2020-08-24 17:27:47+00:00', 'masked_author': 'username_0', 'text': 'I have updated the screenshot.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChristinFrohne', 'comment_id': 679846803.0, 'datetime': '2020-08-25 07:09:38+00:00', 'masked_author': 'username_1', 'text': 'Please also add a new meta description\r\n\r\nTitle: ""Gitpod - Dev environments built for the cloud""\r\nDescription: ""Gitpod streamlines developer workflows by providing prebuilt, collaborative development environments in your browser - powered by VS Code. ""', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'svenefftinge', 'comment_id': 679906632.0, 'datetime': '2020-08-25 09:13:35+00:00', 'masked_author': 'username_3', 'text': 'Please make the drop down boxes so that nothing is selected by default.\r\nCurrently it is Afghanistan and 10 employees.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'nisarhassan12', 'comment_id': 679907312.0, 'datetime': '2020-08-25 09:14:49+00:00', 'masked_author': 'username_0', 'text': '@username_3 Thanks. I have already updated it but have not pushed the changes yet.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jankeromnes', 'comment_id': 679980282.0, 'datetime': '2020-08-25 11:58:26+00:00', 'masked_author': 'username_4', 'text': 'Hi @username_0! Many thanks for the amazing work. 💯\r\n\r\nPlease note that there is already a AWS section in https://www.gitpod.io/self-hosted/#install (sorry for conflicting with your work)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'svenefftinge', 'comment_id': 679984805.0, 'datetime': '2020-08-25 12:08:36+00:00', 'masked_author': 'username_3', 'text': ""Wow, this is now totally messed up. I think it's because of the force-push..."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jankeromnes', 'comment_id': 679985055.0, 'datetime': '2020-08-25 12:09:04+00:00', 'masked_author': 'username_4', 'text': 'I can help, I know my way around tricky rebases', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jankeromnes', 'comment_id': 679985381.0, 'datetime': '2020-08-25 12:09:47+00:00', 'masked_author': 'username_4', 'text': ""I'll clean this PR up now"", 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: WIP: update the messaging + design
username_0: 
<issue_comment>username_1: Great! Just some small nits:

- [ ] The name of the plans are ""Free"" & ""Professional"" 

- [ ] Please move both buttons a bit further down so there is some spacing above ""contact sales""
<img width=""854"" alt=""Bildschirmfoto 2020-08-24 um 08 36 00"" src=""https://user-images.githubusercontent.com/46345125/91011621-ed9cc580-e5e4-11ea-8051-697adc555f59.png"">

- [ ] Could you use the lighter gray for  ""works with"". I think it's #8f8f8f that you're using. 
<img width=""274"" alt=""Bildschirmfoto 2020-08-24 um 08 37 55"" src=""https://user-images.githubusercontent.com/46345125/91011727-1fae2780-e5e5-11ea-9edb-a8bf9b1e4c50.png"">

- [ ] It's free for unlimited users 
<img width=""718"" alt=""Bildschirmfoto 2020-08-24 um 08 34 29"" src=""https://user-images.githubusercontent.com/46345125/91011489-ae6e7480-e5e4-11ea-8909-0b481ed9a48d.png"">

Mobile:

- [ ] the logo section is still broken on iphone

- [ ] move ""with gitpod"" ""usual way"" buttons a bit further up so it's displayed on the same screen

- [ ] I think it'd be nicer if the boxes with the structure would cover the sides as well (No vertical white space)
Like this:
<img width=""377"" alt=""Bildschirmfoto 2020-08-24 um 08 52 03"" src=""https://user-images.githubusercontent.com/46345125/91012868-1a51dc80-e5e7-11ea-9bc6-16939254cd8e.png"">

- [ ] please layout the open-source box & secure-box like this in mobile:
<img width=""377"" alt=""Bildschirmfoto 2020-08-24 um 08 56 05"" src=""https://user-images.githubusercontent.com/46345125/91013374-e4f9be80-e5e7-11ea-8da4-9ed85732f5a1.png"">
<issue_comment>username_2: regarding https://deploy-preview-716--gitpod-website.netlify.app/self-hosted/
* ""Free for up to 5 Users."" --> ""Free for unlimited Users""
* ""Install Gitpod Self-Hosted"" --> There we would additionally have an AWS box. We also support AWS now.
<issue_comment>username_2: regarding https://deploy-preview-716--gitpod-website.netlify.app/pricing/#self-hosted
""Obtain your trial license here and get started by installing Gitpod Self-Hosted."" --> remove.
""How can I install Self-Hosted?"" -> AWS is now officially supported.
<issue_comment>username_1: Please add ""billed annually at $240"" or ""€216"" depending on the location settings to the self-hosted pricing
<img width=""961"" alt=""Bildschirmfoto 2020-08-24 um 13 47 45"" src=""https://user-images.githubusercontent.com/46345125/91041578-990f3f80-e610-11ea-9b7c-331c05b9dd3c.png"">
<issue_comment>username_0: @username_4 is working on fixing that.
<issue_comment>username_1: Please update the screenshot for ""where teams code together"" with this one
<img width=""878"" alt=""Bildschirmfoto 2020-08-24 um 18 18 56"" src=""https://user-images.githubusercontent.com/46345125/91070190-bbb44f00-e636-11ea-957e-1350899c0b07.png"">
<issue_comment>username_0: I have updated the screenshot.
<issue_comment>username_1: Please also add a new meta description

Title: ""Gitpod - Dev environments built for the cloud""
Description: ""Gitpod streamlines developer workflows by providing prebuilt, collaborative development environments in your browser - powered by VS Code. ""
<issue_comment>username_3: Please make the drop down boxes so that nothing is selected by default.
Currently it is Afghanistan and 10 employees.
<issue_comment>username_0: @username_3 Thanks. I have already updated it but have not pushed the changes yet.
<issue_comment>username_4: Hi @username_0! Many thanks for the amazing work. 💯

Please note that there is already a AWS section in https://www.gitpod.io/self-hosted/#install (sorry for conflicting with your work)
<issue_comment>username_3: Wow, this is now totally messed up. I think it's because of the force-push...
<issue_comment>username_4: I can help, I know my way around tricky rebases
<issue_comment>username_4: I'll clean this PR up now"
conda-forge/conda-forge.github.io,143982127,64,,"[{'action': 'opened', 'author': 'jakirkham', 'comment_id': None, 'datetime': '2016-03-28 13:50:32+00:00', 'masked_author': 'username_0', 'text': ""The current system of having the version Windows' MSVC tied to the CPython is troublesome for people in some cases. In particular, with respect to cases where people needed the latest compiler features (e.g. C++11 features). There may be other relevant cases, as well. The main purpose of this issue is to suggest that we include some (maybe even just one) compilation of a non-standard CPython VC build on Windows to simplify things for the conda community. Of course, making this change could disrupt the current feature landscape of Windows CPython so needs some thought on that point. This issue is also opened to get feedback from the conda community to determine which non-standard CPython VC builds would be valuable and thus be worthwhile to support. At present, I am thinking a `vc14` (i.e. Visual Studio 2015) variant of CPython 2.7.x (where x will always be latest) is almost certainly worthwhile just to get C++11 support. Though am not sure if there are other worthwhile non-standard variants to consider.\r\n\r\ncc @username_3 @jasongrout @username_6 @username_1 @username_5"", 'title': 'Supporting non-standard CPython VC builds on Windows', 'type': 'issue'}
 {'action': 'created', 'author': 'msarahan', 'comment_id': 202404184.0, 'datetime': '2016-03-28 13:56:42+00:00', 'masked_author': 'username_1', 'text': 'This obviously comes with a huge YMMV, but would be helpful to a lot of people.  You could have installers like what @username_8 did with ACPD: https://github.com/acpd/acpd\r\n\r\nA lot of people will probably get very confused by incompatible software, but we just need to document what this is and is not very, very clearly.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 202406646.0, 'datetime': '2016-03-28 14:03:32+00:00', 'masked_author': 'username_0', 'text': 'Absolutely. This would also be a very hands on endeavor that would really need community involvement to be successful.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 202407405.0, 'datetime': '2016-03-28 14:06:46+00:00', 'masked_author': 'username_0', 'text': 'Once we nail down which non-standard variant could be reasonably supported here and what accommodations may be needed in conda/conda-build. We may need to revisit the AppVeyor build matrix to include this logic there. That way, we can do a better job at providing things that will play nice together.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 202483866.0, 'datetime': '2016-03-28 16:57:11+00:00', 'masked_author': 'username_2', 'text': ""This is a very big deal, actually. Not to be taken lightly at all!\r\n\r\nkey is that it would essentially be a different platform. You'd have Windows 32 and 64 bit (confusing enough for some folks), and now multiple versions of those. Though I suppose we'd really only need to support Py27 on Windows64.  Py3.5 is already using MSVS2015.\r\n\r\nBut one of the nice things about conda (and Anaconda) is that the binaries are compatible with the python.org ones, so that pip install also works. We'd have to make sure that someone running the MSVS2015 build couldn't accidentally get an incompatible binary from PyPI, (Or anywhere else).\r\n\r\nAlso -- we'd then need to build everything in the default channel, too.....\r\n\r\n-CHB"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 202489472.0, 'datetime': '2016-03-28 17:07:17+00:00', 'masked_author': 'username_0', 'text': 'It was sort of my impression that we are doing this anyways. So, this might be the one part that is not a problem. The only part to work on here would be to add this to our Windows build matrix. Though this is many steps later.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 202502434.0, 'datetime': '2016-03-28 17:43:02+00:00', 'masked_author': 'username_2', 'text': 'well, there are a number of platforms -- one of them is win-64 -- due to its Python roots, I assume that conda assumes that that means the VS2008 run-time C lib as well -- obviously for Python, but also for any shared libraries. So I think the way to do this would be to create a new platfrom, not another python variant.\r\n\r\nwin-64-15 ????\r\n\r\nI have no idea how hard-coded the various platforms are in the whole conda / anaconda ecosystem -- is it hard to add a new one?\r\n\r\n(also, it would be a bit unfortunate, as pure python libs, etc would all need separate builds...)\r\n\r\nBut I just had a realization -- py2.7 and py3.5 currently use different run times, so shared libs that re going to be used with python should be built differently -- how in the world is that dealt with now???\r\n\r\n-CHB', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 202503707.0, 'datetime': '2016-03-28 17:47:38+00:00', 'masked_author': 'username_2', 'text': ""I don't know how hard / possible it is to disallow binary wheels with a given pip install (and someone could install pip themselves from source, etc....)\r\n\r\nprobably what you'd want to do is make sure the platform tag used by python (and therefor found by pip) was unique.\r\n\r\nBut The core python devs are not going to build a Python with a new MS compiler because of all this pain, and because py2.7 is a dead end -- it has always worked better to simiply use a newer compiler when you have a newer version --a nd there is not going to be a newer version of 2.7.\r\n\r\nIN fact, the stackless folks were pushing for a 2.8 that was the same except for the MS compiler used to build it -- that was not accepted as a reasonable option.\r\n\r\nSo maybe it's time to just say -- if you want modern C++, then you should use a modern Python, too.\r\n\r\nI know, tough love!"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ukoethe', 'comment_id': 202987013.0, 'datetime': '2016-03-29 16:33:01+00:00', 'masked_author': 'username_3', 'text': ""No, this problem can be solved with `features` (subject to a fix in the version resolution algorithm that went into conda 4.0). Suppose there is a package `vc11-runtime` that contains a declaration `track_features: - vc11`. Then, users can tell conda to use Visual Studio 2012 by simply installing that package first:\r\n```\r\nconda create  -n python-vc11  vc11-runtime  python=2.7 ...\r\n```\r\nconda will now prefer package variants that contain a `features: - vc11` declaration over those that don't. So, simply put that declaration into packages compiled with vc11, and let conda figure out the rest."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 202991106.0, 'datetime': '2016-03-29 16:45:24+00:00', 'masked_author': 'username_0', 'text': 'If we use an even more recent compiler for this sort of endeavor, would that still work for you, @username_3?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ukoethe', 'comment_id': 203003711.0, 'datetime': '2016-03-29 17:10:41+00:00', 'masked_author': 'username_3', 'text': ""Yes, but I haven't checked if there are any hidden difficulties along the way. \r\n(For example: I use `devenv PCbuild.sln /upgrade` to update Python's official project files to the new compiler version. Will this command still work as desired for VS 2015?)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ukoethe', 'comment_id': 203008564.0, 'datetime': '2016-03-29 17:20:26+00:00', 'masked_author': 'username_3', 'text': ""This is indeed a problem when using a non-standard compiler. However, one could easily add a warning to conda's pip module saying that pip downloads may be incompatible with the current environment when a non-standard compiler was used.\r\n\r\nOn the other hand, conda *exists* because pip's support for compiled modules with complicated C/C++ dependencies was insufficient. People familiar with conda will probably use pip only for simple things like pure Python modules (where the compiler doesn't matter), and wouldn't be surprised if pip failed for more complicated stuff."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 203064084.0, 'datetime': '2016-03-29 19:30:45+00:00', 'masked_author': 'username_2', 'text': ""yeah, I guess that's the trick -- I would be more or less happy to tell anyone writing a package that needs C++11 to use py3, but then you've got other stuff you want to use that isn't py3 ready ( :-( ). I sure wish everyone used Cython -- then the py3 port would be pretty easy.\r\n\r\nHonestly, though I still think we'l all need to go to py3 some day -- the more reasons to support that the better."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 203068737.0, 'datetime': '2016-03-29 19:44:44+00:00', 'masked_author': 'username_2', 'text': 'I still don\'t ""get"" features, but if so -- great.\r\n\r\nbut it sounds risky -- conda will prefer packages with the feature, but I take it it will allow packages that don\'t have it -- which is the vast majority of compiled packages -- so it would be very easy for a user to get an incompatible package -even without pip.\r\n\r\nIt still seems to me that you\'d want this to be a different platform -- or maybe a different python version.\r\n\r\ncall it py28 -- against the wishes of the core devs :-)\r\n\r\nBut I\'ll leave that to the conda experts -- you may be right.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 203511579.0, 'datetime': '2016-03-30 16:22:05+00:00', 'masked_author': 'username_0', 'text': '@username_4, I forgot to cc you on this. Sorry about that. Maybe of some interest to you.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'patricksnape', 'comment_id': 203524371.0, 'datetime': '2016-03-30 16:53:32+00:00', 'masked_author': 'username_4', 'text': ""Although my gut is that I'm against this :stuck_out_tongue_closed_eyes: I understand @username_3's pain about scientific packaging. Ideally the response would be to upgrade those projects so that they work on Python 3.5 and then use Python 3.x so you get a compliant compiler. However, as I said, I totally understand that we are all busy and that is often impractical. Though someone will have to do it before 2019!\r\n\r\nI would throw my weight behind the features option - since any code without compiled extensions doesn't actually care about the Visual Studio version that was used to build it. Any conda-forge code should have the correct feature set anyway so that won't be a problem. I **strongly** urge against Python 2.8.\r\n\r\nIn terms of `pip`, as @username_0 mentioned, the whole point of conda was to try and standardise a lot of these issues. Given the lack of community around providing wheels, I doubt that a lot of wheels being provided by anyone other than Christoph Gohlke are actually being careful about which compiler is used. Therefore, I would say that we document against using wheels and always prefer the `pip` install without wheels option when using conda on Windows."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ukoethe', 'comment_id': 203532577.0, 'datetime': '2016-03-30 17:10:12+00:00', 'masked_author': 'username_3', 'text': ""Another important point in support of this option is that features (or some yet-to-be-defined alternative) are needed for a number of other legitimate configurations anyway (Python version, BLAS variant, AVX acceleration, ...). Then, adding a compiler feature is not such a big deal -- it only makes the build matrix a bit bigger and requires build scripts to be a bit more portable. I don't expect this to be very complicated once the first compiler on a given platform works.\r\n\r\nOf course, I agree that in an ideal world, all packages should support the newest Python version."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 203534761.0, 'datetime': '2016-03-30 17:16:18+00:00', 'masked_author': 'username_0', 'text': 'We already use different compilers with Windows. My concern from earlier involves changes to the `meta.yaml`, which I know you have already spent some time thinking about. Maybe worth sharing. :wink:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 203640965.0, 'datetime': '2016-03-30 21:22:46+00:00', 'masked_author': 'username_2', 'text': 'Another important point in support of this option is that features (or some\nyet-to-be-defined alternative) are needed for a number of other legitimate\nconfigurations anyway (Python version, BLAS variant, AVX acceleration, ...).\n\nThings like BLAS are only required by, well, things that require BLAS.\n\nThe compiler used (or, more to the point, the runtime used) effects every\ncompiled extension. And there are a LOT of complied extensions in the\ndefault channel, not to mention wheels ( which we could say ""Don\'t do that""\nabout those)\n\nI\'m just not sure that features provide a robust solution to this problem.\nBut if they do, great.\n\nOne of the challenges is that if you mix run times, it generally won\'t fail\nright away (or may not fail at all)\n\n-CHB', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcg1969', 'comment_id': 203978401.0, 'datetime': '2016-03-31 15:05:00+00:00', 'masked_author': 'username_5', 'text': ""I dropped out of this conversation, so I know I might either be repeating something already said or missing context---_but_, the more I think about it the more I believe that cleaning our our channel collision problem---that is, two different channels providing the same package---is going to solve a lot of problems, like this one.\r\n\r\nHandling a version of Python compiled with a non-standard compiler is really no different than having to differentiate between 32-bit and 64-bit builds. Hence: each unique CPython needs to be in its own channel, and we need to make sure that those channels don't stomp on each other. Whatever channel is highest priority wins."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcg1969', 'comment_id': 203978610.0, 'datetime': '2016-03-31 15:05:42+00:00', 'masked_author': 'username_5', 'text': ""There are too many things being blocked by conda's inability to handle channel conflicts properly. Time to expedite that fix."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ukoethe', 'comment_id': 204068203.0, 'datetime': '2016-03-31 18:34:30+00:00', 'masked_author': 'username_3', 'text': 'Interesting. Two questions:\r\n\r\n* When your idea gets implemented, how will a user create an environment that uses a non-standard compiler?\r\n* Apparently, you arrived at the conclusion that `features` are not the right solution to the compiler configuration problem. Could you explain why?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcg1969', 'comment_id': 204071904.0, 'datetime': '2016-03-31 18:43:04+00:00', 'masked_author': 'username_5', 'text': ""Features are proving vexing to implement in a consistent manner with behavior that everyone is satisfied with. \r\n\r\nFor instance: what should take priority, the presence of a feature, or a higher version number? For instance, suppose we have the `mkl` feature in an environment, and we run `conda install numpackage`. Further suppose that `numpackage 1.0` uses the `mkl` feature, whereas `numpackage 2.0` does not. What should be preferred? There is merit in both choices, but currently we choose the latter. And that's not likely to change since the `mkl` -> `nomkl` transition depends on it. \r\n\r\nFurthermore, I don't think features alone address some of the mutual exclusion requirements that things like compiler versions will need. For example, if we use a feature to specify a particular compiler version, how do we prevent packages that were compiled with a _different_ compiler are not installed?\r\n\r\nI don't want to say that I've definitively concluded that features aren't at least part of the solution. But if you had been in my shoes the last couple of months you wouldn't be as reluctant as I am to pronounce them the solution."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcg1969', 'comment_id': 204073406.0, 'datetime': '2016-03-31 18:47:10+00:00', 'masked_author': 'username_5', 'text': ""Continuing the `numpackage` example. Suppose we had two channels, `openblas/` and `mkl/`, each populated with exactly the same packages, except as needed to link to their respective BLAS libraries. Perhaps `numpackage 2.0` is only in `openblas`; an MKL version hasn't been built yet.\r\n\r\nWith the current regime, `conda update numpackage` is going to pull the OpenBLAS version, whether the user wants it or not. With two separate channels, and proper collision avoidance, an MKL user will never accidentally install the OpenBLAS version."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ukoethe', 'comment_id': 204081256.0, 'datetime': '2016-03-31 19:03:24+00:00', 'masked_author': 'username_3', 'text': ""IMHO, the use of a feature should be preferred. If I'm not mistaken, that's what the new version resolution algorithm in conda 4.0 implements, no? (My preliminary tests of conda 4.0 seem to confirm this.)  And it's also the effect of using different channels, if I interpret your `openblas` vs. `mkl` example correctly."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcg1969', 'comment_id': 204089586.0, 'datetime': '2016-03-31 19:27:32+00:00', 'masked_author': 'username_5', 'text': ""Everything I just described above regarding features is 4.0 --- including the problems. I'm simply not convinced they fully solve the problems you're hoping they will, and I think it will be far too easy to create environments with conflicting packages without _some_ further enhancements."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 204155000.0, 'datetime': '2016-03-31 22:19:57+00:00', 'masked_author': 'username_2', 'text': ""I recall some talk about a way to specify platform-independent packages --\ni.e. pure python packages don't need to be any different on Linux vs\nWindows vs OS-X.\n\nIF we could get that working, then Win-VC2105 could be a different\nplatform, and folks could still get pure python packages from the other\nplatforms.\n\nOf course, they couldn't get compiled packages that have nothing to do with\npython without re-building them....\n\nThis is a pain -- thank you MS!\n\n-Chris"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'msarahan', 'comment_id': 204156055.0, 'datetime': '2016-03-31 22:25:12+00:00', 'masked_author': 'username_1', 'text': ""We do have noarch builds, but they're sort of error-prone (https://github.com/ContinuumIO/anaconda-issues/issues/730) and not widely used."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'SylvainCorlay', 'comment_id': 204162337.0, 'datetime': '2016-03-31 22:49:27+00:00', 'masked_author': 'username_6', 'text': ""Sorry for jumping in so late.\r\n\r\nI think that it would be a very bad idea to make a MSVC14 build of python for all the reasons mentioned earlier with respect to the ability to install binary wheels from pip that would then *not* be binary compatible.\r\n\r\nBesides, it is actually possible to build C extension modules with more recent versions for MSVC than the one used to build Python itself. The one thing that one must be cautious to use the MSVC8 C runtime when allocating or de-allocating objects passed or received from Python.\r\n\r\nActually, I am doing so (forcing the use of MSVC14 to build python 2.7 extension) in the case of extension modules built with [pybind11](https://github.com/pybind/pybind11/). Pybind11 (authored by @wjakob) has similar goals to `boost.python` but is C++11-only and therefore requires msvc14 on windows.\r\n\r\n@username_0 I made an example project [here](https://github.com/pybind/pbtest), built with pybind11, which comes with a conda recipe. The conda recipe's `bld.bat` does the magic of forcing MSVC14 for the build. You can also notice that I was careful to include the MSVC14 runtime as a runtime dependency to the conda package's meta.yml.\r\n\r\nFinally, Python 3.5 is already build with MSVC14, which is excellent news because\r\n 1. MSVC14 already supports C++11 features\r\n 2. Starting with this version of MSVC, the C runtime was split into two parts: a compiler-independent part (the universal runtime) and the compiler dependent part. Future versions of MSVC will rely on the same universal runtime which will make it possible to build extension modules with future versions of MSVC without any concern about the C runtime version. (One more motivation to switch to Python 3.5 !)\r\n\r\nI recommend [this blog post](http://stevedower.id.au/blog/building-for-python-3-5/) by Steve Dower on the adoption of MSVC14 in Python 3.5, the split of the universal C runtime, and the consequences for authors of C extension modules."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'msarahan', 'comment_id': 204176901.0, 'datetime': '2016-03-31 23:44:38+00:00', 'masked_author': 'username_1', 'text': ""@username_6 thanks for the example.  I think that's equivalent to setting the following in meta.yaml:\r\n\r\n```\r\nbuild:\r\n  msvc_compiler: 14.0\r\n```\r\n\r\nThis is not well documented, but went in a while ago: https://github.com/conda/conda-build/pull/600\r\n\r\nAs you mention, one must be careful about allocation and deallocation.  How do you handle that in arbitrary 3rd party extensions?  Do you use any special tools to find where those happen?  Is it a reasonable task for people who are just building packages, rather than developing them?  Can you point to code examples?  Is it something that can be built into conda build, or does it need to be done on a per-recipe basis?\r\n\r\nAnother good article on this topic is http://siomsystems.com/mixing-visual-studio-versions/"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'SylvainCorlay', 'comment_id': 204185202.0, 'datetime': '2016-04-01 00:21:00+00:00', 'masked_author': 'username_6', 'text': 'I think that it is up to the people developing the packages to be careful about it. If they use the right tools to write their extension modules rather than directly calling into the C Python APIs, it should be a automatic. The trick is to use `PyObject_Malloc `, `PyMem_Free`, `PyObject_Delete` etc.  instead of `free`, `malloc` etc...', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 204207723.0, 'datetime': '2016-04-01 02:08:44+00:00', 'masked_author': 'username_2', 'text': ""I wonder if cython does this consistently? But in any case, this isn't\ngoing to help for wrapping C libs not written specifically for Python....\n\nAlso, I thought there were other issues, like sharing objects from the C\nlib -- file pointers for sure, but maybe others?\n\n-CHB\n\n\n\n-- \n\nChristopher Barker, Ph.D.\nOceanographer\n\nEmergency Response Division\nNOAA/NOS/OR&R            (206) 526-6959   voice\n7600 Sand Point Way NE   (206) 526-6329   fax\nSeattle, WA  98115       (206) 526-6317   main reception\n\nanpch@example.com"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'patricksnape', 'comment_id': 204259218.0, 'datetime': '2016-04-01 05:56:54+00:00', 'masked_author': 'username_4', 'text': ""Yes, I'm usually reluctant to discuss the intricacies of the the VS runtimes with package maintainers because it's really quite complicated to get everything working properly. For the average package maintainer, who probably works on Unix and then is just creating Windows builds for their users, this kind of careful runtime handling is probably out of scope. Although it is possible, and clearly @username_6 is an expert and a perfect example of the kind of person who *will* be careful, I prefer to strongly suggest to people that this is the burden of Python 2.7. What better way to increase Python 3.5 adoption than to tell people that they *can't* have Python 2.7 builds because they used C++11 :smile:? Also, it's been a while, but if I remember correctly, even with the new UCRT you don't actually get version independent binaries because any C code will still rely on `vcruntime140.dll`.\r\n\r\nIn terms of Cython, Cython prefers to delegate to `PyObject_*` commands, but the API is there to call `libc` directly in a fairly straightforward manner. So you can't really guarantee someone hasn't allocated using ``malloc/free`. I wonder what `libcffi` is like in this regard..."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ukoethe', 'comment_id': 204317984.0, 'datetime': '2016-04-01 08:59:37+00:00', 'masked_author': 'username_3', 'text': ""Package variants are a natural phenomenon -- users will always request conda to offer certain packages in several variants (for example, we are discussing vectorization instructions and BLAS elsewhere). Thus, conda needs powerful and reliable machinery to manage co-existing variants and to make sure environments remain consistent in their presence. Once such machinery is available, support for a non-standard compiler is simply Yet Another Variant and nothing to worry about. If we give the people concerned the required tools, they will take care of creating the variants they need, and make pull requests to sites like conda-forge so that everyone can profit.\r\n\r\nThus, I'd like to invite all you bright people to make constructive contributions to conda's variant management capabilities. Getting this right would really make a difference. Thank you."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcg1969', 'comment_id': 204439696.0, 'datetime': '2016-04-01 15:34:08+00:00', 'masked_author': 'username_5', 'text': 'I wonder if Conda\'s existing dependency resolution capabilities couldn\'t be hacked to at least _demonstrate_ proper class/variant behavior.\r\n\r\nSuppose we create a metapackage called `blas_variant`; no contents, no dependencies. Instead of version _numbers_, use strings, one for each variant: ""openblas"", ""mkl"", etc. Whenever a package links to a specific BLAS, it includes as a dependency the appropriate version of the `blas_variant` metapackage. Conda\'s natural dependency resolution will prevent multiple versions of `blas_variant` from being installed, and therefore ensure that all packages that use a BLAS in a given environment use the same one.\r\n\r\nOne case I\'d like to handle is that OpenBLAS and MKL are installed in the same environment, but different programs use each. For instance, say Python uses OpenBLAS, and R uses MKL. This is handled using separate variant metapackages for each language; e.g. `r_blas_variant` and `py_blas_variant`. And it also points out that these variant dependencies should _not_ be added to the BLAS libraries themselves. Because they _can_ live alongside each other in theory, conda should not prevent them from doing so.\r\n\r\nSetting aside the obvious aesthetic problems with this approach, does this capture the behavior we\'re looking for? What would its limitations be?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcg1969', 'comment_id': 204442174.0, 'datetime': '2016-04-01 15:42:33+00:00', 'masked_author': 'username_5', 'text': 'And while I _say_ there are obvious aesthetic problems with the approach, that doesn\'t mean we _shouldn\'t_ use metapackages if they provide the right behavior. What we _can_ do is enhance conda to properly _detect_ these types of metapackages and adjust its messaging so that the user better understands what they are and what they do. For instance, there is no such thing as an ""upgrade"" or ""downgrade"" in this case---everything variant change is a ""crossgrade"".', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'SylvainCorlay', 'comment_id': 204607312.0, 'datetime': '2016-04-01 23:30:37+00:00', 'masked_author': 'username_6', 'text': 'I would agree with that.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ukoethe', 'comment_id': 204682526.0, 'datetime': '2016-04-02 09:34:51+00:00', 'masked_author': 'username_3', 'text': 'This is a cool idea, but I have to think about it in more detail.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ukoethe', 'comment_id': 204682797.0, 'datetime': '2016-04-02 09:41:21+00:00', 'masked_author': 'username_3', 'text': 'When Python 3 fails to attract users by its capabilities, and we have to resort to political tricks like ""you won\'t get C++ 11 if you don\'t upgrade"", it\'s nothing to be proud of. Reminds me of Windows 8... :disappointed:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'patricksnape', 'comment_id': 204746343.0, 'datetime': '2016-04-02 16:07:35+00:00', 'masked_author': 'username_4', 'text': ""@username_3 It starts to become a bit of a philosophical debate really! IMHO there isn't any reason to stick with 2.x outside of legacy code. Recompiling the entire Python ecosystem with a new compiler chain just to get C++11 and all of it's benefits seems like a lot more work to me than probably just wrapping some things in `list` and adding some parentheses to `print`! Plus, Python 3.5 *does* have some  really nice things for scientific computing like the `@` operator!"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'pelson', 'comment_id': 204751552.0, 'datetime': '2016-04-02 16:24:19+00:00', 'masked_author': 'username_7', 'text': ""I don't thing we want this thread to descend into a py2 vs py3 debate, so I'm going to steer the ship here :ship: :anchor: :smile: \r\n\r\nI personally haven't seen enough benefit to invest my own cycles on supporting multiple MSVC versions for py27. The core Python devs have clearly made the decision **not** to make a py2 release that supports ``vc14`` out of the box (though I accept they may have been influenced by politics and practicalities of not having a tool like conda at their disposal). For me, that is reason enough to avoid doing it if we can (its the same reason that most patches in recipes should have an upstream issue filed about them) - if we want to influence *how* a piece of software builds, we should do that in the canonical source repository.\r\n\r\nI completely accept though that if there are compelling reasons to do something, then we should consider doing it based on an assessment of benefits, risk, effort, user experience, and appetite for change."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ukoethe', 'comment_id': 204785923.0, 'datetime': '2016-04-02 19:28:22+00:00', 'masked_author': 'username_3', 'text': 'I fully agree. That\'s why I\'d prefer technical arguments over political ones like ""What better way to increase Python 3.5 adoption ..."".', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 204808252.0, 'datetime': '2016-04-02 21:43:45+00:00', 'masked_author': 'username_2', 'text': '<https://github.com/conda-forge/conda-forge.github.io/issues/64#issuecomment-204751552>', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 204811549.0, 'datetime': '2016-04-02 22:18:12+00:00', 'masked_author': 'username_0', 'text': ""Thanks @username_7 for steering. :smile:\r\n\r\nTo clearly state my interests in this issue (and hopefully help keep us out of troubled waters), they are as follows.\r\n\r\n1. See if there is community interest in non-standard Windows CPython builds.\r\n2. See if a prototype can be developed by those interested.\r\n3. Figure out where we go from their (patch CPython, go our own way, build system tweaks, does this require conda changes, etc.)\r\n\r\nOn 1 the answer thus far seems to be some, but maybe not as much as expected (though we could simply just not be reaching the right people). On 2 the answer is yes for one case, but it probably needs to be worked on a bit more with some feedback. As far as 3, it seems we simply aren't there yet and it might be more clear once 2 is discussed more and completed."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 204811742.0, 'datetime': '2016-04-02 22:19:15+00:00', 'masked_author': 'username_0', 'text': ""After @username_2 comment, I found a related [mail thread]( https://mail.python.org/pipermail/python-dev/2013-November/130421.html ) discussing Stackless Python and the need to have a different VS that is not 2008. It's a bit of a long read and covers some of the same ground we have already covered (e.g. the controversial Python 2.8). One interesting suggestion in there, which may or may not be worth pursuing is having VS version [hard-coded in the library names]( https://mail.python.org/pipermail/python-dev/2013-November/130479.html ). This potentially would allow the same CPython distribution to be support with multiple VS versions, but allow for different compilers to be used."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 204817262.0, 'datetime': '2016-04-02 22:53:21+00:00', 'masked_author': 'username_0', 'text': 'There is one important technical challenge to note. Namely the `FILE*` API. See refs below.\r\n\r\n* https://mail.python.org/pipermail/python-dev/2013-November/130459.html\r\n* https://mail.python.org/pipermail/python-dev/2013-November/130487.html\r\n* http://bugs.python.org/issue15883', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 204827030.0, 'datetime': '2016-04-02 23:33:28+00:00', 'masked_author': 'username_0', 'text': 'There were a few other issues (looks like 3) referenced in this [post]( https://mail.python.org/pipermail/python-dev/2013-November/130546.html ) that a Microsoft developer confirmed were it.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 204827721.0, 'datetime': '2016-04-02 23:45:46+00:00', 'masked_author': 'username_0', 'text': ""Well, it looks like the conclusion to be drawn from this is best summarized in this [post]( https://mail.python.org/pipermail/python-dev/2013-November/130599.html ) by the aforementioned Microsoft developer. Basically, the breakage would be too bad to consider using other VCs either for CPython 2.7 or extensions and that it should be prohibited. The remainder of the threader tapers off into stuff that we are not concerned with here before ending.\r\n\r\nSo, maybe the answer here is it would be technically unfeasible to approach this topic, unfortunately. Sorry to get people's hopes up here, but I don't think we are any better equipped to solve this problem. I am going to close this issue as won't fix. Though people are welcome to discuss further."", 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'jakirkham', 'comment_id': None, 'datetime': '2016-04-02 23:45:46+00:00', 'masked_author': 'username_0', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'created', 'author': 'pelson', 'comment_id': 205274530.0, 'datetime': '2016-04-04 12:29:26+00:00', 'masked_author': 'username_7', 'text': 'A healthy debate, and well conducted on all fronts. Thanks to everybody for keeping focussed on the issue and putting time & effort on making your points of view clear and succinct. :+1:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jjhelmus', 'comment_id': 215742892.0, 'datetime': '2016-04-29 14:52:09+00:00', 'masked_author': 'username_8', 'text': 'Is a version of Python is built using a non-standard version of Visual Studio then then ABI tag should be changed so that wheels and other binaries build against a standad VC do not get installed.  See [PEP 425](https://www.python.org/dev/peps/pep-0425/#abi-tag) for details.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mwiebe', 'comment_id': 216712632.0, 'datetime': '2016-05-04 00:57:26+00:00', 'masked_author': 'username_9', 'text': 'I asked about this here: https://github.com/conda-forge/staged-recipes/pull/363#issuecomment-216706895, now found this issue.\r\n\r\nWithin the VFX industry, most of the major tools build Python 2.7 with a non-standard MSVC compiler, and talking to people using many of these tools together, our support of the standard CPython 2.7 in Deadline was actually the only one they had which worked this way. While it may not be recommended by Microsoft/CPython, Autodesk and other large vendors have been doing this for many years.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 217008998.0, 'datetime': '2016-05-04 21:27:57+00:00', 'masked_author': 'username_2', 'text': 'THanks @username_9 -- nice to hear of real field experience. But I\'m confused about what ""it"" is:\r\n\r\n""""""While it may not be recommended by Microsoft/CPython, Autodesk and other large vendors have been doing this for many years.""""\r\n\r\nDo you mean building and distributing extensions to python 2.7 with MSVC 2010 or 2012, and users using them with the standard py2.7 built with VS 2008?\r\n\r\nIn which case, is it simply a matter of making sure that any extensions built this way don\'t share file handles with Python? or are there other gotchas -- and if so, are they documented anywhere? The file handle thing is the only one I know about, but I\'ve heard tell that are arbitrary other corners of the lib where things can go wrong...\r\n\r\nor is ""it"" in this case distributing python itself built with another version of VS? and then extensions to match?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mwiebe', 'comment_id': 217012893.0, 'datetime': '2016-05-04 21:43:32+00:00', 'masked_author': 'username_9', 'text': 'The latter one, ""it"" in this case referred to building and embedding Python 2.7 with MSVC 2012 (or newer), and building extensions to match.\r\n\r\nI think I overstated the Microsoft/CPython recommendation - the thing that is clearly discouraged is building extensions with a different compiler than the Python, but usually it\'s phrased as ""build Python 2.7 plugins with MSVC 2008"" because that\'s what the official CPython is built with. I\'ve tended to break this rule too though, e.g. in DyND where we use C++14 features so require MSVC 2015, and building/linking that against Python 2.7 built with MSVC 2008 *seems* to work fine, as we never transfer memory or handles ownership across the extension boundary.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mwiebe', 'comment_id': 217018335.0, 'datetime': '2016-05-04 22:06:43+00:00', 'masked_author': 'username_9', 'text': ""Defining a particular ABI tag as @username_8 mentions for Python 2.7 with MSVC 2012, Python 2.7 with MSVC 2015, etc that anybody doing such builds could use would be really nice. I'd love to be able to have embedded Python in our applications done this way with conda preinstalled and able to install compatible extensions from conda-forge out of the box, then also have it interact cleanly with `pip` and other mechanisms via that ABI tag."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 217025732.0, 'datetime': '2016-05-04 22:42:51+00:00', 'masked_author': 'username_2', 'text': 'This came up on the python-dev list a year or so ago (I think).\n\nThe Stackless folks proposed release=ing a 2.8 that would be the same\nexcept it would be compiled with a newer MS compiler. THis was rejected\nbecause it really makes NO sense to call something a different python\nversion just because it\'s a different compiler -- after all, python on\nLinux, and Mac, and ... are all called Python 2.7 -- and they are not the\nleast binary compatible.\n\nWhat I don\'t remember is why the ABI tag idea wasn\'t proposed (or wasn\'t\nadopted) -- that would be easy and robust. But maybe it was that python.org\ndidn\'t want to host two builds of the same python version for Windows that\nwere incompatible.\n\nThe whole conda machinery does make all that easier -- though you would\nstill have the same problem -- when you selected a pyton 2.7 for Windows\nyou\'d need to choose which one, and then there would be different binary\npackages available depending on which one you\'d choose -- kinda confusing\nto the community in general, but maybe good for a ""curated"" system.\n\n-CHB', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Supporting non-standard CPython VC builds on Windows
username_0: The current system of having the version Windows' MSVC tied to the CPython is troublesome for people in some cases. In particular, with respect to cases where people needed the latest compiler features (e.g. C++11 features). There may be other relevant cases, as well. The main purpose of this issue is to suggest that we include some (maybe even just one) compilation of a non-standard CPython VC build on Windows to simplify things for the conda community. Of course, making this change could disrupt the current feature landscape of Windows CPython so needs some thought on that point. This issue is also opened to get feedback from the conda community to determine which non-standard CPython VC builds would be valuable and thus be worthwhile to support. At present, I am thinking a `vc14` (i.e. Visual Studio 2015) variant of CPython 2.7.x (where x will always be latest) is almost certainly worthwhile just to get C++11 support. Though am not sure if there are other worthwhile non-standard variants to consider.

cc @username_3 @jasongrout @username_6 @username_1 @username_5
<issue_comment>username_1: This obviously comes with a huge YMMV, but would be helpful to a lot of people.  You could have installers like what @username_8 did with ACPD: https://github.com/acpd/acpd

A lot of people will probably get very confused by incompatible software, but we just need to document what this is and is not very, very clearly.
<issue_comment>username_0: Absolutely. This would also be a very hands on endeavor that would really need community involvement to be successful.
<issue_comment>username_0: Once we nail down which non-standard variant could be reasonably supported here and what accommodations may be needed in conda/conda-build. We may need to revisit the AppVeyor build matrix to include this logic there. That way, we can do a better job at providing things that will play nice together.
<issue_comment>username_2: This is a very big deal, actually. Not to be taken lightly at all!

key is that it would essentially be a different platform. You'd have Windows 32 and 64 bit (confusing enough for some folks), and now multiple versions of those. Though I suppose we'd really only need to support Py27 on Windows64.  Py3.5 is already using MSVS2015.

But one of the nice things about conda (and Anaconda) is that the binaries are compatible with the python.org ones, so that pip install also works. We'd have to make sure that someone running the MSVS2015 build couldn't accidentally get an incompatible binary from PyPI, (Or anywhere else).

Also -- we'd then need to build everything in the default channel, too.....

-CHB
<issue_comment>username_0: It was sort of my impression that we are doing this anyways. So, this might be the one part that is not a problem. The only part to work on here would be to add this to our Windows build matrix. Though this is many steps later.
<issue_comment>username_2: well, there are a number of platforms -- one of them is win-64 -- due to its Python roots, I assume that conda assumes that that means the VS2008 run-time C lib as well -- obviously for Python, but also for any shared libraries. So I think the way to do this would be to create a new platfrom, not another python variant.

win-64-15 ????

I have no idea how hard-coded the various platforms are in the whole conda / anaconda ecosystem -- is it hard to add a new one?

(also, it would be a bit unfortunate, as pure python libs, etc would all need separate builds...)

But I just had a realization -- py2.7 and py3.5 currently use different run times, so shared libs that re going to be used with python should be built differently -- how in the world is that dealt with now???

-CHB
<issue_comment>username_2: I don't know how hard / possible it is to disallow binary wheels with a given pip install (and someone could install pip themselves from source, etc....)

probably what you'd want to do is make sure the platform tag used by python (and therefor found by pip) was unique.

But The core python devs are not going to build a Python with a new MS compiler because of all this pain, and because py2.7 is a dead end -- it has always worked better to simiply use a newer compiler when you have a newer version --a nd there is not going to be a newer version of 2.7.

IN fact, the stackless folks were pushing for a 2.8 that was the same except for the MS compiler used to build it -- that was not accepted as a reasonable option.

So maybe it's time to just say -- if you want modern C++, then you should use a modern Python, too.

I know, tough love!
<issue_comment>username_3: No, this problem can be solved with `features` (subject to a fix in the version resolution algorithm that went into conda 4.0). Suppose there is a package `vc11-runtime` that contains a declaration `track_features: - vc11`. Then, users can tell conda to use Visual Studio 2012 by simply installing that package first:
```
conda create  -n python-vc11  vc11-runtime  python=2.7 ...
```
conda will now prefer package variants that contain a `features: - vc11` declaration over those that don't. So, simply put that declaration into packages compiled with vc11, and let conda figure out the rest.
<issue_comment>username_0: If we use an even more recent compiler for this sort of endeavor, would that still work for you, @username_3?
<issue_comment>username_3: Yes, but I haven't checked if there are any hidden difficulties along the way. 
(For example: I use `devenv PCbuild.sln /upgrade` to update Python's official project files to the new compiler version. Will this command still work as desired for VS 2015?)
<issue_comment>username_3: This is indeed a problem when using a non-standard compiler. However, one could easily add a warning to conda's pip module saying that pip downloads may be incompatible with the current environment when a non-standard compiler was used.

On the other hand, conda *exists* because pip's support for compiled modules with complicated C/C++ dependencies was insufficient. People familiar with conda will probably use pip only for simple things like pure Python modules (where the compiler doesn't matter), and wouldn't be surprised if pip failed for more complicated stuff.
<issue_comment>username_2: yeah, I guess that's the trick -- I would be more or less happy to tell anyone writing a package that needs C++11 to use py3, but then you've got other stuff you want to use that isn't py3 ready ( :-( ). I sure wish everyone used Cython -- then the py3 port would be pretty easy.

Honestly, though I still think we'l all need to go to py3 some day -- the more reasons to support that the better.
<issue_comment>username_2: I still don't ""get"" features, but if so -- great.

but it sounds risky -- conda will prefer packages with the feature, but I take it it will allow packages that don't have it -- which is the vast majority of compiled packages -- so it would be very easy for a user to get an incompatible package -even without pip.

It still seems to me that you'd want this to be a different platform -- or maybe a different python version.

call it py28 -- against the wishes of the core devs :-)

But I'll leave that to the conda experts -- you may be right.
<issue_comment>username_0: @username_4, I forgot to cc you on this. Sorry about that. Maybe of some interest to you.
<issue_comment>username_4: Although my gut is that I'm against this :stuck_out_tongue_closed_eyes: I understand @username_3's pain about scientific packaging. Ideally the response would be to upgrade those projects so that they work on Python 3.5 and then use Python 3.x so you get a compliant compiler. However, as I said, I totally understand that we are all busy and that is often impractical. Though someone will have to do it before 2019!

I would throw my weight behind the features option - since any code without compiled extensions doesn't actually care about the Visual Studio version that was used to build it. Any conda-forge code should have the correct feature set anyway so that won't be a problem. I **strongly** urge against Python 2.8.

In terms of `pip`, as @username_0 mentioned, the whole point of conda was to try and standardise a lot of these issues. Given the lack of community around providing wheels, I doubt that a lot of wheels being provided by anyone other than Christoph Gohlke are actually being careful about which compiler is used. Therefore, I would say that we document against using wheels and always prefer the `pip` install without wheels option when using conda on Windows.
<issue_comment>username_3: Another important point in support of this option is that features (or some yet-to-be-defined alternative) are needed for a number of other legitimate configurations anyway (Python version, BLAS variant, AVX acceleration, ...). Then, adding a compiler feature is not such a big deal -- it only makes the build matrix a bit bigger and requires build scripts to be a bit more portable. I don't expect this to be very complicated once the first compiler on a given platform works.

Of course, I agree that in an ideal world, all packages should support the newest Python version.
<issue_comment>username_0: We already use different compilers with Windows. My concern from earlier involves changes to the `meta.yaml`, which I know you have already spent some time thinking about. Maybe worth sharing. :wink:
<issue_comment>username_2: Another important point in support of this option is that features (or some
yet-to-be-defined alternative) are needed for a number of other legitimate
configurations anyway (Python version, BLAS variant, AVX acceleration, ...).

Things like BLAS are only required by, well, things that require BLAS.

The compiler used (or, more to the point, the runtime used) effects every
compiled extension. And there are a LOT of complied extensions in the
default channel, not to mention wheels ( which we could say ""Don't do that""
about those)

I'm just not sure that features provide a robust solution to this problem.
But if they do, great.

One of the challenges is that if you mix run times, it generally won't fail
right away (or may not fail at all)

-CHB
<issue_comment>username_5: I dropped out of this conversation, so I know I might either be repeating something already said or missing context---_but_, the more I think about it the more I believe that cleaning our our channel collision problem---that is, two different channels providing the same package---is going to solve a lot of problems, like this one.

Handling a version of Python compiled with a non-standard compiler is really no different than having to differentiate between 32-bit and 64-bit builds. Hence: each unique CPython needs to be in its own channel, and we need to make sure that those channels don't stomp on each other. Whatever channel is highest priority wins.
<issue_comment>username_5: There are too many things being blocked by conda's inability to handle channel conflicts properly. Time to expedite that fix.
<issue_comment>username_3: Interesting. Two questions:

* When your idea gets implemented, how will a user create an environment that uses a non-standard compiler?
* Apparently, you arrived at the conclusion that `features` are not the right solution to the compiler configuration problem. Could you explain why?
<issue_comment>username_5: Features are proving vexing to implement in a consistent manner with behavior that everyone is satisfied with. 

For instance: what should take priority, the presence of a feature, or a higher version number? For instance, suppose we have the `mkl` feature in an environment, and we run `conda install numpackage`. Further suppose that `numpackage 1.0` uses the `mkl` feature, whereas `numpackage 2.0` does not. What should be preferred? There is merit in both choices, but currently we choose the latter. And that's not likely to change since the `mkl` -> `nomkl` transition depends on it. 

Furthermore, I don't think features alone address some of the mutual exclusion requirements that things like compiler versions will need. For example, if we use a feature to specify a particular compiler version, how do we prevent packages that were compiled with a _different_ compiler are not installed?

I don't want to say that I've definitively concluded that features aren't at least part of the solution. But if you had been in my shoes the last couple of months you wouldn't be as reluctant as I am to pronounce them the solution.
<issue_comment>username_5: Continuing the `numpackage` example. Suppose we had two channels, `openblas/` and `mkl/`, each populated with exactly the same packages, except as needed to link to their respective BLAS libraries. Perhaps `numpackage 2.0` is only in `openblas`; an MKL version hasn't been built yet.

With the current regime, `conda update numpackage` is going to pull the OpenBLAS version, whether the user wants it or not. With two separate channels, and proper collision avoidance, an MKL user will never accidentally install the OpenBLAS version.
<issue_comment>username_3: IMHO, the use of a feature should be preferred. If I'm not mistaken, that's what the new version resolution algorithm in conda 4.0 implements, no? (My preliminary tests of conda 4.0 seem to confirm this.)  And it's also the effect of using different channels, if I interpret your `openblas` vs. `mkl` example correctly.
<issue_comment>username_5: Everything I just described above regarding features is 4.0 --- including the problems. I'm simply not convinced they fully solve the problems you're hoping they will, and I think it will be far too easy to create environments with conflicting packages without _some_ further enhancements.
<issue_comment>username_2: I recall some talk about a way to specify platform-independent packages --
i.e. pure python packages don't need to be any different on Linux vs
Windows vs OS-X.

IF we could get that working, then Win-VC2105 could be a different
platform, and folks could still get pure python packages from the other
platforms.

Of course, they couldn't get compiled packages that have nothing to do with
python without re-building them....

This is a pain -- thank you MS!

-Chris
<issue_comment>username_1: We do have noarch builds, but they're sort of error-prone (https://github.com/ContinuumIO/anaconda-issues/issues/730) and not widely used.
<issue_comment>username_6: Sorry for jumping in so late.

I think that it would be a very bad idea to make a MSVC14 build of python for all the reasons mentioned earlier with respect to the ability to install binary wheels from pip that would then *not* be binary compatible.

Besides, it is actually possible to build C extension modules with more recent versions for MSVC than the one used to build Python itself. The one thing that one must be cautious to use the MSVC8 C runtime when allocating or de-allocating objects passed or received from Python.

Actually, I am doing so (forcing the use of MSVC14 to build python 2.7 extension) in the case of extension modules built with [pybind11](https://github.com/pybind/pybind11/). Pybind11 (authored by @wjakob) has similar goals to `boost.python` but is C++11-only and therefore requires msvc14 on windows.

@username_0 I made an example project [here](https://github.com/pybind/pbtest), built with pybind11, which comes with a conda recipe. The conda recipe's `bld.bat` does the magic of forcing MSVC14 for the build. You can also notice that I was careful to include the MSVC14 runtime as a runtime dependency to the conda package's meta.yml.

Finally, Python 3.5 is already build with MSVC14, which is excellent news because
 1. MSVC14 already supports C++11 features
 2. Starting with this version of MSVC, the C runtime was split into two parts: a compiler-independent part (the universal runtime) and the compiler dependent part. Future versions of MSVC will rely on the same universal runtime which will make it possible to build extension modules with future versions of MSVC without any concern about the C runtime version. (One more motivation to switch to Python 3.5 !)

I recommend [this blog post](http://stevedower.id.au/blog/building-for-python-3-5/) by Steve Dower on the adoption of MSVC14 in Python 3.5, the split of the universal C runtime, and the consequences for authors of C extension modules.
<issue_comment>username_1: @username_6 thanks for the example.  I think that's equivalent to setting the following in meta.yaml:

```
build:
  msvc_compiler: 14.0
```

This is not well documented, but went in a while ago: https://github.com/conda/conda-build/pull/600

As you mention, one must be careful about allocation and deallocation.  How do you handle that in arbitrary 3rd party extensions?  Do you use any special tools to find where those happen?  Is it a reasonable task for people who are just building packages, rather than developing them?  Can you point to code examples?  Is it something that can be built into conda build, or does it need to be done on a per-recipe basis?

Another good article on this topic is http://siomsystems.com/mixing-visual-studio-versions/
<issue_comment>username_6: I think that it is up to the people developing the packages to be careful about it. If they use the right tools to write their extension modules rather than directly calling into the C Python APIs, it should be a automatic. The trick is to use `PyObject_Malloc `, `PyMem_Free`, `PyObject_Delete` etc.  instead of `free`, `malloc` etc...
<issue_comment>username_2: I wonder if cython does this consistently? But in any case, this isn't
going to help for wrapping C libs not written specifically for Python....

Also, I thought there were other issues, like sharing objects from the C
lib -- file pointers for sure, but maybe others?

-CHB



-- 

Christopher Barker, Ph.D.
Oceanographer

Emergency Response Division
NOAA/NOS/OR&R            (206) 526-6959   voice
7600 Sand Point Way NE   (206) 526-6329   fax
Seattle, WA  98115       (206) 526-6317   main reception

Chris.Barker@noaa.gov
<issue_comment>username_4: Yes, I'm usually reluctant to discuss the intricacies of the the VS runtimes with package maintainers because it's really quite complicated to get everything working properly. For the average package maintainer, who probably works on Unix and then is just creating Windows builds for their users, this kind of careful runtime handling is probably out of scope. Although it is possible, and clearly @username_6 is an expert and a perfect example of the kind of person who *will* be careful, I prefer to strongly suggest to people that this is the burden of Python 2.7. What better way to increase Python 3.5 adoption than to tell people that they *can't* have Python 2.7 builds because they used C++11 :smile:? Also, it's been a while, but if I remember correctly, even with the new UCRT you don't actually get version independent binaries because any C code will still rely on `vcruntime140.dll`.

In terms of Cython, Cython prefers to delegate to `PyObject_*` commands, but the API is there to call `libc` directly in a fairly straightforward manner. So you can't really guarantee someone hasn't allocated using ``malloc/free`. I wonder what `libcffi` is like in this regard...
<issue_comment>username_3: Package variants are a natural phenomenon -- users will always request conda to offer certain packages in several variants (for example, we are discussing vectorization instructions and BLAS elsewhere). Thus, conda needs powerful and reliable machinery to manage co-existing variants and to make sure environments remain consistent in their presence. Once such machinery is available, support for a non-standard compiler is simply Yet Another Variant and nothing to worry about. If we give the people concerned the required tools, they will take care of creating the variants they need, and make pull requests to sites like conda-forge so that everyone can profit.

Thus, I'd like to invite all you bright people to make constructive contributions to conda's variant management capabilities. Getting this right would really make a difference. Thank you.
<issue_comment>username_5: I wonder if Conda's existing dependency resolution capabilities couldn't be hacked to at least _demonstrate_ proper class/variant behavior.

Suppose we create a metapackage called `blas_variant`; no contents, no dependencies. Instead of version _numbers_, use strings, one for each variant: ""openblas"", ""mkl"", etc. Whenever a package links to a specific BLAS, it includes as a dependency the appropriate version of the `blas_variant` metapackage. Conda's natural dependency resolution will prevent multiple versions of `blas_variant` from being installed, and therefore ensure that all packages that use a BLAS in a given environment use the same one.

One case I'd like to handle is that OpenBLAS and MKL are installed in the same environment, but different programs use each. For instance, say Python uses OpenBLAS, and R uses MKL. This is handled using separate variant metapackages for each language; e.g. `r_blas_variant` and `py_blas_variant`. And it also points out that these variant dependencies should _not_ be added to the BLAS libraries themselves. Because they _can_ live alongside each other in theory, conda should not prevent them from doing so.

Setting aside the obvious aesthetic problems with this approach, does this capture the behavior we're looking for? What would its limitations be?
<issue_comment>username_5: And while I _say_ there are obvious aesthetic problems with the approach, that doesn't mean we _shouldn't_ use metapackages if they provide the right behavior. What we _can_ do is enhance conda to properly _detect_ these types of metapackages and adjust its messaging so that the user better understands what they are and what they do. For instance, there is no such thing as an ""upgrade"" or ""downgrade"" in this case---everything variant change is a ""crossgrade"".
<issue_comment>username_6: I would agree with that.
<issue_comment>username_3: This is a cool idea, but I have to think about it in more detail.
<issue_comment>username_3: When Python 3 fails to attract users by its capabilities, and we have to resort to political tricks like ""you won't get C++ 11 if you don't upgrade"", it's nothing to be proud of. Reminds me of Windows 8... :disappointed:
<issue_comment>username_4: @username_3 It starts to become a bit of a philosophical debate really! IMHO there isn't any reason to stick with 2.x outside of legacy code. Recompiling the entire Python ecosystem with a new compiler chain just to get C++11 and all of it's benefits seems like a lot more work to me than probably just wrapping some things in `list` and adding some parentheses to `print`! Plus, Python 3.5 *does* have some  really nice things for scientific computing like the `@` operator!
<issue_comment>username_7: I don't thing we want this thread to descend into a py2 vs py3 debate, so I'm going to steer the ship here :ship: :anchor: :smile: 

I personally haven't seen enough benefit to invest my own cycles on supporting multiple MSVC versions for py27. The core Python devs have clearly made the decision **not** to make a py2 release that supports ``vc14`` out of the box (though I accept they may have been influenced by politics and practicalities of not having a tool like conda at their disposal). For me, that is reason enough to avoid doing it if we can (its the same reason that most patches in recipes should have an upstream issue filed about them) - if we want to influence *how* a piece of software builds, we should do that in the canonical source repository.

I completely accept though that if there are compelling reasons to do something, then we should consider doing it based on an assessment of benefits, risk, effort, user experience, and appetite for change.
<issue_comment>username_3: I fully agree. That's why I'd prefer technical arguments over political ones like ""What better way to increase Python 3.5 adoption ..."".
<issue_comment>username_2: <https://github.com/conda-forge/conda-forge.github.io/issues/64#issuecomment-204751552>
<issue_comment>username_0: Thanks @username_7 for steering. :smile:

To clearly state my interests in this issue (and hopefully help keep us out of troubled waters), they are as follows.

1. See if there is community interest in non-standard Windows CPython builds.
2. See if a prototype can be developed by those interested.
3. Figure out where we go from their (patch CPython, go our own way, build system tweaks, does this require conda changes, etc.)

On 1 the answer thus far seems to be some, but maybe not as much as expected (though we could simply just not be reaching the right people). On 2 the answer is yes for one case, but it probably needs to be worked on a bit more with some feedback. As far as 3, it seems we simply aren't there yet and it might be more clear once 2 is discussed more and completed.
<issue_comment>username_0: After @username_2 comment, I found a related [mail thread]( https://mail.python.org/pipermail/python-dev/2013-November/130421.html ) discussing Stackless Python and the need to have a different VS that is not 2008. It's a bit of a long read and covers some of the same ground we have already covered (e.g. the controversial Python 2.8). One interesting suggestion in there, which may or may not be worth pursuing is having VS version [hard-coded in the library names]( https://mail.python.org/pipermail/python-dev/2013-November/130479.html ). This potentially would allow the same CPython distribution to be support with multiple VS versions, but allow for different compilers to be used.
<issue_comment>username_0: There is one important technical challenge to note. Namely the `FILE*` API. See refs below.

* https://mail.python.org/pipermail/python-dev/2013-November/130459.html
* https://mail.python.org/pipermail/python-dev/2013-November/130487.html
* http://bugs.python.org/issue15883
<issue_comment>username_0: There were a few other issues (looks like 3) referenced in this [post]( https://mail.python.org/pipermail/python-dev/2013-November/130546.html ) that a Microsoft developer confirmed were it.
<issue_comment>username_0: Well, it looks like the conclusion to be drawn from this is best summarized in this [post]( https://mail.python.org/pipermail/python-dev/2013-November/130599.html ) by the aforementioned Microsoft developer. Basically, the breakage would be too bad to consider using other VCs either for CPython 2.7 or extensions and that it should be prohibited. The remainder of the threader tapers off into stuff that we are not concerned with here before ending.

So, maybe the answer here is it would be technically unfeasible to approach this topic, unfortunately. Sorry to get people's hopes up here, but I don't think we are any better equipped to solve this problem. I am going to close this issue as won't fix. Though people are welcome to discuss further.<issue_closed>
<issue_comment>username_7: A healthy debate, and well conducted on all fronts. Thanks to everybody for keeping focussed on the issue and putting time & effort on making your points of view clear and succinct. :+1:
<issue_comment>username_8: Is a version of Python is built using a non-standard version of Visual Studio then then ABI tag should be changed so that wheels and other binaries build against a standad VC do not get installed.  See [PEP 425](https://www.python.org/dev/peps/pep-0425/#abi-tag) for details.
<issue_comment>username_9: I asked about this here: https://github.com/conda-forge/staged-recipes/pull/363#issuecomment-216706895, now found this issue.

Within the VFX industry, most of the major tools build Python 2.7 with a non-standard MSVC compiler, and talking to people using many of these tools together, our support of the standard CPython 2.7 in Deadline was actually the only one they had which worked this way. While it may not be recommended by Microsoft/CPython, Autodesk and other large vendors have been doing this for many years.
<issue_comment>username_2: THanks @username_9 -- nice to hear of real field experience. But I'm confused about what ""it"" is:

""""""While it may not be recommended by Microsoft/CPython, Autodesk and other large vendors have been doing this for many years.""""

Do you mean building and distributing extensions to python 2.7 with MSVC 2010 or 2012, and users using them with the standard py2.7 built with VS 2008?

In which case, is it simply a matter of making sure that any extensions built this way don't share file handles with Python? or are there other gotchas -- and if so, are they documented anywhere? The file handle thing is the only one I know about, but I've heard tell that are arbitrary other corners of the lib where things can go wrong...

or is ""it"" in this case distributing python itself built with another version of VS? and then extensions to match?
<issue_comment>username_9: The latter one, ""it"" in this case referred to building and embedding Python 2.7 with MSVC 2012 (or newer), and building extensions to match.

I think I overstated the Microsoft/CPython recommendation - the thing that is clearly discouraged is building extensions with a different compiler than the Python, but usually it's phrased as ""build Python 2.7 plugins with MSVC 2008"" because that's what the official CPython is built with. I've tended to break this rule too though, e.g. in DyND where we use C++14 features so require MSVC 2015, and building/linking that against Python 2.7 built with MSVC 2008 *seems* to work fine, as we never transfer memory or handles ownership across the extension boundary.
<issue_comment>username_9: Defining a particular ABI tag as @username_8 mentions for Python 2.7 with MSVC 2012, Python 2.7 with MSVC 2015, etc that anybody doing such builds could use would be really nice. I'd love to be able to have embedded Python in our applications done this way with conda preinstalled and able to install compatible extensions from conda-forge out of the box, then also have it interact cleanly with `pip` and other mechanisms via that ABI tag.
<issue_comment>username_2: This came up on the python-dev list a year or so ago (I think).

The Stackless folks proposed release=ing a 2.8 that would be the same
except it would be compiled with a newer MS compiler. THis was rejected
because it really makes NO sense to call something a different python
version just because it's a different compiler -- after all, python on
Linux, and Mac, and ... are all called Python 2.7 -- and they are not the
least binary compatible.

What I don't remember is why the ABI tag idea wasn't proposed (or wasn't
adopted) -- that would be easy and robust. But maybe it was that python.org
didn't want to host two builds of the same python version for Windows that
were incompatible.

The whole conda machinery does make all that easier -- though you would
still have the same problem -- when you selected a pyton 2.7 for Windows
you'd need to choose which one, and then there would be different binary
packages available depending on which one you'd choose -- kinda confusing
to the community in general, but maybe good for a ""curated"" system.

-CHB"
open-telemetry/opentelemetry.io,809793552,411,,"[{'action': 'opened', 'author': 'flands', 'comment_id': None, 'datetime': '2021-02-17 02:13:46+00:00', 'masked_author': 'username_0', 'text': 'Two changes required:\r\n\r\n- `OT Library` should be `OTel Library`\r\n- `Otel Collector` should be `OTel Collector`\r\n\r\nsource: https://github.com/open-telemetry/opentelemetry.io/blob/main/iconography/Reference_Architecture.svg\r\n\r\n@username_1 FYI', 'title': 'Use of OTel in reference architecture images', 'type': 'issue'}
 {'action': 'created', 'author': 'jkowall', 'comment_id': 780551491.0, 'datetime': '2021-02-17 13:21:12+00:00', 'masked_author': 'username_1', 'text': 'Thanks! Can get those changed.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Ella-bz', 'comment_id': 781216456.0, 'datetime': '2021-02-18 09:41:31+00:00', 'masked_author': 'username_2', 'text': '<img width=""784"" alt=""Reference Architecture@2x"" src=""https://user-images.githubusercontent.com/73476445/108337814-34f3bf80-71de-11eb-9854-860bc1aca34c.png"">\r\nfixed', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jkowall', 'comment_id': 781299712.0, 'datetime': '2021-02-18 12:10:34+00:00', 'masked_author': 'username_1', 'text': 'Thanks @username_2!\r\n\r\n@username_0 do you want the icon images updated from the zip too?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'flands', 'comment_id': 781471752.0, 'datetime': '2021-02-18 16:34:36+00:00', 'masked_author': 'username_0', 'text': 'yes please!', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mnadeem', 'comment_id': 785236535.0, 'datetime': '2021-02-24 17:19:26+00:00', 'masked_author': 'username_3', 'text': 'I have tried doing something similar with **Microsoft power point** it is not as classy as the one above :( \r\n\r\n![image](https://user-images.githubusercontent.com/476145/109039153-79a5bc00-76f2-11eb-84c5-fbe3c1c22779.png)\r\n\r\n\r\n[OTel.pptx](https://github.com/open-telemetry/opentelemetry.io/files/6037710/OTel.pptx)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mnadeem', 'comment_id': 785635320.0, 'datetime': '2021-02-25 05:58:25+00:00', 'masked_author': 'username_3', 'text': 'Did something similar for other image as well, attaching it so that it could be reused by community.\r\n\r\n![image](https://user-images.githubusercontent.com/476145/109109953-3b44e700-775c-11eb-98ff-08a25f731fbb.png)\r\n\r\n[OTel.pptx](https://github.com/open-telemetry/opentelemetry.io/files/6040795/OTel.pptx)\r\n\r\nGlad That I have learnt creating nice ppt from community as I have learned java, Javascript and Go :)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jkowall', 'comment_id': 785852179.0, 'datetime': '2021-02-25 12:14:01+00:00', 'masked_author': 'username_1', 'text': 'Here is a new ppt from @username_2 https://docs.google.com/presentation/d/19woronewjAZT1GF0jgbr0XaTh9_x8DrnyhqyGD2OGLI/edit?usp=sharing', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jkowall', 'comment_id': 899798864.0, 'datetime': '2021-08-16 20:30:19+00:00', 'masked_author': 'username_1', 'text': 'The design is in Figma if you want to have access to it there that is possible. https://www.figma.com/file/PZ1zSzBeNOjJkHTbmRSEcK/Materials-(pics%2C-screens-etc.)?node-id=378%3A0 \r\n\r\nI can export it if you want, or we can ask Ella for changes.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'chalin', 'comment_id': 899808967.0, 'datetime': '2021-08-16 20:49:46+00:00', 'masked_author': 'username_4', 'text': ""Thanks for the link! (Who owns the file?)\r\n\r\nAs far as I can tell, the changes were made, and it seems like I can export the SVG, so I'll submit a PR soon."", 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'chalin', 'comment_id': None, 'datetime': '2021-08-16 23:07:51+00:00', 'masked_author': 'username_4', 'text': '', 'title': None, 'type': 'issue'}]","<issue_start><issue_comment>Title: Use of OTel in reference architecture images
username_0: Two changes required:

- `OT Library` should be `OTel Library`
- `Otel Collector` should be `OTel Collector`

source: https://github.com/open-telemetry/opentelemetry.io/blob/main/iconography/Reference_Architecture.svg

@username_1 FYI
<issue_comment>username_1: Thanks! Can get those changed.
<issue_comment>username_2: <img width=""784"" alt=""Reference Architecture@2x"" src=""https://user-images.githubusercontent.com/73476445/108337814-34f3bf80-71de-11eb-9854-860bc1aca34c.png"">
fixed
<issue_comment>username_1: Thanks @username_2!

@username_0 do you want the icon images updated from the zip too?
<issue_comment>username_0: yes please!
<issue_comment>username_3: I have tried doing something similar with **Microsoft power point** it is not as classy as the one above :( 

![image](https://user-images.githubusercontent.com/476145/109039153-79a5bc00-76f2-11eb-84c5-fbe3c1c22779.png)


[OTel.pptx](https://github.com/open-telemetry/opentelemetry.io/files/6037710/OTel.pptx)
<issue_comment>username_3: Did something similar for other image as well, attaching it so that it could be reused by community.

![image](https://user-images.githubusercontent.com/476145/109109953-3b44e700-775c-11eb-98ff-08a25f731fbb.png)

[OTel.pptx](https://github.com/open-telemetry/opentelemetry.io/files/6040795/OTel.pptx)

Glad That I have learnt creating nice ppt from community as I have learned java, Javascript and Go :)
<issue_comment>username_1: Here is a new ppt from @username_2 https://docs.google.com/presentation/d/19woronewjAZT1GF0jgbr0XaTh9_x8DrnyhqyGD2OGLI/edit?usp=sharing
<issue_comment>username_1: The design is in Figma if you want to have access to it there that is possible. https://www.figma.com/file/PZ1zSzBeNOjJkHTbmRSEcK/Materials-(pics%2C-screens-etc.)?node-id=378%3A0 

I can export it if you want, or we can ask Ella for changes.
<issue_comment>username_4: Thanks for the link! (Who owns the file?)

As far as I can tell, the changes were made, and it seems like I can export the SVG, so I'll submit a PR soon.<issue_closed>"
