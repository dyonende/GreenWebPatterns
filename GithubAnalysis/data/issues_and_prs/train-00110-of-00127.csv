dlang/dlang.org,287530820,2074,"{'number': 2074.0, 'repo': 'dlang.org', 'user_login': 'dlang'}","[{'action': 'opened', 'author': 'JackStouffer', 'comment_id': None, 'datetime': '2018-01-10T18:20:08Z', 'masked_author': 'username_0', 'text': 'Changed the design of the front page to leverage social proof to increase conversions (reducing bounce and increasing clicking on ""download"" and ""learn"").\r\n\r\n## Rationale\r\n\r\nSocial proof is an extremely powerful way to convince people to spend time on the web or to build trust, where 70% of people say they trust the recommendation of a random stranger online in things like reviews and 92% trust a recommendation from anyone they know [1]. In our case, we don\'t have strangers, but a brands like Netflix or eBay which the visitor might trust already. This gives close to the same effect as someone hearing that a friend uses something.\r\n\r\nHerein lies the problem: most people don\'t see our social proof. Only 22% of people scroll down to the bottom of webpages on average [2], right where the ""Organizations Using D"" is currently located.\r\n\r\nFurther, the first ten seconds are the most important in retaining users on a page, with a focus on the first two seconds [3]. So combined with the scrolling data we have, it\'s prudent to use your most convincing arguments ""above the fold"". Keeping the social proof above the 600px mark hits the user right when they are trying to decide if they want to stay on the site.\r\n\r\nWith that in mind, here\'s a preview of the changes:\r\n\r\n<img width=""1280"" alt=""screen shot 2018-01-10 at 1 15 32 pm"" src=""https://user-images.githubusercontent.com/680068/34788398-72353cf2-f608-11e7-8e04-5f385ff5e4c0.png"">\r\n\r\nIn order to best capture the attention of the user in these ten seconds, this design works off of the ""Z pattern"", which puts the most important things on the page in a Z above the fold [4]. The reasoning is that from eye tracking software, it was discovered that people\'s eyes skim the entire screen when they first open a page. They either go in a F across the screen, or a Z [5]. The Z pattern puts the most important things on the four points of a Z, in our page, this would be the download button (which is now emphasized), the code example, and the organizations across the bottom.\r\n\r\n<img width=""1280"" alt=""screen shot 2018-01-09 at 4 52 05 pm"" src=""https://user-images.githubusercontent.com/680068/34788408-7b1fef74-f608-11e7-8ffe-010670d0e4bd.png"">\r\n\r\nThis change also has the added benefit of helping to alleviate one of the perceived shortcomings of D is its adoption by the industry [6]. This claim is both true and false. It\'s not up to the same adoption of say, Go, but it\'s still being used. This change focuses on adoption better.\r\n\r\n## What Exactly Has Been Changed\r\n\r\n* Moved ""Orgs using D"" to the top of the page under the intro\r\n* Changed which organizations are displayed and the order to show the most well known brands first\r\n* Increased whitespace on intro to declutter first impression so the user sees just the intro and the social proof\r\n* Changed the color of the download button to focus on the call to action\r\n\r\n## The Scientific Approach\r\n\r\nWhile I believe this will increase conversions, you don\'t have to take my word for it. If we were to integrate Google Analytics (even temporarily just for this experiment if people don\'t like it), then we can use it to A/B test this change.\r\n\r\nEssentially what happens is you have a control page (the current front page) and a modified page (these changes). When a user loads dlang.org they are randomly assigned one or the other and given a cookie to make sure they don\'t see the other version on reload.  GA then tracks the differences in behavior between the control group and the experiment group over a period of time (say three weeks). At the end of the experiment, we could see the differences in initial bounce or going to the documentation or downloads page.\r\n\r\nThis would give us an objective measure to decide if we should adopt this or not.\r\n\r\n### Sources\r\n\r\n[1] http://www.nielsen.com/us/en/insights/news/2012/trust-in-advertising--paid-owned-and-earned.html\r\n[2] https://www.clicktale.com/resources/blog/resourcesbloginvest-in-customer-experience-software/\r\n[3] https://www.nngroup.com/articles/how-long-do-users-stay-on-web-pages/\r\n[4] https://instapage.com/blog/z-pattern-layout\r\n[5] https://99designs.com/blog/tips/visual-hierarchy-landing-page-designs/\r\n[6] https://www.quora.com/Which-language-has-the-brightest-future-in-replacement-of-C-between-D-Go-and-Rust-And-Why/answer/Andrei-Alexandrescu', 'title': 'Change Front Page to Focus on Call to Action and Social Proof', 'type': 'issue'}
 {'action': 'created', 'author': 'CyberShadow', 'comment_id': 356799943.0, 'datetime': '2018-01-11 01:59:19+00:00', 'masked_author': 'username_1', 'text': 'Looks good! I think @username_3 wants to OK all index changes though.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'wilzbach', 'comment_id': 356800494.0, 'datetime': '2018-01-11 02:02:11+00:00', 'masked_author': 'username_2', 'text': 'FYI @username_3 is on a conference for this week, so you might not here back from him until early next week.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'andralex', 'comment_id': 356832293.0, 'datetime': '2018-01-11 05:41:43+00:00', 'masked_author': 'username_3', 'text': ""Well let's see!"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'CyberShadow', 'comment_id': 356832757.0, 'datetime': '2018-01-11 05:45:03+00:00', 'masked_author': 'username_1', 'text': 'Perhaps the org list ought to have a `max-width`:\r\n\r\n![](https://dump.thecybershadow.net/5a408427f022716804a7c17023ab54df/Screen%20Shot%202018-01-11%20at%2005.43.54.png)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'JackStouffer', 'comment_id': 356919339.0, 'datetime': '2018-01-11 12:24:47+00:00', 'masked_author': 'username_0', 'text': ""@username_3 Thanks!\r\n\r\n@username_1 ok I'll submit a followup PR. \r\n\r\nBTW what do you think of the A/B testing idea?"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'CyberShadow', 'comment_id': 356920356.0, 'datetime': '2018-01-11 12:29:27+00:00', 'masked_author': 'username_1', 'text': ""Could be worthwhile, but I would be cautious about:\r\n- adding more dependencies / failure points\r\n- adding more complexity and opportunities for things to break (e.g. Google is banned in China)\r\n- slowing down the page load\r\n- giving Google more data (even if we don't care, some of our users might)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'BBasile', 'comment_id': 357131409.0, 'datetime': '2018-01-12 03:12:04+00:00', 'masked_author': 'username_4', 'text': 'use this comment to vote for keep or revert.', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Change Front Page to Focus on Call to Action and Social Proof
username_0: Changed the design of the front page to leverage social proof to increase conversions (reducing bounce and increasing clicking on ""download"" and ""learn"").

## Rationale

Social proof is an extremely powerful way to convince people to spend time on the web or to build trust, where 70% of people say they trust the recommendation of a random stranger online in things like reviews and 92% trust a recommendation from anyone they know [1]. In our case, we don't have strangers, but a brands like Netflix or eBay which the visitor might trust already. This gives close to the same effect as someone hearing that a friend uses something.

Herein lies the problem: most people don't see our social proof. Only 22% of people scroll down to the bottom of webpages on average [2], right where the ""Organizations Using D"" is currently located.

Further, the first ten seconds are the most important in retaining users on a page, with a focus on the first two seconds [3]. So combined with the scrolling data we have, it's prudent to use your most convincing arguments ""above the fold"". Keeping the social proof above the 600px mark hits the user right when they are trying to decide if they want to stay on the site.

With that in mind, here's a preview of the changes:

<img width=""1280"" alt=""screen shot 2018-01-10 at 1 15 32 pm"" src=""https://user-images.githubusercontent.com/680068/34788398-72353cf2-f608-11e7-8e04-5f385ff5e4c0.png"">

In order to best capture the attention of the user in these ten seconds, this design works off of the ""Z pattern"", which puts the most important things on the page in a Z above the fold [4]. The reasoning is that from eye tracking software, it was discovered that people's eyes skim the entire screen when they first open a page. They either go in a F across the screen, or a Z [5]. The Z pattern puts the most important things on the four points of a Z, in our page, this would be the download button (which is now emphasized), the code example, and the organizations across the bottom.

<img width=""1280"" alt=""screen shot 2018-01-09 at 4 52 05 pm"" src=""https://user-images.githubusercontent.com/680068/34788408-7b1fef74-f608-11e7-8ffe-010670d0e4bd.png"">

This change also has the added benefit of helping to alleviate one of the perceived shortcomings of D is its adoption by the industry [6]. This claim is both true and false. It's not up to the same adoption of say, Go, but it's still being used. This change focuses on adoption better.

## What Exactly Has Been Changed

* Moved ""Orgs using D"" to the top of the page under the intro
* Changed which organizations are displayed and the order to show the most well known brands first
* Increased whitespace on intro to declutter first impression so the user sees just the intro and the social proof
* Changed the color of the download button to focus on the call to action

## The Scientific Approach

While I believe this will increase conversions, you don't have to take my word for it. If we were to integrate Google Analytics (even temporarily just for this experiment if people don't like it), then we can use it to A/B test this change.

Essentially what happens is you have a control page (the current front page) and a modified page (these changes). When a user loads dlang.org they are randomly assigned one or the other and given a cookie to make sure they don't see the other version on reload.  GA then tracks the differences in behavior between the control group and the experiment group over a period of time (say three weeks). At the end of the experiment, we could see the differences in initial bounce or going to the documentation or downloads page.

This would give us an objective measure to decide if we should adopt this or not.

### Sources

[1] http://www.nielsen.com/us/en/insights/news/2012/trust-in-advertising--paid-owned-and-earned.html
[2] https://www.clicktale.com/resources/blog/resourcesbloginvest-in-customer-experience-software/
[3] https://www.nngroup.com/articles/how-long-do-users-stay-on-web-pages/
[4] https://instapage.com/blog/z-pattern-layout
[5] https://99designs.com/blog/tips/visual-hierarchy-landing-page-designs/
[6] https://www.quora.com/Which-language-has-the-brightest-future-in-replacement-of-C-between-D-Go-and-Rust-And-Why/answer/Andrei-Alexandrescu
<issue_comment>username_1: Looks good! I think @username_3 wants to OK all index changes though.
<issue_comment>username_2: FYI @username_3 is on a conference for this week, so you might not here back from him until early next week.
<issue_comment>username_3: Well let's see!
<issue_comment>username_1: Perhaps the org list ought to have a `max-width`:

![](https://dump.thecybershadow.net/5a408427f022716804a7c17023ab54df/Screen%20Shot%202018-01-11%20at%2005.43.54.png)
<issue_comment>username_0: @username_3 Thanks!

@username_1 ok I'll submit a followup PR. 

BTW what do you think of the A/B testing idea?
<issue_comment>username_1: Could be worthwhile, but I would be cautious about:
- adding more dependencies / failure points
- adding more complexity and opportunities for things to break (e.g. Google is banned in China)
- slowing down the page load
- giving Google more data (even if we don't care, some of our users might)
<issue_comment>username_4: use this comment to vote for keep or revert."
RSS-Bridge/rss-bridge,343360490,752,,"[{'action': 'opened', 'author': 'Draky50110', 'comment_id': None, 'datetime': '2018-07-21 22:32:15+00:00', 'masked_author': 'username_0', 'text': 'Error message: `Could not request http://cdn2.cad-comic.com/rss.xml`\r\nQuery string: `action=display&bridge=CAD&format=Atom`\r\nVersion: `2018-07-17`', 'title': 'CAD Bridge failed with error 500', 'type': 'issue'}
 {'action': 'created', 'author': 'LogMANOriginal', 'comment_id': 406856725.0, 'datetime': '2018-07-22 10:44:08+00:00', 'masked_author': 'username_1', 'text': ""Confirmed, thanks for reporting!\r\n\r\nThis bridge was using a hidden RSS feed which was taken down (Server not found). They do actually provide an RSS feed right on their site in the upper right corner. Sort of...\r\n\r\n![feed](https://user-images.githubusercontent.com/5776685/43044710-04f86510-8dac-11e8-9f49-c982901de467.png)\r\n\r\nThe feed doesn't contain the comics (pictures) though, which is a nice feature to have I suppose. Simply replacing the feed doesn't work, it seems the layout changed as well.\r\n\r\nIf you only need the feed items you can either directly subscribe to the feed provided by them, or make use of the FilterBridge: `action=display&bridge=Filter&url=https%3A%2F%2Fcad-comic.com%2Ffeed%2F&filter=&filter_type=permit&format=Atom`"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Draky50110', 'comment_id': 406897488.0, 'datetime': '2018-07-22 21:18:57+00:00', 'masked_author': 'username_0', 'text': ':+1:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'LogMANOriginal', 'comment_id': 411852697.0, 'datetime': '2018-08-09 18:27:22+00:00', 'masked_author': 'username_1', 'text': 'Turns out CAD Bridge is now powered by WordPress, try: `?action=display&bridge=WordPress&url=https%3A%2F%2Fcad-comic.com&format=Atom`\r\n\r\nThe feed actually includes the images. As well as some unwanted stuff, but there is only so much the bridge can do right now. Is this sufficient to your requirement?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Draky50110', 'comment_id': 412098372.0, 'datetime': '2018-08-10 14:25:36+00:00', 'masked_author': 'username_0', 'text': 'Thanks.\r\nAs WordPress, https://cad-comic.com/feed/ is working so do not think a RSS-Bridge is needed... maybe it could be deleted from release as you say, WordPress bridge is ok :)', 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'Draky50110', 'comment_id': None, 'datetime': '2018-08-10 14:25:36+00:00', 'masked_author': 'username_0', 'text': '', 'title': None, 'type': 'issue'}]","<issue_start><issue_comment>Title: CAD Bridge failed with error 500
username_0: Error message: `Could not request http://cdn2.cad-comic.com/rss.xml`
Query string: `action=display&bridge=CAD&format=Atom`
Version: `2018-07-17`
<issue_comment>username_1: Confirmed, thanks for reporting!

This bridge was using a hidden RSS feed which was taken down (Server not found). They do actually provide an RSS feed right on their site in the upper right corner. Sort of...

![feed](https://user-images.githubusercontent.com/5776685/43044710-04f86510-8dac-11e8-9f49-c982901de467.png)

The feed doesn't contain the comics (pictures) though, which is a nice feature to have I suppose. Simply replacing the feed doesn't work, it seems the layout changed as well.

If you only need the feed items you can either directly subscribe to the feed provided by them, or make use of the FilterBridge: `action=display&bridge=Filter&url=https%3A%2F%2Fcad-comic.com%2Ffeed%2F&filter=&filter_type=permit&format=Atom`
<issue_comment>username_0: :+1:
<issue_comment>username_1: Turns out CAD Bridge is now powered by WordPress, try: `?action=display&bridge=WordPress&url=https%3A%2F%2Fcad-comic.com&format=Atom`

The feed actually includes the images. As well as some unwanted stuff, but there is only so much the bridge can do right now. Is this sufficient to your requirement?
<issue_comment>username_0: Thanks.
As WordPress, https://cad-comic.com/feed/ is working so do not think a RSS-Bridge is needed... maybe it could be deleted from release as you say, WordPress bridge is ok :)<issue_closed>"
RSS-Bridge/rss-bridge,1015554718,2288,"{'number': 2288.0, 'repo': 'rss-bridge', 'user_login': 'RSS-Bridge'}","[{'action': 'opened', 'author': 'Bockiii', 'comment_id': None, 'datetime': '2021-10-04T19:33:41Z', 'masked_author': 'username_0', 'text': 'Hi,\r\n\r\nfollowing up on #2280 , this is my Work In Progress on building a Tester bridge. The code is full of commented out test statements and is always evolving.\r\n\r\nThis is not meant to be an immediate ""merge this"" PR, its a discussion and develop-together PR. If you have ideas on how to make it better, shoot.', 'title': '[TesterBridge] Addition of bridge for testing', 'type': 'issue'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 933795703.0, 'datetime': '2021-10-04 19:39:16+00:00', 'masked_author': 'username_0', 'text': 'What it does right now: \r\n\r\n- Give it the URL of an rss-bridge instance (for actual auto testing, this will be done differently later probably).\r\n- The bridge will fetch all available bridges and will try to assert possible feed URLs. The bridge should be relatively easy to read but here is the gist:\r\n- fetch rss-front page\r\n- ignore bridges in the array (since they have json issues right now. We can also use this for blacklisting untestable bridges later).\r\n- get the parameters for each bridge\r\n- if a bridge has multiple sections, select one of those at random and report it back\r\n- write out what you found, aka ""which string would you retrieve now"".\r\n\r\nThe getBridgeFeed function works and reports back the amount of rss feed items returned right now.\r\n\r\nAs you can see from my issue writings and the state of the bridge, there is still quite a bit of work to do, but the foundations are laid.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 933912215.0, 'datetime': '2021-10-04 22:47:02+00:00', 'masked_author': 'username_0', 'text': 'As a rule, I think we should enforce that exampleValues exist for everything that is mandatory and that these exampleValues (or defaultValues) actually produce a result.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 934155763.0, 'datetime': '2021-10-05 07:49:38+00:00', 'masked_author': 'username_0', 'text': 'pinging some recent contributors to see if someone wants to help :)\r\n\r\n@csisoap @username_2 @sysadminstory @VerifiedJoseph @username_1', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ORelio', 'comment_id': 934235664.0, 'datetime': '2021-10-05 09:31:09+00:00', 'masked_author': 'username_1', 'text': ""I still need to perform maintainance on my bridges but I'm OK to provide example values to help automated testing on them 😉"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'somini', 'comment_id': 936229415.0, 'datetime': '2021-10-06 13:24:32+00:00', 'masked_author': 'username_2', 'text': 'From what I can tell, this is the only action needed by bridge authors? Is there any other way to give examples?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 936296215.0, 'datetime': '2021-10-06 14:03:20+00:00', 'masked_author': 'username_0', 'text': ""So far, correct. I think this would be the best way to give an example to do the automated testing. Additional examples can always be added through the (i) additional info.\r\n\r\nExample: \r\n```\r\n\t'zip' => array(\r\n\t\t'name' => 'ZIP code',\r\n\t\t'type' => 'text',\r\n\t\t'required' => true,\r\n\t\t'exampleValue' => '74910, 74',\r\n\t\t'title' => 'Insert ZIP code (complete or partial)'\r\n```\r\n\r\nwould become \r\n\r\n```\r\n\t'zip' => array(\r\n\t\t'name' => 'ZIP code',\r\n\t\t'type' => 'text',\r\n\t\t'required' => true,\r\n\t\t'exampleValue' => '74910',\r\n\t\t'title' => 'Insert ZIP code (complete or partial) as a comma separated list'\r\n```\r\n\r\nBigger problems are things like this (from Arte7Bridge):\r\n\r\n```\r\n\t'colfr' => array(\r\n\t\t'name' => 'Collection id',\r\n\t\t'required' => true,\r\n\t\t'title' => 'ex. RC-014095 pour https://www.arte.tv/fr/videos/RC-014095/blow-up/'\r\n\t)\r\n```\r\n\r\nIt's a required field that has no example or default value, so there is no sensible way to guestimate a value for that. So there is no way this bridge could be tested.\r\n\r\nTbh, I think it's totally doable to enter example/default values for all bridges in a sensible amount of time. We don't even need all bridge owners, a random person can do that :)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 936753171.0, 'datetime': '2021-10-06 17:32:40+00:00', 'masked_author': 'username_0', 'text': ""One more thing, and this is not a direct consequence of testing, just something that I noticed. We should limit the amount of items retrieved. Some bridges retrieve hundreds of feed items, which makes no sense at all (since it's already filtered and supposed to be a useable feed). It's a pain for the testing tool (as it needs to wait for all bridges to return all their items in order to check if the bridge actually did something) but it's also non sensical for actual use. The mozilla securities bridge was the worst offender. The bridge retrieves 260+ items every time it's updated..."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'somini', 'comment_id': 939327468.0, 'datetime': '2021-10-09 16:57:13+00:00', 'masked_author': 'username_2', 'text': 'Looks like I overestimated the required work, good job. What are the misbehaved 7 bridges?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'yamanq', 'comment_id': 945048675.0, 'datetime': '2021-10-17 04:43:20+00:00', 'masked_author': 'username_3', 'text': '- My opinion is that separating each bridge context into its own feed item is probably the best solution because the alternative requires extra parsing of the feed output to determine which context is causing an issue. Also, bridge contexts often break independently of one another.\r\n\r\n- We could possibly extend the bridge classes to contain a TestFeedItem function that can be overridden to check that the feed item is valid. For example, a bridge like HDWallPapers would override that function to check that links in the feed result in images rather than broken links (current state).', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 945160275.0, 'datetime': '2021-10-17 17:07:03+00:00', 'masked_author': 'username_0', 'text': 'I specifically didn\'t want to do that since that requires additional work on all 300 bridges that would be effectively the same as just using the required+examplevalues right now.\r\n\r\nAs for checking the content of each bridge, thats not really feasibly automateable since the content is 100% different for each bridge. Some just return a small text (the 8-ball-type bridges), some return just an image (comics), some return a giant article with images, text, tables, links and all (the folha-bridge has notoriously big articles, also the crewbay items are huge), so you wouldn\'t be able to really quantify if the content is correct, only if content is returned.\r\n\r\nMy tester bridge currently checks for 3 things:\r\n- returns 0 items: ""bridge broken""\r\n- returns 1 item: check if thats an error message, if yes, bridge broken, if not: bridge working\r\n- returns more than 1: bridge works', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'yamanq', 'comment_id': 945208569.0, 'datetime': '2021-10-17 22:47:52+00:00', 'masked_author': 'username_3', 'text': ""You're right about this. At the end of the day, a bridge could simply return an error itself if a critical part of its feed is not working correctly."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'dvikan', 'comment_id': 981168814.0, 'datetime': '2021-11-28 22:59:13+00:00', 'masked_author': 'username_4', 'text': 'In my humble opinion without fully grokking the architecture of rss-bridge, I think that bridges should be invoked/tested the same way that `DisplayAction::execute()` does it.\r\n\r\nBut we do indeed need known good configuration for all bridges that require it. E.g. the twitter bridge would require a username.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 981618258.0, 'datetime': '2021-11-29 13:08:21+00:00', 'masked_author': 'username_0', 'text': ""The tester bridge basically does that, just en masse since it's creating a feed for every single whitelisted bridge.\r\n\r\nAs for the configuration, that's what the other PR from me is for (defaultValue/exampleValue). We just need an additional test for new bridges to check for examplevalues/defaultvalues."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 982761221.0, 'datetime': '2021-11-30 15:45:15+00:00', 'masked_author': 'username_0', 'text': 'Alright, I did some changes.\r\n\r\n- I created a new fork ( https://github.com/rss-bridge-tester/rss-bridge )\r\n- This fork is updated from the original repo on a schedule (the schedule is a bit random right now, I will update that to ""once a week"" in the finished version).\r\n- Also once a week, the bridge tester bridge will be run on a heroku instance of rss-bridge.\r\n- Results are written to a .csv file in the github repo\r\n- I\'m currently setting up a power-bi page to display the results in a structured manner. But in general, the csv can be used for statistic stuff.\r\n\r\nIt currently fails because #2296 has to be merged first and we will also have to establish a check that checks new bridge additions for example/defaultValues.\r\n\r\nA problem of the current way it is setup: If one bridge has an undefined scope (aka a mandatory field that has no example/defaultValue) the whole test will fail (as every bridge results in a feed item and if a feed item fails, rss-bridge fails the whole bridge by default). If a bridge ""fails"" because it retrieves no content, everything is fine. It\'s just a problem when the context of a bridge is incomplete.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 991623062.0, 'datetime': '2021-12-11 12:18:41+00:00', 'masked_author': 'username_0', 'text': ""Some stats after just 3 runs. the lines will even out after a while and I will also have to do some sanity checks on the data.\r\n\r\nAlso, if you have ideas for more diagrams, shoot.\r\n![image](https://user-images.githubusercontent.com/16492843/145676140-2c36e716-880b-4c6e-a1b2-3956c540b4b7.png)\r\n\r\n![image](https://user-images.githubusercontent.com/16492843/145676144-b9d8405a-9d86-4917-a193-979343a343e1.png)\r\n\r\n![image](https://user-images.githubusercontent.com/16492843/145676148-5fa3761a-b923-4da9-a4c2-a1e21fa2a33a.png)\r\n\r\npinging @username_2 @em92 @username_4 @username_1 @username_3 \r\nThoughts?\r\n\r\nbtw: The current test-state has nothing to do with this PR anymore really (like, the code), so I will change this at one point since it now involves a new github action, python code etc. I'm also not sure on how to display it nicely yet. I am using Power BI myself because I know it, but it's not possible to do a public version of it (at least it requires a substantial amount of money :D ). I'm currently looking into Metabase, which could be setup on the VPS that em got, but that will require some additional research and maybe a change to the workflow (as I will probably post the data to the database directly instead of shoving it into a csv file). But the testing part is functional. It still requires the #2296 merge and some additional work, but it works in general."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'dvikan', 'comment_id': 991660271.0, 'datetime': '2021-12-11 14:21:03+00:00', 'masked_author': 'username_4', 'text': 'Please use php and place it in `./contrib` so it can be reused by others.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 991668241.0, 'datetime': '2021-12-11 14:44:18+00:00', 'masked_author': 'username_0', 'text': 'Using php seems to not be feasible with public services since most of them cut off requests after some amount of time. Heroku cuts the testerbridge request after 30 seconds for example.\n\nPython works well.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'yamanq', 'comment_id': 991709242.0, 'datetime': '2021-12-11 16:50:13+00:00', 'masked_author': 'username_3', 'text': 'I don\'t see any problems with writing the test suite in Python. We could use matplotlib (+ seaborn?) to generate those nice plots as well. One plot that could be helpful is showing the ""uptime"" of a bridge, as some bridges occasionally fail for rate limiting / other reasons that don\'t necessarily mean that the bridge is broken. We could show this as a rugplot or a heatmap where the x axis is some timescale (daily is probably the best).', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'dvikan', 'comment_id': 991717732.0, 'datetime': '2021-12-11 17:17:17+00:00', 'masked_author': 'username_4', 'text': 'This is a php project after all. Seems silly to use two different dynamic languages when one suffices.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'somini', 'comment_id': 991733190.0, 'datetime': '2021-12-11 18:06:22+00:00', 'masked_author': 'username_2', 'text': 'This kind of data seems crucial to run in CI, or even expose on the bridge code itself, @username_0 this looks good.\r\n\r\nI agree that it seems silly to write a test suite in Python, maybe it could be a sister project instead, for monitoring the RSS Bridge deployment?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 991733972.0, 'datetime': '2021-12-11 18:09:16+00:00', 'masked_author': 'username_0', 'text': 'No problem, that\'s what it is right now anyways. It\'s not dependent on the main repo in any way ( the rss-bridge instance is done using the docker container), so we can keep it like this forever. I would just argue that the visibility would be higher if it\'s part of the main repo, but there are ways to keep the visibility and still do it external.\r\n\r\nAnother option would be to do a new repo in the rss-bridge github organisation and move it there. Then it\'s still ""official"", can be managed by the team and is still separate.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'dvikan', 'comment_id': 991736483.0, 'datetime': '2021-12-11 18:17:02+00:00', 'masked_author': 'username_4', 'text': 'Thank you for lengthy response @username_0. I understand all your points.\r\n\r\nI would argue that bridge monitoring should not be a Bridge. It should be a cli tool without any requirement of an http server. The max execution time can be set to forever if needed.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 991738547.0, 'datetime': '2021-12-11 18:23:52+00:00', 'masked_author': 'username_0', 'text': ""If you come up with a pure php way to do it, be my guest :) I've opened this discussion-pr over 2 months ago with 0 pull requests or intend to support by anyone, so I'm just doing it my way :) I'm not bitter about that btw, thats just the reality :)\r\n\r\nI dont know how you would want to test a bridge without an actual running version of rss-bridge though, but I'm also basically illiterate in php. In my mind, you can only test the outcome of a bridge by actually running it.\r\n\r\nSo for the time being, I will continue with the python solution and go into the visualization. We can keep it separate or we can move it to a repo in the rss-bridge organization, that can all be done at a later point in time."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 991793356.0, 'datetime': '2021-12-11 21:47:49+00:00', 'masked_author': 'username_0', 'text': 'btw: for all the php pros: I still need someone to implement a check for the auto-checker that tests if a mandatory field has an examplevalue or defaultvalue (both would be fine).\r\n\r\nWe need to put that into the wiki as well', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 995168519.0, 'datetime': '2021-12-15 19:58:30+00:00', 'masked_author': 'username_0', 'text': ""btw, I'm planning to do the visualizations with Tableau Public but because of log4j, it's not possible to download their software right now :D So when they fixed that, I'll try it with that. Looks promising (and is less hard work than matplotlib :D )"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'f0086', 'comment_id': 998306553.0, 'datetime': '2021-12-20 22:08:51+00:00', 'masked_author': 'username_5', 'text': 'After reading through this and the related PRs, I am kind of hijack this PR because I opened a similar Issue (#2377) :). I will leave my thoughts on this here, but there are not meant to be implemented in this particular PR. I would like to continue this discussion for a solid solution.\r\n\r\nThe first question we need to answer is: Whats the goal of all this? For me, its improving the user experience and the quality of this project. Regarding the analytics from @username_0, half of the bridges are somewhat broken. That\'s a 50:50 chance for a user to accidental using a broken bridge. IMHO thats not acceptable. I use RSSBridge for a long time now and I can say: this is reality.\r\n\r\n**Improving the user experience**\r\nMy understanding of a rock solid software is that the features it will provide are working 100%. The nature of that project makes this nearly impossible, but 50% is too low, even for a project with a lot of moving parts and external dependencies. Waiting for a fix can take time, so in the meantime the bridge needs to be disabled or flagged as broken. We already have the feature of enable/disable certain bridges. If we could automatically disable broken bridges (on a running instance), this would make the user experience MUCH better.\r\n\r\n**Fixing bridges faster**\r\nAfter reading a little in the issue tracker, it seems there is a mantra to leave broken bridges to the authors/maintainers and no other person is allowed to fix it. Sure, the author of the code/bridge knows best what to do when the bridge stopped working, but honestly, in most cases it is not complicated to fix it. Sure, if we can detect broken bridges automatically, we could notify the author of the bridge (if we make an email/github user mandatory). But everyone should be encouraged to fix broken bridges. If there is a list of broken ones, it would be a great starting point for someone who just want to contribute come code (as mentioned by @username_0).\r\n\r\nThe current workflow is the following: A bridge breaks. Some random user on some instance noticed it at some point (days, weeks, months later after he/she get curious why there are no updates on that feed). Then, (if friendly enough), the user opens a new github issue. After that, someone need to go through this issue and find the author of the bridge. In a lot of cases, the author do not give a shit and ignore it. If he fixes it eventually and open a PR, the code need to pass obscure php5.6 linting and find someone who can merge it. After that, the maintainer of the instance need to update their installation in order to reflect the fix and make the bridge work again. This whole process can take weeks or months. Between that, the bridge is broken. This workflow need to be improved IMHO.\r\n\r\nMy proposal:\r\n* Remove php5.6 support and the linting, for more, see #2378\r\n* Disable bridges automatically from within a public ""broken bridge list"", see #2377. For that, @username_0 is working hard on an external tool which provice a CSV file which can RSSBridge can read/cache and use to disable/enable the bridges.\r\n* Make contributing code to fix bridges more pleasing: More maintainers with merge permissions, more active in the issue tracker, better guidelines\r\n* Do not rely on the enduser to report broken bridges (see below)\r\n\r\n**So, what makes bridges break?**\r\nTo view this more abstract, a bridge fetches HTML (and other) sources, search for the needed content and build up the ```$items``` array. To verify that the bridge works, we need to make sure the source is available and the content is on the place we search for it. Solid bridges are prepared for failures on both cases (throw an error if the source can not be downloaded and check if the needed HTML-Tags are there before accessing it). But the reality is that most bridges are build to reflect the good case. Some bridges fail hard (crash), some fail silent (empty $items array).\r\n\r\n**Find and report broken bridges**\r\nTackling this from the outside (the @username_0 approach) is a great starting point to get a rough overview of the ""problem"" (which is huge, according to the charts above). But to set this on a solid base, we need to do this from the inside. Each bridge should provide some guards or constraints under which it can operate. With that, we can run automated tests, generate the ""broken bridges"" csv file, alert maintainers, and so on.\r\n\r\nBut how can we implement this?\r\nSome ideas:\r\n\r\n* Implement a ```verifySource()``` method in ```BridgeAbstract```, which do some basic checks with ```getURI()``` (can it be downloaded, is the content length > 0 etc.) and some basic checks with ```collectData()``` (no errors thrown, no use of the error class methods, items count > 0 with example values, etc.). Each bridge can overwrite this method to provide a better and more accurate verifySource method which could check if certain elements are present in the HTML code, use different input parameters and so on. With that approach, we can test the majority of the bridges automatically and improve this over time (when bridges implement the verifySource() method.\r\n* Check all bridges in a regular interval and provide a public accessible file with all broken bridges. This files can be fetched from the instances and disable the bridge or flag is as ""broken"" for a more moderate action.\r\n* Make the ```MAINTAINER``` attribute in the bridge implementations mandatory and replace it with an email or @github-username. With that, we can automatically notify the maintainer for broken bridges. This bypasses half of the current workflow.\r\n* On each build and docker hub push, the ```whitelist.default.txt``` file can be the inverse of the broken bridges file. This will further improve the first user experience after installing RSSBridge (it took me a while to realize that I need to whitelist bridges).\r\n\r\nI can provide some POC code to demonstrate this if you agree.\r\nWhat do you think?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bockiii', 'comment_id': 998351537.0, 'datetime': '2021-12-20 23:43:50+00:00', 'masked_author': 'username_0', 'text': 'Thanks for the lengthy comment and contribution. I mostly agree with you and on some parts have no opinion (on the formatting/linting topic for example).\r\n\r\nYes, my main goal with this is to enhance the user experience. In order to do that, we need to know where the biggest pain points are and for that we need data. My approach is one metric that gives a bunch of data points that might be relevant to tackle a multitude of issues.\r\n\r\n- General bridge functionality (working vs non working)\r\n- Speed of bridges\r\n- Amount of data pulled (in mb, not yet logged but I want to go there. Some bridges embed videos etc).\r\n- Unneccessary data (bridges that return 200 items each pull, every 4 hours or so)\r\n\r\nThings I\'m not checking yet, which should be checked:\r\n- Sensible content of feed items: Does the source provide tags that are not provided in the feed? Does the feed include embeds, social links, misformated content (because of missing css information) and so on and so forth?\r\n- Configuration sensibility: Some bridges use a labyrinth of settings that sometimes cant be used together (example: two checkboxes, one ""Only Weekdays"" one ""Only Weekends"". Both together wont work and would be better suited for a dropdown list)\r\n\r\nAbout the auto-disabling: I\'m on the fence about that. The problem is the volatility of some bridges (and maybe lack of testability right now). So a bridge that doesnt work in my test may work for a user. Good example is the ""i know what youre downloading"" bridge. Configuration option is an IP. If that IP is downloading something, you get a non-0 feed items answer. If that IP isnt downloading something, you get a 0. Which IP am I supposed to test in an automated testing? Which IP is ALWAYS downloading something through torrents? (btw, not looking for an answer, just an example of the difficulty).\r\nThere are also bridges whos functionality depend on either the geolocation of the IP thats running the bridge or on the amount of pulls from that IP (see the gazillion facebook issues).\r\n\r\nSo yes, in the end, we all want to make rss-bridge a better experience for the user and I agree that there are currently some stop-blocks for contributors, for users and for hosters.\r\n\r\ne.g: It\'s still not possible to just host rss-bridge on heroku because it\'s impossible to provide a custom whitelist.txt. The ""scalingo"" link still refers to the repo link as sebsauvage\'s, so I doubt that that link will work (though I haven\'t tested it).\r\n\r\nSo yeah.. things need to be done.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'somini', 'comment_id': 998419254.0, 'datetime': '2021-12-21 02:31:56+00:00', 'masked_author': 'username_2', 'text': 'I don\'t know about other people, but I would love for other people to fix my code! From what I can tell (and this happens with almost all my bridges), the number of people actually subscribed to particular bridges is minimal. Most of my bridges are done for me alone (not in the ""private"" sense, it\'s just that no one else cares), I just push them upstream in the hope that someone else might find them useful and to make deployment easier.\r\nI feel that most of bridge authors are like this, just using a small subset of all bridges.\r\n\r\nThen there is the other bridges, the big guns: Facebook, Twitter (completely abandoned, superseded by nitter), and the more popular sites. These bridges create the bulk of the support load, and most of the times it\'s just policy changes: IP temporary blacklists, bans, DDOS ""protection"", the whole shebang.\r\n\r\nIn yet another downside for the maintainers, we are basically either reimplementing Wordpress features that the site owners did not turn on, or scraping sites that actively resist data liberation.\r\nIt\'s sort of white-hat scraping, to coin a phrase. Like `youtube-dl`, but for text.\r\n\r\nBaby-sitting a CI system for this would be a full time job, and above my pay grade. Rotating IP addresses to avoid site blacklists, etc etc. Ain\'t nobody got time for that!', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: [TesterBridge] Addition of bridge for testing
username_0: Hi,

following up on #2280 , this is my Work In Progress on building a Tester bridge. The code is full of commented out test statements and is always evolving.

This is not meant to be an immediate ""merge this"" PR, its a discussion and develop-together PR. If you have ideas on how to make it better, shoot.
<issue_comment>username_0: What it does right now: 

- Give it the URL of an rss-bridge instance (for actual auto testing, this will be done differently later probably).
- The bridge will fetch all available bridges and will try to assert possible feed URLs. The bridge should be relatively easy to read but here is the gist:
- fetch rss-front page
- ignore bridges in the array (since they have json issues right now. We can also use this for blacklisting untestable bridges later).
- get the parameters for each bridge
- if a bridge has multiple sections, select one of those at random and report it back
- write out what you found, aka ""which string would you retrieve now"".

The getBridgeFeed function works and reports back the amount of rss feed items returned right now.

As you can see from my issue writings and the state of the bridge, there is still quite a bit of work to do, but the foundations are laid.
<issue_comment>username_0: As a rule, I think we should enforce that exampleValues exist for everything that is mandatory and that these exampleValues (or defaultValues) actually produce a result.
<issue_comment>username_0: pinging some recent contributors to see if someone wants to help :)

@csisoap @username_2 @sysadminstory @VerifiedJoseph @username_1
<issue_comment>username_1: I still need to perform maintainance on my bridges but I'm OK to provide example values to help automated testing on them 😉
<issue_comment>username_2: From what I can tell, this is the only action needed by bridge authors? Is there any other way to give examples?
<issue_comment>username_0: So far, correct. I think this would be the best way to give an example to do the automated testing. Additional examples can always be added through the (i) additional info.

Example: 
```
	'zip' => array(
		'name' => 'ZIP code',
		'type' => 'text',
		'required' => true,
		'exampleValue' => '74910, 74',
		'title' => 'Insert ZIP code (complete or partial)'
```

would become 

```
	'zip' => array(
		'name' => 'ZIP code',
		'type' => 'text',
		'required' => true,
		'exampleValue' => '74910',
		'title' => 'Insert ZIP code (complete or partial) as a comma separated list'
```

Bigger problems are things like this (from Arte7Bridge):

```
	'colfr' => array(
		'name' => 'Collection id',
		'required' => true,
		'title' => 'ex. RC-014095 pour https://www.arte.tv/fr/videos/RC-014095/blow-up/'
	)
```

It's a required field that has no example or default value, so there is no sensible way to guestimate a value for that. So there is no way this bridge could be tested.

Tbh, I think it's totally doable to enter example/default values for all bridges in a sensible amount of time. We don't even need all bridge owners, a random person can do that :)
<issue_comment>username_0: One more thing, and this is not a direct consequence of testing, just something that I noticed. We should limit the amount of items retrieved. Some bridges retrieve hundreds of feed items, which makes no sense at all (since it's already filtered and supposed to be a useable feed). It's a pain for the testing tool (as it needs to wait for all bridges to return all their items in order to check if the bridge actually did something) but it's also non sensical for actual use. The mozilla securities bridge was the worst offender. The bridge retrieves 260+ items every time it's updated...
<issue_comment>username_2: Looks like I overestimated the required work, good job. What are the misbehaved 7 bridges?
<issue_comment>username_3: - My opinion is that separating each bridge context into its own feed item is probably the best solution because the alternative requires extra parsing of the feed output to determine which context is causing an issue. Also, bridge contexts often break independently of one another.

- We could possibly extend the bridge classes to contain a TestFeedItem function that can be overridden to check that the feed item is valid. For example, a bridge like HDWallPapers would override that function to check that links in the feed result in images rather than broken links (current state).
<issue_comment>username_0: I specifically didn't want to do that since that requires additional work on all 300 bridges that would be effectively the same as just using the required+examplevalues right now.

As for checking the content of each bridge, thats not really feasibly automateable since the content is 100% different for each bridge. Some just return a small text (the 8-ball-type bridges), some return just an image (comics), some return a giant article with images, text, tables, links and all (the folha-bridge has notoriously big articles, also the crewbay items are huge), so you wouldn't be able to really quantify if the content is correct, only if content is returned.

My tester bridge currently checks for 3 things:
- returns 0 items: ""bridge broken""
- returns 1 item: check if thats an error message, if yes, bridge broken, if not: bridge working
- returns more than 1: bridge works
<issue_comment>username_3: You're right about this. At the end of the day, a bridge could simply return an error itself if a critical part of its feed is not working correctly.
<issue_comment>username_4: In my humble opinion without fully grokking the architecture of rss-bridge, I think that bridges should be invoked/tested the same way that `DisplayAction::execute()` does it.

But we do indeed need known good configuration for all bridges that require it. E.g. the twitter bridge would require a username.
<issue_comment>username_0: The tester bridge basically does that, just en masse since it's creating a feed for every single whitelisted bridge.

As for the configuration, that's what the other PR from me is for (defaultValue/exampleValue). We just need an additional test for new bridges to check for examplevalues/defaultvalues.
<issue_comment>username_0: Alright, I did some changes.

- I created a new fork ( https://github.com/rss-bridge-tester/rss-bridge )
- This fork is updated from the original repo on a schedule (the schedule is a bit random right now, I will update that to ""once a week"" in the finished version).
- Also once a week, the bridge tester bridge will be run on a heroku instance of rss-bridge.
- Results are written to a .csv file in the github repo
- I'm currently setting up a power-bi page to display the results in a structured manner. But in general, the csv can be used for statistic stuff.

It currently fails because #2296 has to be merged first and we will also have to establish a check that checks new bridge additions for example/defaultValues.

A problem of the current way it is setup: If one bridge has an undefined scope (aka a mandatory field that has no example/defaultValue) the whole test will fail (as every bridge results in a feed item and if a feed item fails, rss-bridge fails the whole bridge by default). If a bridge ""fails"" because it retrieves no content, everything is fine. It's just a problem when the context of a bridge is incomplete.
<issue_comment>username_0: Some stats after just 3 runs. the lines will even out after a while and I will also have to do some sanity checks on the data.

Also, if you have ideas for more diagrams, shoot.
![image](https://user-images.githubusercontent.com/16492843/145676140-2c36e716-880b-4c6e-a1b2-3956c540b4b7.png)

![image](https://user-images.githubusercontent.com/16492843/145676144-b9d8405a-9d86-4917-a193-979343a343e1.png)

![image](https://user-images.githubusercontent.com/16492843/145676148-5fa3761a-b923-4da9-a4c2-a1e21fa2a33a.png)

pinging @username_2 @em92 @username_4 @username_1 @username_3 
Thoughts?

btw: The current test-state has nothing to do with this PR anymore really (like, the code), so I will change this at one point since it now involves a new github action, python code etc. I'm also not sure on how to display it nicely yet. I am using Power BI myself because I know it, but it's not possible to do a public version of it (at least it requires a substantial amount of money :D ). I'm currently looking into Metabase, which could be setup on the VPS that em got, but that will require some additional research and maybe a change to the workflow (as I will probably post the data to the database directly instead of shoving it into a csv file). But the testing part is functional. It still requires the #2296 merge and some additional work, but it works in general.
<issue_comment>username_4: Please use php and place it in `./contrib` so it can be reused by others.
<issue_comment>username_0: Using php seems to not be feasible with public services since most of them cut off requests after some amount of time. Heroku cuts the testerbridge request after 30 seconds for example.

Python works well.
<issue_comment>username_3: I don't see any problems with writing the test suite in Python. We could use matplotlib (+ seaborn?) to generate those nice plots as well. One plot that could be helpful is showing the ""uptime"" of a bridge, as some bridges occasionally fail for rate limiting / other reasons that don't necessarily mean that the bridge is broken. We could show this as a rugplot or a heatmap where the x axis is some timescale (daily is probably the best).
<issue_comment>username_4: This is a php project after all. Seems silly to use two different dynamic languages when one suffices.
<issue_comment>username_2: This kind of data seems crucial to run in CI, or even expose on the bridge code itself, @username_0 this looks good.

I agree that it seems silly to write a test suite in Python, maybe it could be a sister project instead, for monitoring the RSS Bridge deployment?
<issue_comment>username_0: No problem, that's what it is right now anyways. It's not dependent on the main repo in any way ( the rss-bridge instance is done using the docker container), so we can keep it like this forever. I would just argue that the visibility would be higher if it's part of the main repo, but there are ways to keep the visibility and still do it external.

Another option would be to do a new repo in the rss-bridge github organisation and move it there. Then it's still ""official"", can be managed by the team and is still separate.
<issue_comment>username_4: Thank you for lengthy response @username_0. I understand all your points.

I would argue that bridge monitoring should not be a Bridge. It should be a cli tool without any requirement of an http server. The max execution time can be set to forever if needed.
<issue_comment>username_0: If you come up with a pure php way to do it, be my guest :) I've opened this discussion-pr over 2 months ago with 0 pull requests or intend to support by anyone, so I'm just doing it my way :) I'm not bitter about that btw, thats just the reality :)

I dont know how you would want to test a bridge without an actual running version of rss-bridge though, but I'm also basically illiterate in php. In my mind, you can only test the outcome of a bridge by actually running it.

So for the time being, I will continue with the python solution and go into the visualization. We can keep it separate or we can move it to a repo in the rss-bridge organization, that can all be done at a later point in time.
<issue_comment>username_0: btw: for all the php pros: I still need someone to implement a check for the auto-checker that tests if a mandatory field has an examplevalue or defaultvalue (both would be fine).

We need to put that into the wiki as well
<issue_comment>username_0: btw, I'm planning to do the visualizations with Tableau Public but because of log4j, it's not possible to download their software right now :D So when they fixed that, I'll try it with that. Looks promising (and is less hard work than matplotlib :D )
<issue_comment>username_5: After reading through this and the related PRs, I am kind of hijack this PR because I opened a similar Issue (#2377) :). I will leave my thoughts on this here, but there are not meant to be implemented in this particular PR. I would like to continue this discussion for a solid solution.

The first question we need to answer is: Whats the goal of all this? For me, its improving the user experience and the quality of this project. Regarding the analytics from @username_0, half of the bridges are somewhat broken. That's a 50:50 chance for a user to accidental using a broken bridge. IMHO thats not acceptable. I use RSSBridge for a long time now and I can say: this is reality.

**Improving the user experience**
My understanding of a rock solid software is that the features it will provide are working 100%. The nature of that project makes this nearly impossible, but 50% is too low, even for a project with a lot of moving parts and external dependencies. Waiting for a fix can take time, so in the meantime the bridge needs to be disabled or flagged as broken. We already have the feature of enable/disable certain bridges. If we could automatically disable broken bridges (on a running instance), this would make the user experience MUCH better.

**Fixing bridges faster**
After reading a little in the issue tracker, it seems there is a mantra to leave broken bridges to the authors/maintainers and no other person is allowed to fix it. Sure, the author of the code/bridge knows best what to do when the bridge stopped working, but honestly, in most cases it is not complicated to fix it. Sure, if we can detect broken bridges automatically, we could notify the author of the bridge (if we make an email/github user mandatory). But everyone should be encouraged to fix broken bridges. If there is a list of broken ones, it would be a great starting point for someone who just want to contribute come code (as mentioned by @username_0).

The current workflow is the following: A bridge breaks. Some random user on some instance noticed it at some point (days, weeks, months later after he/she get curious why there are no updates on that feed). Then, (if friendly enough), the user opens a new github issue. After that, someone need to go through this issue and find the author of the bridge. In a lot of cases, the author do not give a shit and ignore it. If he fixes it eventually and open a PR, the code need to pass obscure php5.6 linting and find someone who can merge it. After that, the maintainer of the instance need to update their installation in order to reflect the fix and make the bridge work again. This whole process can take weeks or months. Between that, the bridge is broken. This workflow need to be improved IMHO.

My proposal:
* Remove php5.6 support and the linting, for more, see #2378
* Disable bridges automatically from within a public ""broken bridge list"", see #2377. For that, @username_0 is working hard on an external tool which provice a CSV file which can RSSBridge can read/cache and use to disable/enable the bridges.
* Make contributing code to fix bridges more pleasing: More maintainers with merge permissions, more active in the issue tracker, better guidelines
* Do not rely on the enduser to report broken bridges (see below)

**So, what makes bridges break?**
To view this more abstract, a bridge fetches HTML (and other) sources, search for the needed content and build up the ```$items``` array. To verify that the bridge works, we need to make sure the source is available and the content is on the place we search for it. Solid bridges are prepared for failures on both cases (throw an error if the source can not be downloaded and check if the needed HTML-Tags are there before accessing it). But the reality is that most bridges are build to reflect the good case. Some bridges fail hard (crash), some fail silent (empty $items array).

**Find and report broken bridges**
Tackling this from the outside (the @username_0 approach) is a great starting point to get a rough overview of the ""problem"" (which is huge, according to the charts above). But to set this on a solid base, we need to do this from the inside. Each bridge should provide some guards or constraints under which it can operate. With that, we can run automated tests, generate the ""broken bridges"" csv file, alert maintainers, and so on.

But how can we implement this?
Some ideas:

* Implement a ```verifySource()``` method in ```BridgeAbstract```, which do some basic checks with ```getURI()``` (can it be downloaded, is the content length > 0 etc.) and some basic checks with ```collectData()``` (no errors thrown, no use of the error class methods, items count > 0 with example values, etc.). Each bridge can overwrite this method to provide a better and more accurate verifySource method which could check if certain elements are present in the HTML code, use different input parameters and so on. With that approach, we can test the majority of the bridges automatically and improve this over time (when bridges implement the verifySource() method.
* Check all bridges in a regular interval and provide a public accessible file with all broken bridges. This files can be fetched from the instances and disable the bridge or flag is as ""broken"" for a more moderate action.
* Make the ```MAINTAINER``` attribute in the bridge implementations mandatory and replace it with an email or @github-username. With that, we can automatically notify the maintainer for broken bridges. This bypasses half of the current workflow.
* On each build and docker hub push, the ```whitelist.default.txt``` file can be the inverse of the broken bridges file. This will further improve the first user experience after installing RSSBridge (it took me a while to realize that I need to whitelist bridges).

I can provide some POC code to demonstrate this if you agree.
What do you think?
<issue_comment>username_0: Thanks for the lengthy comment and contribution. I mostly agree with you and on some parts have no opinion (on the formatting/linting topic for example).

Yes, my main goal with this is to enhance the user experience. In order to do that, we need to know where the biggest pain points are and for that we need data. My approach is one metric that gives a bunch of data points that might be relevant to tackle a multitude of issues.

- General bridge functionality (working vs non working)
- Speed of bridges
- Amount of data pulled (in mb, not yet logged but I want to go there. Some bridges embed videos etc).
- Unneccessary data (bridges that return 200 items each pull, every 4 hours or so)

Things I'm not checking yet, which should be checked:
- Sensible content of feed items: Does the source provide tags that are not provided in the feed? Does the feed include embeds, social links, misformated content (because of missing css information) and so on and so forth?
- Configuration sensibility: Some bridges use a labyrinth of settings that sometimes cant be used together (example: two checkboxes, one ""Only Weekdays"" one ""Only Weekends"". Both together wont work and would be better suited for a dropdown list)

About the auto-disabling: I'm on the fence about that. The problem is the volatility of some bridges (and maybe lack of testability right now). So a bridge that doesnt work in my test may work for a user. Good example is the ""i know what youre downloading"" bridge. Configuration option is an IP. If that IP is downloading something, you get a non-0 feed items answer. If that IP isnt downloading something, you get a 0. Which IP am I supposed to test in an automated testing? Which IP is ALWAYS downloading something through torrents? (btw, not looking for an answer, just an example of the difficulty).
There are also bridges whos functionality depend on either the geolocation of the IP thats running the bridge or on the amount of pulls from that IP (see the gazillion facebook issues).

So yes, in the end, we all want to make rss-bridge a better experience for the user and I agree that there are currently some stop-blocks for contributors, for users and for hosters.

e.g: It's still not possible to just host rss-bridge on heroku because it's impossible to provide a custom whitelist.txt. The ""scalingo"" link still refers to the repo link as sebsauvage's, so I doubt that that link will work (though I haven't tested it).

So yeah.. things need to be done.
<issue_comment>username_2: I don't know about other people, but I would love for other people to fix my code! From what I can tell (and this happens with almost all my bridges), the number of people actually subscribed to particular bridges is minimal. Most of my bridges are done for me alone (not in the ""private"" sense, it's just that no one else cares), I just push them upstream in the hope that someone else might find them useful and to make deployment easier.
I feel that most of bridge authors are like this, just using a small subset of all bridges.

Then there is the other bridges, the big guns: Facebook, Twitter (completely abandoned, superseded by nitter), and the more popular sites. These bridges create the bulk of the support load, and most of the times it's just policy changes: IP temporary blacklists, bans, DDOS ""protection"", the whole shebang.

In yet another downside for the maintainers, we are basically either reimplementing Wordpress features that the site owners did not turn on, or scraping sites that actively resist data liberation.
It's sort of white-hat scraping, to coin a phrase. Like `youtube-dl`, but for text.

Baby-sitting a CI system for this would be a full time job, and above my pay grade. Rotating IP addresses to avoid site blacklists, etc etc. Ain't nobody got time for that!"
JuliaLang/www.julialang.org,633803319,854,,"[{'action': 'opened', 'author': 'logankilpatrick', 'comment_id': None, 'datetime': '2020-06-07 22:00:43+00:00', 'masked_author': 'username_0', 'text': 'Just like what is done here: https://dotnet.microsoft.com/download \r\n<img width=""1398"" alt=""Screen Shot 2020-06-07 at 4 58 07 PM"" src=""https://user-images.githubusercontent.com/35577566/83981068-38f5e080-a8e0-11ea-9d0d-941951139ecf.png"">\r\n\r\n...I think it would be powerful to add this to the download page.', 'title': ""Add a little more about why Julia on the Download page (logistical Why's)"", 'type': 'issue'}
 {'action': 'created', 'author': 'zdroid', 'comment_id': 640286568.0, 'datetime': '2020-06-07 22:03:09+00:00', 'masked_author': 'username_1', 'text': ""It could be made very easily in a similar manner to the front page's heading. We just need an appropriate background image for it. And while we are at it, we can choose a background image for the front page as well... :laughing:"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'StarTrooper08', 'comment_id': 846833677.0, 'datetime': '2021-05-24 07:31:56+00:00', 'masked_author': 'username_2', 'text': '@username_0 Is this issue still open ?\nOr else is it completed?\n\nIf not completed I would be glad to take this issue.', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Add a little more about why Julia on the Download page (logistical Why's)
username_0: Just like what is done here: https://dotnet.microsoft.com/download 
<img width=""1398"" alt=""Screen Shot 2020-06-07 at 4 58 07 PM"" src=""https://user-images.githubusercontent.com/35577566/83981068-38f5e080-a8e0-11ea-9d0d-941951139ecf.png"">

...I think it would be powerful to add this to the download page.
<issue_comment>username_1: It could be made very easily in a similar manner to the front page's heading. We just need an appropriate background image for it. And while we are at it, we can choose a background image for the front page as well... :laughing:
<issue_comment>username_2: @username_0 Is this issue still open ?
Or else is it completed?

If not completed I would be glad to take this issue."
kubernetes/website,286950114,6891,,"[{'action': 'opened', 'author': 'z-oo', 'comment_id': None, 'datetime': '2018-01-09 02:22:18+00:00', 'masked_author': 'username_0', 'text': '<!-- Thanks for filing an issue! Before submitting, please fill in the following information. -->\r\n\r\n<!--Required Information-->\r\n\r\n**This is a...** \r\n<!-- choose one by changing [ ] to [x] -->\r\n- [ ] Feature Request\r\n- [x] Bug Report\r\n\r\n**Problem:**\r\nI followed this instruction on a freshly installed Ubuntu 16.04 machine and it did not work. It was stuck on `kubeadm init` step. I need to manually specify kubelet flag `--cgroup-driver=systemd`. This seems very reproducible and it happened to all my freshly installed ubuntu if I follow the instruction.\r\n\r\n```\r\n# kubeadm init\r\n[init] Using Kubernetes version: v1.9.1\r\n[init] Using Authorization modes: [Node RBAC]\r\n[preflight] Running pre-flight checks.\r\n\t[WARNING FileExisting-crictl]: crictl not found in system path\r\n[certificates] Generated ca certificate and key.\r\n[certificates] Generated apiserver certificate and key.\r\n[certificates] apiserver serving cert is signed for DNS names [simulator4 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.1.1.114]\r\n[certificates] Generated apiserver-kubelet-client certificate and key.\r\n[certificates] Generated sa key and public key.\r\n[certificates] Generated front-proxy-ca certificate and key.\r\n[certificates] Generated front-proxy-client certificate and key.\r\n[certificates] Valid certificates and keys now exist in ""/etc/kubernetes/pki""\r\n[kubeconfig] Wrote KubeConfig file to disk: ""admin.conf""\r\n[kubeconfig] Wrote KubeConfig file to disk: ""kubelet.conf""\r\n[kubeconfig] Wrote KubeConfig file to disk: ""controller-manager.conf""\r\n[kubeconfig] Wrote KubeConfig file to disk: ""scheduler.conf""\r\n[controlplane] Wrote Static Pod manifest for component kube-apiserver to ""/etc/kubernetes/manifests/kube-apiserver.yaml""\r\n[controlplane] Wrote Static Pod manifest for component kube-controller-manager to ""/etc/kubernetes/manifests/kube-controller-manager.yaml""\r\n[controlplane] Wrote Static Pod manifest for component kube-scheduler to ""/etc/kubernetes/manifests/kube-scheduler.yaml""\r\n[etcd] Wrote Static Pod manifest for a local etcd instance to ""/etc/kubernetes/manifests/etcd.yaml""\r\n[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory ""/etc/kubernetes/manifests"".\r\n[init] This might take a minute or longer if the control plane images have to be pulled.\r\n[kubelet-check] It seems like the kubelet isn\'t running or healthy.\r\n[kubelet-check] The HTTP call equal to \'curl -sSL http://localhost:10255/healthz\' failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.\r\n[kubelet-check] It seems like the kubelet isn\'t running or healthy.\r\n[kubelet-check] The HTTP call equal to \'curl -sSL http://localhost:10255/healthz\' failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.\r\n[kubelet-check] It seems like the kubelet isn\'t running or healthy.\r\n[kubelet-check] The HTTP call equal to \'curl -sSL http://localhost:10255/healthz\' failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.\r\n[kubelet-check] It seems like the kubelet isn\'t running or healthy.\r\n[kubelet-check] The HTTP call equal to \'curl -sSL http://localhost:10255/healthz/syncloop\' failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.\r\n[kubelet-check] It seems like the kubelet isn\'t running or healthy.\r\n[kubelet-check] The HTTP call equal to \'curl -sSL http://localhost:10255/healthz/syncloop\' failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.\r\n[kubelet-check] It seems like the kubelet isn\'t running or healthy.\r\n[kubelet-check] The HTTP call equal to \'curl -sSL http://localhost:10255/healthz/syncloop\' failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.\r\n[kubelet-check] It seems like the kubelet isn\'t running or healthy.\r\n[kubelet-check] The HTTP call equal to \'curl -sSL http://localhost:10255/healthz\' failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.\r\n[kubelet-check] It seems like the kubelet isn\'t running or healthy.\r\n[kubelet-check] The HTTP call equal to \'curl -sSL http://localhost:10255/healthz/syncloop\' failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.\r\n[kubelet-check] It seems like the kubelet isn\'t running or healthy.\r\n[kubelet-check] The HTTP call equal to \'curl -sSL http://localhost:10255/healthz\' failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.\r\n\r\nUnfortunately, an error has occurred:\r\n\ttimed out waiting for the condition\r\n\r\nThis error is likely caused by:\r\n\t- The kubelet is not running\r\n\t- The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)\r\n\t- There is no internet connection, so the kubelet cannot pull the following control plane images:\r\n\t\t- gcr.io/google_containers/kube-apiserver-amd64:v1.9.1\r\n\t\t- gcr.io/google_containers/kube-controller-manager-amd64:v1.9.1\r\n\t\t- gcr.io/google_containers/kube-scheduler-amd64:v1.9.1\r\n\r\nIf you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:\r\n\t- \'systemctl status kubelet\'\r\n\t- \'journalctl -xeu kubelet\'\r\ncouldn\'t initialize a Kubernetes cluster\r\n```\r\n\r\nAnd `jouralctl -u kubelet` snippet:\r\n```\r\nJan 08 17:45:18 simulator4 kubelet[6942]: I0108 17:45:18.760906    6942 docker_service.go:232] Docker cri networking managed by cni\r\nJan 08 17:45:18 simulator4 kubelet[6942]: I0108 17:45:18.770387    6942 docker_service.go:237] Docker Info: &{ID:VUXN:LVWA:AWK7:BYAM:L4W7:AEOV:LUL6:AL26:VYR2:26JP:EM2E:E4SB Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:0 Driver:aufs \r\nJan 08 17:45:18 simulator4 kubelet[6942]: error: failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: ""cgroupfs"" is different from docker cgroup driver: ""systemd""\r\nJan 08 17:45:18 simulator4 systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE\r\nJan 08 17:45:18 simulator4 systemd[1]: kubelet.service: Unit entered failed state.\r\nJan 08 17:45:18 simulator4 systemd[1]: kubelet.service: Failed with result \'exit-code\'.\r\n[Truncated]\n```\r\n# docker version\r\nClient:\r\n Version:      17.03.2-ce\r\n API version:  1.27\r\n Go version:   go1.7.5\r\n Git commit:   f5ec1e2\r\n Built:        Tue Jun 27 03:35:14 2017\r\n OS/Arch:      linux/amd64\r\n\r\nServer:\r\n Version:      17.03.2-ce\r\n API version:  1.27 (minimum version 1.12)\r\n Go version:   go1.7.5\r\n Git commit:   f5ec1e2\r\n Built:        Tue Jun 27 03:35:14 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\n```\r\nThe same problem happened when I used 1.13.0.', 'title': 'Issue with k8s.io/docs/setup/independent/create-cluster-kubeadm/', 'type': 'issue'}
 {'action': 'created', 'author': 'zhangxiaoyu-zidif', 'comment_id': 356165522.0, 'datetime': '2018-01-09 03:00:18+00:00', 'masked_author': 'username_1', 'text': '/cc @luxas @username_3', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'stewart-yu', 'comment_id': 356177308.0, 'datetime': '2018-01-09 04:32:38+00:00', 'masked_author': 'username_2', 'text': 'I think it should resolve manually', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'z-oo', 'comment_id': 356214767.0, 'datetime': '2018-01-09 08:32:38+00:00', 'masked_author': 'username_0', 'text': 'Hmm, I did not see the troubleshooting page previous. Thanks for pointing me to the it.\r\n\r\nAfter I read that page, I don\'t think the page directly solve my problem and probably requires update to address my problem. I can see two sections related to my problem:\r\n1) ""kubeadm blocks waiting for control plane during installation"" section. It address the problem when kubelet has cgroup ""systemd"" while docker has cgroup ""cgroupfs"". This can be solved by configuring docker. However, my problem is that kubelet has cgroup ""cgroupfs"" while docker has cgropu ""systemd"". So this section is not relevant.\r\n1.1) In addition, this section\'s link to ""installing docker"" is invalid.\r\n\r\n2) ""Errors on CentOS when setting up masters"". This section talks exact problem I am facing. However,\r\n2.1) my problem occurs on Ubuntu instead of CentOs, so this section can be easily missed.\r\n2.2) the commandline (`sed ...` replacement) won\'t work in the default configuration because `--cgroup-driver` flag does not exist at all in `10-kubeadm.conf` file. The right solution is to add `--cgroup-driver` flag.\r\n\r\nAfter all, I wonder whether this is a problem specific to me or everyone using ubuntu 16.04 + kubernetes / kubeadm 1.9.1. I strictly followed the instruction on freshly installed Ubuntus and I suspect it would happen to many other people. If it is common enough, IMHO this should belong to the main article rather than troubleshooting.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'stewart-yu', 'comment_id': 356216595.0, 'datetime': '2018-01-09 08:40:49+00:00', 'masked_author': 'username_2', 'text': ""That's same. first, run `docker info`, you can see docker's cgroup; secondary, run `vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf`,  edit and make `cgroup-driver=systemd` \r\nI will fix  troubeshooting ASAP."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'xiangpengzhao', 'comment_id': 356219960.0, 'datetime': '2018-01-09 08:55:02+00:00', 'masked_author': 'username_3', 'text': '@username_2 :+1:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'PhoenixAD', 'comment_id': 361489072.0, 'datetime': '2018-01-30 06:20:57+00:00', 'masked_author': 'username_4', 'text': ""@username_0 Did you solve this problem? I'm facing the same problem."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'z-oo', 'comment_id': 361706225.0, 'datetime': '2018-01-30 19:27:10+00:00', 'masked_author': 'username_0', 'text': ""@username_4 Yes. As in the proposed solution, you want to add a flag `--cgroup-driver=systemd` to `/etc/systemd/system/kubelet.service.d/10-kubeadm.conf`\r\n\r\n@username_2 the real problem is not fixed. The troubleshooting document talks about the case when kubelet uses cgroup driver `systemd` while the docker uses cgroup driver `cgroupfs`. But when I follow the setup instruction on Ubuntu, the result the the other way around -- kubelet uses cgroup driver `cgroupfs` and docker uses cgroup driver `systemd`. In this case the troubleshooting document isn't useful."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'george-peng-git', 'comment_id': 364850033.0, 'datetime': '2018-02-12 07:58:40+00:00', 'masked_author': 'username_5', 'text': 'I had exactly the same problem. It is found by following the instructions on Ubuntu 16.04, kubelet 1.9.2 uses `cgroupfs` by default rather than `systemd`, causing inconsistencies between kubelet and docker. I had to recover the docker settings to use `cgroupfs` and to restart the kubelet service to resolve the problem.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'nickezekias', 'comment_id': 1003297919.0, 'datetime': '2021-12-31 07:42:09+00:00', 'masked_author': 'username_6', 'text': ""Second as for the cgroups instructions mentioned on the installation page, I never read it, because supposedly installing docker beforehand, Kubernetes detects it as container runtime, so you don't need to mess with cgroups `configurations. And also as a beginner with Kubernetes, simply warning me that cgroups had to match on the install page, would never had lead me to fixing this issue, unless I had googled around on the said instruction.\r\n\r\nWith that being said, I'm suggesting the [**kubeadm blocks waiting for control plane during installation**](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#kubeadm-blocks-waiting-for-control-plane-during-installation) section in the troubleshooting page, should simply refer to this GitHub issue as it directly explains and solves the problem, and would probably save Kubernetes newbies a lot of time and frustration."", 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Issue with k8s.io/docs/setup/independent/create-cluster-kubeadm/
username_0: <!-- Thanks for filing an issue! Before submitting, please fill in the following information. -->

<!--Required Information-->

**This is a...** 
<!-- choose one by changing [ ] to [x] -->
- [ ] Feature Request
- [x] Bug Report

**Problem:**
I followed this instruction on a freshly installed Ubuntu 16.04 machine and it did not work. It was stuck on `kubeadm init` step. I need to manually specify kubelet flag `--cgroup-driver=systemd`. This seems very reproducible and it happened to all my freshly installed ubuntu if I follow the instruction.

```
# kubeadm init
[init] Using Kubernetes version: v1.9.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks.
	[WARNING FileExisting-crictl]: crictl not found in system path
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [simulator4 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.1.1.114]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in ""/etc/kubernetes/pki""
[kubeconfig] Wrote KubeConfig file to disk: ""admin.conf""
[kubeconfig] Wrote KubeConfig file to disk: ""kubelet.conf""
[kubeconfig] Wrote KubeConfig file to disk: ""controller-manager.conf""
[kubeconfig] Wrote KubeConfig file to disk: ""scheduler.conf""
[controlplane] Wrote Static Pod manifest for component kube-apiserver to ""/etc/kubernetes/manifests/kube-apiserver.yaml""
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to ""/etc/kubernetes/manifests/kube-controller-manager.yaml""
[controlplane] Wrote Static Pod manifest for component kube-scheduler to ""/etc/kubernetes/manifests/kube-scheduler.yaml""
[etcd] Wrote Static Pod manifest for a local etcd instance to ""/etc/kubernetes/manifests/etcd.yaml""
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory ""/etc/kubernetes/manifests"".
[init] This might take a minute or longer if the control plane images have to be pulled.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10255/healthz' failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10255/healthz' failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10255/healthz' failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10255/healthz/syncloop' failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10255/healthz/syncloop' failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10255/healthz/syncloop' failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10255/healthz' failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10255/healthz/syncloop' failed with error: Get http://localhost:10255/healthz/syncloop: dial tcp [::1]:10255: getsockopt: connection refused.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10255/healthz' failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.

Unfortunately, an error has occurred:
	timed out waiting for the condition

This error is likely caused by:
	- The kubelet is not running
	- The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)
	- There is no internet connection, so the kubelet cannot pull the following control plane images:
		- gcr.io/google_containers/kube-apiserver-amd64:v1.9.1
		- gcr.io/google_containers/kube-controller-manager-amd64:v1.9.1
		- gcr.io/google_containers/kube-scheduler-amd64:v1.9.1

If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:
	- 'systemctl status kubelet'
	- 'journalctl -xeu kubelet'
couldn't initialize a Kubernetes cluster
```

And `jouralctl -u kubelet` snippet:
```
Jan 08 17:45:18 simulator4 kubelet[6942]: I0108 17:45:18.760906    6942 docker_service.go:232] Docker cri networking managed by cni
Jan 08 17:45:18 simulator4 kubelet[6942]: I0108 17:45:18.770387    6942 docker_service.go:237] Docker Info: &{ID:VUXN:LVWA:AWK7:BYAM:L4W7:AEOV:LUL6:AL26:VYR2:26JP:EM2E:E4SB Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:0 Driver:aufs 
Jan 08 17:45:18 simulator4 kubelet[6942]: error: failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: ""cgroupfs"" is different from docker cgroup driver: ""systemd""
Jan 08 17:45:18 simulator4 systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Jan 08 17:45:18 simulator4 systemd[1]: kubelet.service: Unit entered failed state.
Jan 08 17:45:18 simulator4 systemd[1]: kubelet.service: Failed with result 'exit-code'.
[Truncated]
```
# docker version
Client:
 Version:      17.03.2-ce
 API version:  1.27
 Go version:   go1.7.5
 Git commit:   f5ec1e2
 Built:        Tue Jun 27 03:35:14 2017
 OS/Arch:      linux/amd64

Server:
 Version:      17.03.2-ce
 API version:  1.27 (minimum version 1.12)
 Go version:   go1.7.5
 Git commit:   f5ec1e2
 Built:        Tue Jun 27 03:35:14 2017
 OS/Arch:      linux/amd64
 Experimental: false
```
The same problem happened when I used 1.13.0.
<issue_comment>username_1: /cc @luxas @username_3
<issue_comment>username_2: I think it should resolve manually
<issue_comment>username_0: Hmm, I did not see the troubleshooting page previous. Thanks for pointing me to the it.

After I read that page, I don't think the page directly solve my problem and probably requires update to address my problem. I can see two sections related to my problem:
1) ""kubeadm blocks waiting for control plane during installation"" section. It address the problem when kubelet has cgroup ""systemd"" while docker has cgroup ""cgroupfs"". This can be solved by configuring docker. However, my problem is that kubelet has cgroup ""cgroupfs"" while docker has cgropu ""systemd"". So this section is not relevant.
1.1) In addition, this section's link to ""installing docker"" is invalid.

2) ""Errors on CentOS when setting up masters"". This section talks exact problem I am facing. However,
2.1) my problem occurs on Ubuntu instead of CentOs, so this section can be easily missed.
2.2) the commandline (`sed ...` replacement) won't work in the default configuration because `--cgroup-driver` flag does not exist at all in `10-kubeadm.conf` file. The right solution is to add `--cgroup-driver` flag.

After all, I wonder whether this is a problem specific to me or everyone using ubuntu 16.04 + kubernetes / kubeadm 1.9.1. I strictly followed the instruction on freshly installed Ubuntus and I suspect it would happen to many other people. If it is common enough, IMHO this should belong to the main article rather than troubleshooting.
<issue_comment>username_2: That's same. first, run `docker info`, you can see docker's cgroup; secondary, run `vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf`,  edit and make `cgroup-driver=systemd` 
I will fix  troubeshooting ASAP.
<issue_comment>username_3: @username_2 :+1:
<issue_comment>username_4: @username_0 Did you solve this problem? I'm facing the same problem.
<issue_comment>username_0: @username_4 Yes. As in the proposed solution, you want to add a flag `--cgroup-driver=systemd` to `/etc/systemd/system/kubelet.service.d/10-kubeadm.conf`

@username_2 the real problem is not fixed. The troubleshooting document talks about the case when kubelet uses cgroup driver `systemd` while the docker uses cgroup driver `cgroupfs`. But when I follow the setup instruction on Ubuntu, the result the the other way around -- kubelet uses cgroup driver `cgroupfs` and docker uses cgroup driver `systemd`. In this case the troubleshooting document isn't useful.
<issue_comment>username_5: I had exactly the same problem. It is found by following the instructions on Ubuntu 16.04, kubelet 1.9.2 uses `cgroupfs` by default rather than `systemd`, causing inconsistencies between kubelet and docker. I had to recover the docker settings to use `cgroupfs` and to restart the kubelet service to resolve the problem.
<issue_comment>username_6: Second as for the cgroups instructions mentioned on the installation page, I never read it, because supposedly installing docker beforehand, Kubernetes detects it as container runtime, so you don't need to mess with cgroups `configurations. And also as a beginner with Kubernetes, simply warning me that cgroups had to match on the install page, would never had lead me to fixing this issue, unless I had googled around on the said instruction.

With that being said, I'm suggesting the [**kubeadm blocks waiting for control plane during installation**](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#kubeadm-blocks-waiting-for-control-plane-during-installation) section in the troubleshooting page, should simply refer to this GitHub issue as it directly explains and solves the problem, and would probably save Kubernetes newbies a lot of time and frustration."
mono/website,157250631,210,,"[{'action': 'opened', 'author': 'heiligerdankgesang', 'comment_id': None, 'datetime': '2016-05-27 17:06:45+00:00', 'masked_author': 'username_0', 'text': 'DotNetPowered.com link (http://www.dotnetpowered.com/languages.aspx) on http://mono-framework.com/Languages is broken.', 'title': 'Broken link on http://mono-framework.com/Languages', 'type': 'issue'}
 {'action': 'created', 'author': 'akoeplinger', 'comment_id': 222201286.0, 'datetime': '2016-05-27 17:08:10+00:00', 'masked_author': 'username_1', 'text': ""http://mono-framework.com/ is not a page that should be used (I'll figure out internally why it's still online). The Mono website is at http://www.mono-project.com."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'heiligerdankgesang', 'comment_id': 223115953.0, 'datetime': '2016-06-01 20:33:25+00:00', 'masked_author': 'username_0', 'text': ""Didn't even realize that. Thanks for looking into it."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'akoeplinger', 'comment_id': 241837059.0, 'datetime': '2016-08-23 18:50:00+00:00', 'masked_author': 'username_1', 'text': 'There is a redirect in place for http://mono-framework.com now. Thanks.', 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'akoeplinger', 'comment_id': None, 'datetime': '2016-08-23 18:50:00+00:00', 'masked_author': 'username_1', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'created', 'author': 'heiligerdankgesang', 'comment_id': 241938462.0, 'datetime': '2016-08-24 02:13:44+00:00', 'masked_author': 'username_0', 'text': 'Thanks Alex!', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Broken link on http://mono-framework.com/Languages
username_0: DotNetPowered.com link (http://www.dotnetpowered.com/languages.aspx) on http://mono-framework.com/Languages is broken.
<issue_comment>username_1: http://mono-framework.com/ is not a page that should be used (I'll figure out internally why it's still online). The Mono website is at http://www.mono-project.com.
<issue_comment>username_0: Didn't even realize that. Thanks for looking into it.
<issue_comment>username_1: There is a redirect in place for http://mono-framework.com now. Thanks.<issue_closed>
<issue_comment>username_0: Thanks Alex!"
kubernetes/website,996648183,29713,,"[{'action': 'opened', 'author': 'hantsy', 'comment_id': None, 'datetime': '2021-09-15 04:30:41+00:00', 'masked_author': 'username_0', 'text': 'Windows 10 \r\nPowerShell with admin privileges\r\n\r\n```bash\r\nminikube start --registry-mirror=""https://hub-mirror.c.163.com""  --image-mirror-country=""cn""  --driver=hyperv\r\n* minikube v1.23.0 on Microsoft Windows 10 Pro 10.0.19043 Build 19043\r\n* Using the hyperv driver based on user configuration\r\n* Using image repository registry.cn-hangzhou.aliyuncs.com/google_containers\r\n* Starting control plane node minikube in cluster minikube\r\n* Creating hyperv VM (CPUs=2, Memory=6144MB, Disk=20000MB) ...\r\n! The image \'registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetesui/dashboard:v2.1.0\' was not found; unable to add it to cache.\r\n! The image \'registry.cn-hangzhou.aliyuncs.com/google_containers/coredns/coredns:v1.8.4\' was not found; unable to add it to cache.\r\n! The image \'registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetesui/metrics-scraper:v1.0.4\' was not found; unable to add it to cache.\r\n! The image \'registry.cn-hangzhou.aliyuncs.com/google_containers/k8s-minikube/storage-provisioner:v5\' was not found; unable to add it to cache.\r\n! This VM is having trouble accessing https://registry.cn-hangzhou.aliyuncs.com/google_containers\r\n* To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/\r\n* Preparing Kubernetes v1.22.1 on Docker 20.10.8 ...\r\nX Unable to load cached images: loading cached images: CreateFile C:\\Users\\username_0\\.minikube\\cache\\images\\registry.cn-hangzhou.aliyuncs.com\\google_containers\\kubernetesui\\dashboard_v2.1.0: The system cannot find the file specified.\r\n! initialization failed, will try again: wait: /bin/bash -c ""sudo env PATH=/var/lib/minikube/binaries/v1.22.1:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,Mem"": Process exited with status 1\r\nstdout:\r\n[init] Using Kubernetes version: v1.22.1\r\n[preflight] Running pre-flight checks\r\n[preflight] Pulling images required for setting up a Kubernetes cluster\r\n[preflight] This might take a minute or two, depending on the speed of your internet connection\r\n[preflight] You can also perform this action in beforehand using \'kubeadm config images pull\'\r\n\r\nstderr:\r\n        [WARNING Service-Kubelet]: kubelet service is not enabled, please run \'systemctl enable kubelet.service\'\r\nerror execution phase preflight: [preflight] Some fatal errors occurred:\r\n        [ERROR ImagePull]: failed to pull image registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4: output: Error response from daemon: manifest for registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4 not found: manifest unknown: manifest unknown\r\n, error: exit status 1\r\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\r\nTo see the stack trace of this error execute with --v=5 or higher\r\n\r\n*\r\nX Error starting cluster: wait: /bin/bash -c ""sudo env PATH=/var/lib/minikube/binaries/v1.22.1:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,Mem"": Process exited with status 1\r\nstdout:\r\n[init] Using Kubernetes version: v1.22.1\r\n[preflight] Running pre-flight checks\r\n[preflight] Pulling images required for setting up a Kubernetes cluster\r\n[preflight] This might take a minute or two, depending on the speed of your internet connection\r\n[preflight] You can also perform this action in beforehand using \'kubeadm config images pull\'\r\n\r\nstderr:\r\n        [WARNING Service-Kubelet]: kubelet service is not enabled, please run \'systemctl enable kubelet.service\'\r\nerror execution phase preflight: [preflight] Some fatal errors occurred:\r\n        [ERROR ImagePull]: failed to pull image registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4: output: Error response from daemon: manifest for registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4 not found: manifest unknown: manifest unknown\r\n, error: exit status 1\r\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\r\nTo see the stack trace of this error execute with --v=5 or higher\r\n\r\n*\r\n╭─────────────────────────────────────────────────────────────────────────────────────────────╮\r\n│                                                                                             │\r\n│    * If the above advice does not help, please let us know:                                 │\r\n│      https://github.com/kubernetes/minikube/issues/new/choose                               │\r\n│                                                                                             │\r\n│    * Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    │\r\n│                                                                                             │\r\n╰─────────────────────────────────────────────────────────────────────────────────────────────╯\r\n\r\nX Exiting due to GUEST_START: wait: /bin/bash -c ""sudo env PATH=/var/lib/minikube/binaries/v1.22.1:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,Mem"": Process exited with status 1\r\nstdout:\r\n[init] Using Kubernetes version: v1.22.1\r\n[preflight] Running pre-flight checks\r\n[preflight] Pulling images required for setting up a Kubernetes cluster\r\n[preflight] This might take a minute or two, depending on the speed of your internet connection\r\n[preflight] You can also perform this action in beforehand using \'kubeadm config images pull\'\r\n\r\nstderr:\r\n        [WARNING Service-Kubelet]: kubelet service is not enabled, please run \'systemctl enable kubelet.service\'\r\nerror execution phase preflight: [preflight] Some fatal errors occurred:\r\n        [ERROR ImagePull]: failed to pull image registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4: output: Error response from daemon: manifest for registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4 not found: manifest unknown: manifest unknown\r\n, error: exit status 1\r\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\r\nTo see the stack trace of this error execute with --v=5 or higher\r\n\r\n*\r\n╭─────────────────────────────────────────────────────────────────────────────────────────────╮\r\n│                                                                                             │                         │    * If the above advice does not help, please let us know:                                 │                         │      https://github.com/kubernetes/minikube/issues/new/choose                               │                         │                                                                                             │                         │    * Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    │                         │                                                                                             │\r\n╰─────────────────────────────────────────────────────────────────────────────────────────────╯\r\n```', 'title': 'Start failed in China even added mirror related parameters', 'type': 'issue'}
 {'action': 'created', 'author': 'sftim', 'comment_id': 919799145.0, 'datetime': '2021-09-15 08:12:13+00:00', 'masked_author': 'username_1', 'text': 'This looks like a support request\r\n/kind support', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'sftim', 'comment_id': 919799314.0, 'datetime': '2021-09-15 08:12:28+00:00', 'masked_author': 'username_1', 'text': '/remove-kind bug', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'neolit123', 'comment_id': 919817875.0, 'datetime': '2021-09-15 08:38:31+00:00', 'masked_author': 'username_2', 'text': 'Please use #minikube on k8s slack or log an issue in kubernetes/minikube.\n\n/close', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Start failed in China even added mirror related parameters
username_0: Windows 10 
PowerShell with admin privileges

```bash
minikube start --registry-mirror=""https://hub-mirror.c.163.com""  --image-mirror-country=""cn""  --driver=hyperv
* minikube v1.23.0 on Microsoft Windows 10 Pro 10.0.19043 Build 19043
* Using the hyperv driver based on user configuration
* Using image repository registry.cn-hangzhou.aliyuncs.com/google_containers
* Starting control plane node minikube in cluster minikube
* Creating hyperv VM (CPUs=2, Memory=6144MB, Disk=20000MB) ...
! The image 'registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetesui/dashboard:v2.1.0' was not found; unable to add it to cache.
! The image 'registry.cn-hangzhou.aliyuncs.com/google_containers/coredns/coredns:v1.8.4' was not found; unable to add it to cache.
! The image 'registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetesui/metrics-scraper:v1.0.4' was not found; unable to add it to cache.
! The image 'registry.cn-hangzhou.aliyuncs.com/google_containers/k8s-minikube/storage-provisioner:v5' was not found; unable to add it to cache.
! This VM is having trouble accessing https://registry.cn-hangzhou.aliyuncs.com/google_containers
* To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
* Preparing Kubernetes v1.22.1 on Docker 20.10.8 ...
X Unable to load cached images: loading cached images: CreateFile C:\Users\username_0\.minikube\cache\images\registry.cn-hangzhou.aliyuncs.com\google_containers\kubernetesui\dashboard_v2.1.0: The system cannot find the file specified.
! initialization failed, will try again: wait: /bin/bash -c ""sudo env PATH=/var/lib/minikube/binaries/v1.22.1:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,Mem"": Process exited with status 1
stdout:
[init] Using Kubernetes version: v1.22.1
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'

stderr:
        [WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
error execution phase preflight: [preflight] Some fatal errors occurred:
        [ERROR ImagePull]: failed to pull image registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4: output: Error response from daemon: manifest for registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4 not found: manifest unknown: manifest unknown
, error: exit status 1
[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
To see the stack trace of this error execute with --v=5 or higher

*
X Error starting cluster: wait: /bin/bash -c ""sudo env PATH=/var/lib/minikube/binaries/v1.22.1:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,Mem"": Process exited with status 1
stdout:
[init] Using Kubernetes version: v1.22.1
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'

stderr:
        [WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
error execution phase preflight: [preflight] Some fatal errors occurred:
        [ERROR ImagePull]: failed to pull image registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4: output: Error response from daemon: manifest for registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4 not found: manifest unknown: manifest unknown
, error: exit status 1
[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
To see the stack trace of this error execute with --v=5 or higher

*
╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│                                                                                             │
│    * If the above advice does not help, please let us know:                                 │
│      https://github.com/kubernetes/minikube/issues/new/choose                               │
│                                                                                             │
│    * Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    │
│                                                                                             │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯

X Exiting due to GUEST_START: wait: /bin/bash -c ""sudo env PATH=/var/lib/minikube/binaries/v1.22.1:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,Mem"": Process exited with status 1
stdout:
[init] Using Kubernetes version: v1.22.1
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'

stderr:
        [WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
error execution phase preflight: [preflight] Some fatal errors occurred:
        [ERROR ImagePull]: failed to pull image registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4: output: Error response from daemon: manifest for registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4 not found: manifest unknown: manifest unknown
, error: exit status 1
[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
To see the stack trace of this error execute with --v=5 or higher

*
╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│                                                                                             │                         │    * If the above advice does not help, please let us know:                                 │                         │      https://github.com/kubernetes/minikube/issues/new/choose                               │                         │                                                                                             │                         │    * Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    │                         │                                                                                             │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯
```
<issue_comment>username_1: This looks like a support request
/kind support
<issue_comment>username_1: /remove-kind bug
<issue_comment>username_2: Please use #minikube on k8s slack or log an issue in kubernetes/minikube.

/close"
ethereum/ethereum-org-website,1071773341,4654,"{'number': 4654.0, 'repo': 'ethereum-org-website', 'user_login': 'ethereum'}","[{'action': 'opened', 'author': 'skylarweaver', 'comment_id': None, 'datetime': '2021-12-06T06:18:23Z', 'masked_author': 'username_0', 'text': 'This is my suggestion for addressing #3020 \r\n\r\nEssentially I just used [Carl\'s article](https://blog.ethereum.org/2021/05/18/country-power-no-more/) and adapted it very slightly (removed first-person language and some other slight modifications to make it a bit more formal).\r\n\r\n**I think there is no better way to address the environmental impact FUD than 1) _primarily_ focusing on how much the switch to PoS will reduce Ethereum\'s energy impact, and 2) then _secondarily_ focusing on the current impact of PoW. Carl\'s article does this very well IMO.**\r\n\r\n**Some thoughts:**\r\n* In the ""Some Comparisons"" part he references ""Digiconomist."" It\'s [been cited that this is not accurate](https://twitter.com/0xstark/status/1455694988507971587). This [more recent estimate](https://kylemcdonald.github.io/ethereum-emissions/) is supposedly more accurate. I think it would be prudent to reach out to Carl and see if/how we should update the estimates to reflect these new numbers.\r\n* This PR is just a markdown file —\xa0I couldn\'t figure out how to get the routing working soooo right now nothing links to this page. Will need additional dev work to add the routes — I can do it if someone can help me troubleshoot but maybe easier for someone more familiar with the codebase to do it.\r\n* Perhaps it would be better titled ""Ethereum & the Environment"" or ""Environmental Impact"". Maybe the team can check SEO results and see which one gets more hits. Maybe a combo btwn ""Energy Use & Environment""?\r\n\r\nThis is just a quick proposal to get something moving here. Other suggestions, edits, modifications welcome. If we want to go another route than using Carl\'s blog post, I understand that too.', 'title': 'Add page about energy use post-merge [Issue #3020]', 'type': 'issue'}
 {'action': 'created', 'author': 'samajammin', 'comment_id': 989230012.0, 'datetime': '2021-12-08 21:51:15+00:00', 'masked_author': 'username_1', 'text': ""Awesome - thanks for opening this @username_0!\r\n\r\nWe already have a WIP PR that addresses this same issue - see https://github.com/ethereum/ethereum-org-website/pull/3650\r\n\r\nGiven that page is close to getting merged, I'd suggest we stick with that. Is there anything you'd like to add to that page from this PR you created?"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'minimalsm', 'comment_id': 994924562.0, 'datetime': '2021-12-15 15:55:34+00:00', 'masked_author': 'username_2', 'text': 'Closing as discussed in #3650', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Add page about energy use post-merge [Issue #3020]
username_0: This is my suggestion for addressing #3020 

Essentially I just used [Carl's article](https://blog.ethereum.org/2021/05/18/country-power-no-more/) and adapted it very slightly (removed first-person language and some other slight modifications to make it a bit more formal).

**I think there is no better way to address the environmental impact FUD than 1) _primarily_ focusing on how much the switch to PoS will reduce Ethereum's energy impact, and 2) then _secondarily_ focusing on the current impact of PoW. Carl's article does this very well IMO.**

**Some thoughts:**
* In the ""Some Comparisons"" part he references ""Digiconomist."" It's [been cited that this is not accurate](https://twitter.com/0xstark/status/1455694988507971587). This [more recent estimate](https://kylemcdonald.github.io/ethereum-emissions/) is supposedly more accurate. I think it would be prudent to reach out to Carl and see if/how we should update the estimates to reflect these new numbers.
* This PR is just a markdown file — I couldn't figure out how to get the routing working soooo right now nothing links to this page. Will need additional dev work to add the routes — I can do it if someone can help me troubleshoot but maybe easier for someone more familiar with the codebase to do it.
* Perhaps it would be better titled ""Ethereum & the Environment"" or ""Environmental Impact"". Maybe the team can check SEO results and see which one gets more hits. Maybe a combo btwn ""Energy Use & Environment""?

This is just a quick proposal to get something moving here. Other suggestions, edits, modifications welcome. If we want to go another route than using Carl's blog post, I understand that too.
<issue_comment>username_1: Awesome - thanks for opening this @username_0!

We already have a WIP PR that addresses this same issue - see https://github.com/ethereum/ethereum-org-website/pull/3650

Given that page is close to getting merged, I'd suggest we stick with that. Is there anything you'd like to add to that page from this PR you created?
<issue_comment>username_2: Closing as discussed in #3650"
