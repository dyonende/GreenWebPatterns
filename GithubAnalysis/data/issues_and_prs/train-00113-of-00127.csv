clearlydefined/website,334251417,174,,"[{'action': 'opened', 'author': 'fossygirl', 'comment_id': None, 'datetime': '2018-06-20 21:12:41+00:00', 'masked_author': 'username_0', 'text': 'GitHub is great but as the list of contributions grows, managing a flat list of PRs becomes complicated. As a user of clearlydefined.io, in particular, as a curator, users would find it super convenient if the site had an easy to use experience that allows them to sort and filter contributions to find just the ones in which they are interested. Much like the sorting and filtering on the definition list, users should be able  to discriminate based on time, type, provider, contributor, score of the current definition, ‚Ä¶ This helps them focus my review energy. They should be able to save their ‚Äúquery‚Äù (e.g., filter and sort settings) in the form of a URL that they can bookmark or otherwise save and easily re-load.\r\n \r\nThe list of discovered contributions should expose summary information such as number and type of definitions modified, contributor, etc. It would also be great if from the list of contributions, they are easily able to select one and open it in the view/review modes as if they opened it from the GitHub PR. This would allow them to see the net effect of the proposed changes and perform review/curation operations.', 'title': 'Contribution management', 'type': 'issue'}
 {'action': 'created', 'author': 'storrisi', 'comment_id': 463548392.0, 'datetime': '2019-02-14 09:04:58+00:00', 'masked_author': 'username_1', 'text': ""@username_0 this looks like to have some key points that should be discussed in order to be developed.\r\n\r\nI'm thinking if the new Browse page is currently solving some of the requirements here?"", 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Contribution management
username_0: GitHub is great but as the list of contributions grows, managing a flat list of PRs becomes complicated. As a user of clearlydefined.io, in particular, as a curator, users would find it super convenient if the site had an easy to use experience that allows them to sort and filter contributions to find just the ones in which they are interested. Much like the sorting and filtering on the definition list, users should be able  to discriminate based on time, type, provider, contributor, score of the current definition, ‚Ä¶ This helps them focus my review energy. They should be able to save their ‚Äúquery‚Äù (e.g., filter and sort settings) in the form of a URL that they can bookmark or otherwise save and easily re-load.
 
The list of discovered contributions should expose summary information such as number and type of definitions modified, contributor, etc. It would also be great if from the list of contributions, they are easily able to select one and open it in the view/review modes as if they opened it from the GitHub PR. This would allow them to see the net effect of the proposed changes and perform review/curation operations.
<issue_comment>username_1: @username_0 this looks like to have some key points that should be discussed in order to be developed.

I'm thinking if the new Browse page is currently solving some of the requirements here?"
jscraftcamp/website,553135598,822,,"[{'action': 'opened', 'author': 'Narigo', 'comment_id': None, 'datetime': '2020-01-21 21:19:00+00:00', 'masked_author': 'username_0', 'text': ""## Why Snacks?\r\n\r\nThe night before was a party. If the attendees don't need a snack now, they must have some other secret sauce to get their bodies back up to speed. But many rely on a sponsor to help out and prevent a low blood sugar by providing quick energy refilling snacks in the form of sweets, baked goods and candy. Keep those hard working brains happy - either by choosing yourself what to get or just leave it up to us to find the right sugar-bombs!\r\n\r\n## How does it work?\r\n\r\nCost ~100,- depending on what the sponsor orders.\r\nIdeally the sponsor orders the snacks, to be delivered to the location. Feel free to ask us in this ticket about details.\r\n\r\nLast year we asked some food companies for offers and had the sponsor confirm that amount up front. Once the food was delivered on the day the sponsor pulled out the credit card and made all attendees happy by enabling them to making the blood sugar level catch up."", 'title': 'Sponsor needed for snacks on Saturday üçåüçéüç™üçêüç©üç¶ - üí∞', 'type': 'issue'}]","<issue_start><issue_comment>Title: Sponsor needed for snacks on Saturday üçåüçéüç™üçêüç©üç¶ - üí∞
username_0: ## Why Snacks?

The night before was a party. If the attendees don't need a snack now, they must have some other secret sauce to get their bodies back up to speed. But many rely on a sponsor to help out and prevent a low blood sugar by providing quick energy refilling snacks in the form of sweets, baked goods and candy. Keep those hard working brains happy - either by choosing yourself what to get or just leave it up to us to find the right sugar-bombs!

## How does it work?

Cost ~100,- depending on what the sponsor orders.
Ideally the sponsor orders the snacks, to be delivered to the location. Feel free to ask us in this ticket about details.

Last year we asked some food companies for offers and had the sponsor confirm that amount up front. Once the food was delivered on the day the sponsor pulled out the credit card and made all attendees happy by enabling them to making the blood sugar level catch up."
girldevelopit/gdi-website,165835204,474,,"[{'action': 'opened', 'author': 'LaVonnaR', 'comment_id': None, 'datetime': '2016-07-15 17:11:00+00:00', 'masked_author': 'username_0', 'text': 'Please add the following bio and photo to the about page. Thank you!\r\n\r\nBindu Jallabah, Operations Director\r\n\r\nBindu is fervently passionate about developing ecosystems that empower disadvantaged communities in making informed, self-determined decisions. She has dedicated most of her career to advocating and developing pragmatic solutions that promote social equity ‚Äî particularly sustainable empowerment of women and advancing the rights of individuals with intellectual disabilities.\r\nBindu is a seasoned administrator with nearly two decades of progressive experience in nonprofit leadership and operations management. Prior to joining GDI, Bindu won awards for her work developing and executing the operational strategy for the Elwyn Baring Street Center.\r\nBindu is founder and Board Chair of Karanso Africa, a civil society organization that has innovated literacy to promote self-efficacy and self-determination for women across Sub-Saharan Africa. Leveraging a strong background in Information Technology, Bindu is architect of Karanso‚Äôs Docteur Mobile initiative which builds upon the use of mobile technology as a tool for self-care and advocacy to improve access to maternal and reproductive health services for vulnerable women in remote villages in West Africa.\r\n![bindu headshot - cropped](https://cloud.githubusercontent.com/assets/20444834/16880203/17e2b474-4a82-11e6-8cae-5e2198acb4b9.jpg)', 'title': 'Add Bindu bio & photo to About page', 'type': 'issue'}
 {'action': 'closed', 'author': 'kstack7', 'comment_id': None, 'datetime': '2016-07-19 02:56:56+00:00', 'masked_author': 'username_1', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'created', 'author': 'LaVonnaR', 'comment_id': 233949337.0, 'datetime': '2016-07-20 13:31:01+00:00', 'masked_author': 'username_0', 'text': ""Hi All,\n\nHappy Wednesday!\n\nApologies for being unfamiliar with github, but I received an email that\nthis issue was closed, however, Bindu's bio and photo are not up on the\nsite. Does closed mean the issue is resolved?\n\nBest,\nLaVonna"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kstack7', 'comment_id': 233986575.0, 'datetime': '2016-07-20 15:31:57+00:00', 'masked_author': 'username_1', 'text': 'Good question! This happened since my naming convention had a built-in ""fixes"" call that references an issue to close once merged. This task is present in staging at the moment, so you can review it here:  http://girl-develop-it-staging.herokuapp.com/about\r\n\r\nI\'m happy to avoid the ""fixes"" title in order to keep issues open until they\'re fully merged into production :)', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Add Bindu bio & photo to About page
username_0: Please add the following bio and photo to the about page. Thank you!

Bindu Jallabah, Operations Director

Bindu is fervently passionate about developing ecosystems that empower disadvantaged communities in making informed, self-determined decisions. She has dedicated most of her career to advocating and developing pragmatic solutions that promote social equity ‚Äî particularly sustainable empowerment of women and advancing the rights of individuals with intellectual disabilities.
Bindu is a seasoned administrator with nearly two decades of progressive experience in nonprofit leadership and operations management. Prior to joining GDI, Bindu won awards for her work developing and executing the operational strategy for the Elwyn Baring Street Center.
Bindu is founder and Board Chair of Karanso Africa, a civil society organization that has innovated literacy to promote self-efficacy and self-determination for women across Sub-Saharan Africa. Leveraging a strong background in Information Technology, Bindu is architect of Karanso‚Äôs Docteur Mobile initiative which builds upon the use of mobile technology as a tool for self-care and advocacy to improve access to maternal and reproductive health services for vulnerable women in remote villages in West Africa.
![bindu headshot - cropped](https://cloud.githubusercontent.com/assets/20444834/16880203/17e2b474-4a82-11e6-8cae-5e2198acb4b9.jpg)<issue_closed>
<issue_comment>username_0: Hi All,

Happy Wednesday!

Apologies for being unfamiliar with github, but I received an email that
this issue was closed, however, Bindu's bio and photo are not up on the
site. Does closed mean the issue is resolved?

Best,
LaVonna
<issue_comment>username_1: Good question! This happened since my naming convention had a built-in ""fixes"" call that references an issue to close once merged. This task is present in staging at the moment, so you can review it here:  http://girl-develop-it-staging.herokuapp.com/about

I'm happy to avoid the ""fixes"" title in order to keep issues open until they're fully merged into production :)"
facebook/docusaurus,983065296,5446,,"[{'action': 'opened', 'author': 'jasonbosco', 'comment_id': None, 'datetime': '2021-08-30 18:12:30+00:00', 'masked_author': 'username_0', 'text': ""## üí• Proposal\r\n\r\nThis is a proposal to add another search component option for Docusaurus users on this docs page: https://docusaurus.io/docs/search. \r\n\r\nI've customized the [built-in Algolia Docusaurus](https://www.npmjs.com/package/@docusaurus/theme-search-algolia) search component to work with Typesense in [this plugin](https://github.com/typesense/docusaurus-theme-search-typesense) and I think it would be useful to include instructions for how to use this alternate search plugin, in the official docs. \r\n\r\nFor context, [Typesense](https://github.com/typesense/typesense) is an open source alternative to Algolia that users can choose to self-host or use the managed SaaS version. Given that Docusaurus itself is open source, I think users would appreciate the ability to use another open source project to power their search as well. \r\n\r\n### Have you read the [Contributing Guidelines on issues](https://github.com/facebook/docusaurus/blob/master/CONTRIBUTING.md#reporting-new-issues)?\r\n\r\nYes."", 'title': 'Typesense Search Component', 'type': 'issue'}
 {'action': 'created', 'author': 'slorber', 'comment_id': 910164722.0, 'datetime': '2021-09-01 10:49:56+00:00', 'masked_author': 'username_1', 'text': ""Thanks for creating this plugin.\r\n\r\nUnfortunately, we don't want to document usage ourselves for a few reasons:\r\n- We are biased on purpose and have a long-term partnership with Algolia\r\n- We are quite sure Algolia will still be in the game in the upcoming years and will keep providing us doc updates, support, and integration\r\n- We don't want to document non-official third-party plugins that we don't create/use/maintain ourselves, unless there's a strong reason to do so. \r\n\r\nWe don't provide doc for local search plugins too, and only provide a list of links here: https://docusaurus.io/community/resources#search\r\n\r\nOnce the first doc PR is merged, the complaints about outdated doc will be Docusaurus maintainer's burden, and we don't want that. Similarly, we'll likely replace some doc about deployment options with links to their official doc.\r\n\r\nWhat I suggest:\r\n- We do not write Typesense documentation on the Docusaurus website: instead we link to Typesense official doc,, that you have the burden to keep up-to-date\r\n- Add your plugin to this list of links: https://docusaurus.io/community/resources#search\r\n- Make it clear that Algolia is not the only possible choice in https://docusaurus.io/docs/search\r\n- If Typesense becomes a successful Docusaurus theme, widely used, and with good long-term support, we could revisit this choice and document it officially. I'm also trying to get a `docusaurus-community` org on which we could move such plugins we plan to doc/maintain a bit more than regular third-party plugins.\r\n\r\nI'm going to close this, and am happy to merge any doc PR that gives your plugin (and other local search ones) better visibility, as long as we don't have to write the doc for it ourselves (and particularly maintain over time), and it's just linking to the official doc.\r\n\r\nAs you already have a [doc for Docusaurus](https://typesense.org/docs/0.21.0/guide/docsearch.html#option-a-docusaurus-powered-sites), linking to it seems a good idea, and it's now your burden to keep this link alive and up-to-date."", 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'slorber', 'comment_id': None, 'datetime': '2021-09-01 10:49:56+00:00', 'masked_author': 'username_1', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'created', 'author': 'jasonbosco', 'comment_id': 912877630.0, 'datetime': '2021-09-04 00:44:36+00:00', 'masked_author': 'username_0', 'text': ""Thank you for the detailed response @username_1. \r\n\r\nI understand the reasoning behind not including detailed instructions in the Docusaurus docs, but just link to Typesense's doc for now. I'll create a PR to update the docs following your guidelines above."", 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Typesense Search Component
username_0: ## üí• Proposal

This is a proposal to add another search component option for Docusaurus users on this docs page: https://docusaurus.io/docs/search. 

I've customized the [built-in Algolia Docusaurus](https://www.npmjs.com/package/@docusaurus/theme-search-algolia) search component to work with Typesense in [this plugin](https://github.com/typesense/docusaurus-theme-search-typesense) and I think it would be useful to include instructions for how to use this alternate search plugin, in the official docs. 

For context, [Typesense](https://github.com/typesense/typesense) is an open source alternative to Algolia that users can choose to self-host or use the managed SaaS version. Given that Docusaurus itself is open source, I think users would appreciate the ability to use another open source project to power their search as well. 

### Have you read the [Contributing Guidelines on issues](https://github.com/facebook/docusaurus/blob/master/CONTRIBUTING.md#reporting-new-issues)?

Yes.
<issue_comment>username_1: Thanks for creating this plugin.

Unfortunately, we don't want to document usage ourselves for a few reasons:
- We are biased on purpose and have a long-term partnership with Algolia
- We are quite sure Algolia will still be in the game in the upcoming years and will keep providing us doc updates, support, and integration
- We don't want to document non-official third-party plugins that we don't create/use/maintain ourselves, unless there's a strong reason to do so. 

We don't provide doc for local search plugins too, and only provide a list of links here: https://docusaurus.io/community/resources#search

Once the first doc PR is merged, the complaints about outdated doc will be Docusaurus maintainer's burden, and we don't want that. Similarly, we'll likely replace some doc about deployment options with links to their official doc.

What I suggest:
- We do not write Typesense documentation on the Docusaurus website: instead we link to Typesense official doc,, that you have the burden to keep up-to-date
- Add your plugin to this list of links: https://docusaurus.io/community/resources#search
- Make it clear that Algolia is not the only possible choice in https://docusaurus.io/docs/search
- If Typesense becomes a successful Docusaurus theme, widely used, and with good long-term support, we could revisit this choice and document it officially. I'm also trying to get a `docusaurus-community` org on which we could move such plugins we plan to doc/maintain a bit more than regular third-party plugins.

I'm going to close this, and am happy to merge any doc PR that gives your plugin (and other local search ones) better visibility, as long as we don't have to write the doc for it ourselves (and particularly maintain over time), and it's just linking to the official doc.

As you already have a [doc for Docusaurus](https://typesense.org/docs/0.21.0/guide/docsearch.html#option-a-docusaurus-powered-sites), linking to it seems a good idea, and it's now your burden to keep this link alive and up-to-date.<issue_closed>
<issue_comment>username_0: Thank you for the detailed response @username_1. 

I understand the reasoning behind not including detailed instructions in the Docusaurus docs, but just link to Typesense's doc for now. I'll create a PR to update the docs following your guidelines above."
reactiveui/website,249874531,22,,"[{'action': 'opened', 'author': 'ghuntley', 'comment_id': None, 'datetime': '2017-08-13 13:41:09+00:00', 'masked_author': 'username_0', 'text': 'Over in https://github.com/reactiveui/website/issues/16#issuecomment-322016434 \r\n\r\nKallyn brought this up:\r\n```\r\nIMO if I was someone who never knew about ReactiveUI or what it does, the homepage would be the most confusing. So, there are a couple of things that I would change with it:\r\n\r\n1. The one-liner explanation only tells me that ReactiveUI is a ""advanced, composable, and functional MVVM framework"". As far as I\'m aware, that\'s pretty much what every MVVM framework is (apart from the functional side). Maybe it would be better to focus on what ReactiveUI gives them? (e.g. ""Gives you the power to build reactive, testable, and composable UI code using the familiar MVVM pattern"")\r\n2. Our list of features is below the community section. While I appreciate how much community is at the center of ReactiveUI, I\'m assuming a lot of users don\'t really care at the moment they are trying to learn what ReactiveUI is and does for them.\r\n3. We don\'t have a call to action. For what it\'s worth, I think this could simply be a prominent link to some getting started docs. The purpose is primarily to give them an avenue to learn more.\r\n\r\nI could draft up these changes so we can discuss in a PR if anyone wants that too.\r\n```', 'title': ""The homepage needs lot's of improvement"", 'type': 'issue'}
 {'action': 'created', 'author': 'ghuntley', 'comment_id': 322042896.0, 'datetime': '2017-08-13 13:41:40+00:00', 'masked_author': 'username_0', 'text': ""üëç open PR's early + happy to jump in a video call and pair with you on this stuff."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'cabauman', 'comment_id': 708913245.0, 'datetime': '2020-10-15 05:48:41+00:00', 'masked_author': 'username_1', 'text': ""Looks like I don't have permission to close this, but I'd say this issue is resolved now, seeing the numerous linked PRs."", 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'cabauman', 'comment_id': None, 'datetime': '2020-10-15 06:44:32+00:00', 'masked_author': 'username_1', 'text': '', 'title': None, 'type': 'issue'}]","<issue_start><issue_comment>Title: The homepage needs lot's of improvement
username_0: Over in https://github.com/reactiveui/website/issues/16#issuecomment-322016434 

Kallyn brought this up:
```
IMO if I was someone who never knew about ReactiveUI or what it does, the homepage would be the most confusing. So, there are a couple of things that I would change with it:

1. The one-liner explanation only tells me that ReactiveUI is a ""advanced, composable, and functional MVVM framework"". As far as I'm aware, that's pretty much what every MVVM framework is (apart from the functional side). Maybe it would be better to focus on what ReactiveUI gives them? (e.g. ""Gives you the power to build reactive, testable, and composable UI code using the familiar MVVM pattern"")
2. Our list of features is below the community section. While I appreciate how much community is at the center of ReactiveUI, I'm assuming a lot of users don't really care at the moment they are trying to learn what ReactiveUI is and does for them.
3. We don't have a call to action. For what it's worth, I think this could simply be a prominent link to some getting started docs. The purpose is primarily to give them an avenue to learn more.

I could draft up these changes so we can discuss in a PR if anyone wants that too.
```
<issue_comment>username_0: üëç open PR's early + happy to jump in a video call and pair with you on this stuff.
<issue_comment>username_1: Looks like I don't have permission to close this, but I'd say this issue is resolved now, seeing the numerous linked PRs.<issue_closed>"
lirantal/is-website-vulnerable,512837151,35,,"[{'action': 'opened', 'author': 'zivkaziv', 'comment_id': None, 'datetime': '2019-10-26 13:43:54+00:00', 'masked_author': 'username_0', 'text': ""<!--\r\nThank you for suggesting an idea to make this project better!\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nThe current output set utm_* query params in the snyk vulnerabilities url.\r\nFor example:\r\n```\r\n Website: https://www.microsoft.com/he-il/\r\n  \r\n    ‚é° ‚úñ jQuery@3.3.1\r\n    ‚éú ‚ñ†‚ñ†‚ñ†  1  vulnerabilities\r\n    ‚é£ ‚ñ∂Ô∏é https://snyk.io/vuln/npm:jquery?lh=3.3.1&utm_source=lighthouse&utm_medium=ref&utm_campaign=audit\r\n  \r\n  [1] Total vulnerabilities\r\n  [7528.38ms] execution time\r\n  vulnerabilities powered by Snyk.io (https://snyk.io/vuln?type=npm)\r\n  ```\r\nhttps://snyk.io/vuln/npm:jquery?lh=3.3.1**&utm_source=lighthouse&utm_medium=ref&utm_campaign=audit**\r\n\r\n**Describe the solution you'd like**\r\nTrim those utm_* query params from the URL\r\n\r\n**Describe alternatives you've considered**\r\n\r\n- Leave it as is..\r\n- Create different query params"", 'title': 'Trim UTM_* from snyk URLs ', 'type': 'issue'}
 {'action': 'created', 'author': 'lirantal', 'comment_id': 546628508.0, 'datetime': '2019-10-26 18:36:42+00:00', 'masked_author': 'username_1', 'text': 'Will be fixed by #38', 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'lirantal', 'comment_id': None, 'datetime': '2019-10-27 07:25:54+00:00', 'masked_author': 'username_1', 'text': '', 'title': None, 'type': 'issue'}]","<issue_start><issue_comment>Title: Trim UTM_* from snyk URLs 
username_0: <!--
Thank you for suggesting an idea to make this project better!

Please fill in as much of the template below as you're able.
-->

**Is your feature request related to a problem? Please describe.**
The current output set utm_* query params in the snyk vulnerabilities url.
For example:
```
 Website: https://www.microsoft.com/he-il/
  
    ‚é° ‚úñ jQuery@3.3.1
    ‚éú ‚ñ†‚ñ†‚ñ†  1  vulnerabilities
    ‚é£ ‚ñ∂Ô∏é https://snyk.io/vuln/npm:jquery?lh=3.3.1&utm_source=lighthouse&utm_medium=ref&utm_campaign=audit
  
  [1] Total vulnerabilities
  [7528.38ms] execution time
  vulnerabilities powered by Snyk.io (https://snyk.io/vuln?type=npm)
  ```
https://snyk.io/vuln/npm:jquery?lh=3.3.1**&utm_source=lighthouse&utm_medium=ref&utm_campaign=audit**

**Describe the solution you'd like**
Trim those utm_* query params from the URL

**Describe alternatives you've considered**

- Leave it as is..
- Create different query params
<issue_comment>username_1: Will be fixed by #38<issue_closed>"
kubernetes/website,743603541,25061,,"[{'action': 'opened', 'author': 'HBDUDE', 'comment_id': None, 'datetime': '2020-11-16 07:42:40+00:00', 'masked_author': 'username_0', 'text': 'Needs a dark mode for enhanced accessibility.', 'title': 'Interactive Tutorial - Creating a Cluster', 'type': 'issue'}
 {'action': 'created', 'author': 'sftim', 'comment_id': 730505025.0, 'datetime': '2020-11-19 16:55:48+00:00', 'masked_author': 'username_1', 'text': '/retitle Allow switching website between ‚Äúlight mode‚Äù and  ‚Äúdark mode‚Äù\r\n\r\n/kind feature\r\n/area web-development\r\n/priority awaiting-more-evidence', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'sftim', 'comment_id': 730505396.0, 'datetime': '2020-11-19 16:56:26+00:00', 'masked_author': 'username_1', 'text': ""@username_0 interesting idea. If this gets a few :+1: reactions we'll be happy to accept it as a feature for the backlog."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'zaheeruddinfaiz', 'comment_id': 779653670.0, 'datetime': '2021-02-16 07:50:44+00:00', 'masked_author': 'username_2', 'text': 'It would be great to have such an option. Since reading the documentation, the dark mode helps in reading for longer period of time.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'stevek-pro', 'comment_id': 832238323.0, 'datetime': '2021-05-04 20:53:49+00:00', 'masked_author': 'username_3', 'text': 'It would save energy, too.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mhrbmr', 'comment_id': 832248187.0, 'datetime': '2021-05-04 21:05:06+00:00', 'masked_author': 'username_4', 'text': 'Just in curiosity, because I‚Äôm new to open source software, but does that mean anyone can potentially contribute? Say if someone wanted to build a dark mode out and then submitted it for review, would that be something someone could do?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'stevek-pro', 'comment_id': 832255317.0, 'datetime': '2021-05-04 21:17:53+00:00', 'masked_author': 'username_3', 'text': 'Indeed, you can and it will be much appreciated. I already started working on it. If you want to coordinate and help, let me know.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mhrbmr', 'comment_id': 832261257.0, 'datetime': '2021-05-04 21:30:06+00:00', 'masked_author': 'username_4', 'text': 'Ok, that‚Äôs really cool to know. Im not extremely experienced as a dev yet, and so I don‚Äôt know if I‚Äôd be of much use, but I‚Äôd love to check out the code and see how it goes.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'sftim', 'comment_id': 849542053.0, 'datetime': '2021-05-27 11:04:50+00:00', 'masked_author': 'username_1', 'text': '/priority backlog\r\n/remove-priority awaiting-more-evidence\r\n/triage accepted', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'vickyvikas7988', 'comment_id': 867020871.0, 'datetime': '2021-06-23 17:21:30+00:00', 'masked_author': 'username_5', 'text': '+1 \r\nNeed dark mode for documentation', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'stevek-pro', 'comment_id': 867175206.0, 'datetime': '2021-06-23 21:32:32+00:00', 'masked_author': 'username_3', 'text': 'Please someone provide location of central SASS (or similar) file. I asked in Slack, w/o result.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'sftim', 'comment_id': 867445615.0, 'datetime': '2021-06-24 08:27:57+00:00', 'masked_author': 'username_1', 'text': ""@username_3 this is a backlog priority issue. SIG Docs has a really chunky amount of work that we've triaged as more valuable, so it's likely that this will move forward specifically when someone who wants to see this specific improvement land picks it up.\r\n\r\nIf we don't see any movement within a few months, we have a bot that would close the feature request."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'sftim', 'comment_id': 868462327.0, 'datetime': '2021-06-25 12:23:54+00:00', 'masked_author': 'username_1', 'text': 'See https://stuffandnonsense.co.uk/blog/redesigning-your-product-and-website-for-dark-mode for a CSS approach towards implementing this.', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Interactive Tutorial - Creating a Cluster
username_0: Needs a dark mode for enhanced accessibility.
<issue_comment>username_1: /retitle Allow switching website between ‚Äúlight mode‚Äù and  ‚Äúdark mode‚Äù

/kind feature
/area web-development
/priority awaiting-more-evidence
<issue_comment>username_1: @username_0 interesting idea. If this gets a few :+1: reactions we'll be happy to accept it as a feature for the backlog.
<issue_comment>username_2: It would be great to have such an option. Since reading the documentation, the dark mode helps in reading for longer period of time.
<issue_comment>username_3: It would save energy, too.
<issue_comment>username_4: Just in curiosity, because I‚Äôm new to open source software, but does that mean anyone can potentially contribute? Say if someone wanted to build a dark mode out and then submitted it for review, would that be something someone could do?
<issue_comment>username_3: Indeed, you can and it will be much appreciated. I already started working on it. If you want to coordinate and help, let me know.
<issue_comment>username_4: Ok, that‚Äôs really cool to know. Im not extremely experienced as a dev yet, and so I don‚Äôt know if I‚Äôd be of much use, but I‚Äôd love to check out the code and see how it goes.
<issue_comment>username_1: /priority backlog
/remove-priority awaiting-more-evidence
/triage accepted
<issue_comment>username_5: +1 
Need dark mode for documentation
<issue_comment>username_3: Please someone provide location of central SASS (or similar) file. I asked in Slack, w/o result.
<issue_comment>username_1: @username_3 this is a backlog priority issue. SIG Docs has a really chunky amount of work that we've triaged as more valuable, so it's likely that this will move forward specifically when someone who wants to see this specific improvement land picks it up.

If we don't see any movement within a few months, we have a bot that would close the feature request.
<issue_comment>username_1: See https://stuffandnonsense.co.uk/blog/redesigning-your-product-and-website-for-dark-mode for a CSS approach towards implementing this."
oVirt/ovirt-site,238172452,1036,,"[{'action': 'opened', 'author': 'fbacchella', 'comment_id': None, 'datetime': '2017-06-23 15:14:44+00:00', 'masked_author': 'username_0', 'text': ""I don't use hosted engine because I'm afraid of reliability of it.\r\n\r\nWhat about bootstrap in case of failure ? Missed upgrade ? Database corruption ?\r\n\r\nI'm might be wrong but I'm afraid of that.\r\n\r\nSo a blog entry explaining why it's a safe option, perhaps some basic check and step to recover in case of big problem can help increase usage of this deployment method."", 'title': 'Why hosted engine is safe ?', 'type': 'issue'}
 {'action': 'created', 'author': 'mykaul', 'comment_id': 310699397.0, 'datetime': '2017-06-23 15:39:11+00:00', 'masked_author': 'username_1', 'text': '@username_3 @doron-fediuck', 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'gregsheremeta', 'comment_id': None, 'datetime': '2018-12-19 23:43:26+00:00', 'masked_author': 'username_2', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'created', 'author': 'gregsheremeta', 'comment_id': 448792810.0, 'datetime': '2018-12-19 23:43:26+00:00', 'masked_author': 'username_2', 'text': ""Perhaps the updated Self-Hosted Engine Guide's information about backup helps.\r\nhttps://www.ovirt.org/documentation/self-hosted/Self-Hosted_Engine_Guide.html"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'fbacchella', 'comment_id': 449334801.0, 'datetime': '2018-12-21 09:43:02+00:00', 'masked_author': 'username_0', 'text': ""There is nothing is the documentation about a complete shutdown, like a data center power loss. What to check ? How the engine will be restarted. Without explicit documentation about that case, I can't have a look at self-hosted engine."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'MarSik', 'comment_id': 449378000.0, 'datetime': '2018-12-21 12:36:51+00:00', 'masked_author': 'username_3', 'text': 'Missed upgrade and database corruption are scenarios that you have to handle with bare metal engine as well. The backup documentation is a good place to start for those. Hosted engine tools allow you to connect to the serial console and do a manual investigation or fixing.\r\n\r\nHosted engine VM is started by the ovirt-ha-agent process which is managed by systemd and is [autostarted](https://github.com/oVirt/ovirt-hosted-engine-ha/blob/master/initscripts/ovirt-ha-agent.service.in#L21). So the engine recovers properly even when a cluster is cold booted.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'gregsheremeta', 'comment_id': 449379065.0, 'datetime': '2018-12-21 12:42:23+00:00', 'masked_author': 'username_2', 'text': '[This](https://www.ovirt.org/documentation/self-hosted/chap-Introduction.html) might help too:\r\n""Additionally, the Engine is configured to be highly available. If the host running the Engine virtual machine goes into maintenance mode, or fails unexpectedly, the virtual machine will be migrated automatically to another host in the environment. A minimum of two self-hosted Engine hosts are required to support the high availability feature.""\r\n\r\nIf you have more specific questions, please send an email to hzdkv@example.com', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Why hosted engine is safe ?
username_0: I don't use hosted engine because I'm afraid of reliability of it.

What about bootstrap in case of failure ? Missed upgrade ? Database corruption ?

I'm might be wrong but I'm afraid of that.

So a blog entry explaining why it's a safe option, perhaps some basic check and step to recover in case of big problem can help increase usage of this deployment method.
<issue_comment>username_1: @username_3 @doron-fediuck<issue_closed>
<issue_comment>username_2: Perhaps the updated Self-Hosted Engine Guide's information about backup helps.
https://www.ovirt.org/documentation/self-hosted/Self-Hosted_Engine_Guide.html
<issue_comment>username_0: There is nothing is the documentation about a complete shutdown, like a data center power loss. What to check ? How the engine will be restarted. Without explicit documentation about that case, I can't have a look at self-hosted engine.
<issue_comment>username_3: Missed upgrade and database corruption are scenarios that you have to handle with bare metal engine as well. The backup documentation is a good place to start for those. Hosted engine tools allow you to connect to the serial console and do a manual investigation or fixing.

Hosted engine VM is started by the ovirt-ha-agent process which is managed by systemd and is [autostarted](https://github.com/oVirt/ovirt-hosted-engine-ha/blob/master/initscripts/ovirt-ha-agent.service.in#L21). So the engine recovers properly even when a cluster is cold booted.
<issue_comment>username_2: [This](https://www.ovirt.org/documentation/self-hosted/chap-Introduction.html) might help too:
""Additionally, the Engine is configured to be highly available. If the host running the Engine virtual machine goes into maintenance mode, or fails unexpectedly, the virtual machine will be migrated automatically to another host in the environment. A minimum of two self-hosted Engine hosts are required to support the high availability feature.""

If you have more specific questions, please send an email to users@ovirt.org"
JuliaLang/www.julialang.org,603229197,725,"{'number': 725.0, 'repo': 'www.julialang.org', 'user_login': 'JuliaLang'}","[{'action': 'opened', 'author': 'PallHaraldsson', 'comment_id': None, 'datetime': '2020-04-20T13:14:44Z', 'masked_author': 'username_0', 'text': '[skip ci]\r\nhttps://github.com/JuliaLang/julia/issues/35215#issuecomment-616523407\r\n\r\nIn short, I would additionally suggest 1.3 as LTS, unless 1.4 or newer can be compiled to work (and published here) on same CPUs. See more in the comment, on two possible LTS versions.', 'title': 'Document limitation for pre-Bulldozer AMD CPUs', 'type': 'issue'}
 {'action': 'created', 'author': 'ViralBShah', 'comment_id': 616546508.0, 'datetime': '2020-04-20 13:17:22+00:00', 'masked_author': 'username_1', 'text': ""We don't want this in a downloads page and need to do this for all architectures. The message needs to be a bit more specific too."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'PallHaraldsson', 'comment_id': 616552021.0, 'datetime': '2020-04-20 13:26:45+00:00', 'masked_author': 'username_0', 'text': 'What do you mean ""need to do this for all architectures""? AMD (older than 2011) are the earliest CPUs I know of failing on 1.4. Older Intel should work, but I\'m not sure older still Intel works on any version. I did not look into Via, or POWER etc. just thought this might be helpful here..., doesn\'t rule out documenting also elsewhere.\r\n\r\nNote however LTS suggestion. Then message could be simplified to ""some older computers still cork on Julia LTS"".', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ViralBShah', 'comment_id': 616553256.0, 'datetime': '2020-04-20 13:28:47+00:00', 'masked_author': 'username_1', 'text': 'Please stop mentioning the 1.3 LTS. We will not be doing this.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'PallHaraldsson', 'comment_id': 616553625.0, 'datetime': '2020-04-20 13:29:25+00:00', 'masked_author': 'username_0', 'text': 'I intentionally had ""very old"" not specific, as if I mention a year, it\'s about when the CPU arch is made, and I\'m not sure for how long sold (after discontinued). People may not know or care their CPU is Bulldozer-based or older.', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Document limitation for pre-Bulldozer AMD CPUs
username_0: [skip ci]
https://github.com/JuliaLang/julia/issues/35215#issuecomment-616523407

In short, I would additionally suggest 1.3 as LTS, unless 1.4 or newer can be compiled to work (and published here) on same CPUs. See more in the comment, on two possible LTS versions.
<issue_comment>username_1: We don't want this in a downloads page and need to do this for all architectures. The message needs to be a bit more specific too.
<issue_comment>username_0: What do you mean ""need to do this for all architectures""? AMD (older than 2011) are the earliest CPUs I know of failing on 1.4. Older Intel should work, but I'm not sure older still Intel works on any version. I did not look into Via, or POWER etc. just thought this might be helpful here..., doesn't rule out documenting also elsewhere.

Note however LTS suggestion. Then message could be simplified to ""some older computers still cork on Julia LTS"".
<issue_comment>username_1: Please stop mentioning the 1.3 LTS. We will not be doing this.
<issue_comment>username_0: I intentionally had ""very old"" not specific, as if I mention a year, it's about when the CPU arch is made, and I'm not sure for how long sold (after discontinued). People may not know or care their CPU is Bulldozer-based or older."
quarkusio/quarkusio.github.io,1104324919,1301,"{'number': 1301.0, 'repo': 'quarkusio.github.io', 'user_login': 'quarkusio'}","[{'action': 'opened', 'author': 'gastaldi', 'comment_id': None, 'datetime': '2022-01-15T03:40:13Z', 'masked_author': 'username_0', 'text': 'Include @oztimpower.\r\n\r\nCloses #1117', 'title': 'Update authors.yaml', 'type': 'issue'}
 {'action': 'created', 'author': 'gastaldi', 'comment_id': 1013603975.0, 'datetime': '2022-01-15 03:56:36+00:00', 'masked_author': 'username_0', 'text': ""@oztimpower I have added you in the `authors.yaml` in this PR, but I couldn't find a doc/guide/post where you are listed as an author.\r\n\r\nCan you help me to verify if it's being displayed correctly?"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'gastaldi', 'comment_id': 1021799571.0, 'datetime': '2022-01-26 02:21:12+00:00', 'masked_author': 'username_0', 'text': 'Closing for now', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Update authors.yaml
username_0: Include @oztimpower.

Closes #1117
<issue_comment>username_0: @oztimpower I have added you in the `authors.yaml` in this PR, but I couldn't find a doc/guide/post where you are listed as an author.

Can you help me to verify if it's being displayed correctly?
<issue_comment>username_0: Closing for now"
gohugoio/hugo,238595236,3648,,"[{'action': 'opened', 'author': 'AntJanus', 'comment_id': None, 'datetime': '2017-06-26 16:17:06+00:00', 'masked_author': 'username_0', 'text': 'I\'m running Windows 10 64-bit and I\'m running Hugo through Powershell. I\'m getting the following error:\r\n\r\n```\r\nError: open : The system cannot find the file specified.\r\n```\r\n\r\nWhen running any `hugo new first-post` command. I appended `-v` and here\'s the output:\r\n\r\n```\r\nINFO 2017/06/26 10:13:27 Using config file:\r\nINFO 2017/06/26 10:13:27 attempting to create ""test"" of """" of ext """"\r\nError: open : The system cannot find the file specified.\r\n```\r\n\r\nI tried the command with and without extension, deeply nested and shallow. Can\'t figure it out. I\'m able to generate a new site fine and `server` seems to work too.', 'title': 'Hugo fails to create a new post', 'type': 'issue'}
 {'action': 'created', 'author': 'bep', 'comment_id': 311108680.0, 'datetime': '2017-06-26 16:19:20+00:00', 'masked_author': 'username_1', 'text': 'What Hugo version?\r\n\r\nSee https://github.com/gohugoio/hugo/releases/tag/v0.24.1', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'AntJanus', 'comment_id': 311109075.0, 'datetime': '2017-06-26 16:20:43+00:00', 'masked_author': 'username_0', 'text': ""I'm on v0.24.1 freshly installed."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'AntJanus', 'comment_id': 311109236.0, 'datetime': '2017-06-26 16:21:18+00:00', 'masked_author': 'username_0', 'text': 'Not sure if it makes a difference but my Go version is 1.8.3', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'bep', 'comment_id': 311110241.0, 'datetime': '2017-06-26 16:25:03+00:00', 'masked_author': 'username_1', 'text': ""I still suspect you're having the wrong Hugo version. Can you print the output of\r\n\r\n```bash\r\nhugo env\r\n```"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'AntJanus', 'comment_id': 311110363.0, 'datetime': '2017-06-26 16:25:32+00:00', 'masked_author': 'username_0', 'text': '```\r\nHugo Static Site Generator v0.24 windows/amd64 BuildDate: 2017-06-23T00:44:27-06:00\r\nGOOS=""windows""\r\nGOARCH=""amd64""\r\nGOVERSION=""go1.8.3""\r\n```', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'bep', 'comment_id': 311111044.0, 'datetime': '2017-06-26 16:27:50+00:00', 'masked_author': 'username_1', 'text': 'As I said. This is fixed in Hugo **v0.24.1**.', 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'bep', 'comment_id': None, 'datetime': '2017-06-26 16:27:52+00:00', 'masked_author': 'username_1', 'text': '', 'title': None, 'type': 'issue'}]","<issue_start><issue_comment>Title: Hugo fails to create a new post
username_0: I'm running Windows 10 64-bit and I'm running Hugo through Powershell. I'm getting the following error:

```
Error: open : The system cannot find the file specified.
```

When running any `hugo new first-post` command. I appended `-v` and here's the output:

```
INFO 2017/06/26 10:13:27 Using config file:
INFO 2017/06/26 10:13:27 attempting to create ""test"" of """" of ext """"
Error: open : The system cannot find the file specified.
```

I tried the command with and without extension, deeply nested and shallow. Can't figure it out. I'm able to generate a new site fine and `server` seems to work too.
<issue_comment>username_1: What Hugo version?

See https://github.com/gohugoio/hugo/releases/tag/v0.24.1
<issue_comment>username_0: I'm on v0.24.1 freshly installed.
<issue_comment>username_0: Not sure if it makes a difference but my Go version is 1.8.3
<issue_comment>username_1: I still suspect you're having the wrong Hugo version. Can you print the output of

```bash
hugo env
```
<issue_comment>username_0: ```
Hugo Static Site Generator v0.24 windows/amd64 BuildDate: 2017-06-23T00:44:27-06:00
GOOS=""windows""
GOARCH=""amd64""
GOVERSION=""go1.8.3""
```
<issue_comment>username_1: As I said. This is fixed in Hugo **v0.24.1**.<issue_closed>"
conda-forge/conda-forge.github.io,132772395,22,,"[{'action': 'opened', 'author': 'ocefpaf', 'comment_id': None, 'datetime': '2016-02-10 17:55:40+00:00', 'masked_author': 'username_0', 'text': '(@username_1 brought this up in https://github.com/conda-forge/conda-forge.github.io/issues/16#issuecomment-182430891)\r\n\r\nI Agreed with @username_1 that we should avoid as much as possible to add packages in conda-forge that are available in the default channel.\r\n\r\nHowever, we already have a few redundant packages (`pyproj`, `shapely`, `geos`, and more to come soon). The reason for thw redundancy is that those packages are partially broken in the default channel.\r\n(And we could not find a proper channel of communication to send the recipe patch back to them.)\r\n\r\nMaybe, when fixing a default channel package we should allow the package addition here as long as there is a plan to send that fix back to the default channel, and to remove the package from conda-forge once that happens.', 'title': 'When to package software which is already in the default conda channel', 'type': 'issue'}
 {'action': 'created', 'author': 'JanSchulz', 'comment_id': 182504965.0, 'datetime': '2016-02-10 18:00:26+00:00', 'masked_author': 'username_1', 'text': 'Maybe register a new channel: ""temporary-fixes""?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'JanSchulz', 'comment_id': 182505515.0, 'datetime': '2016-02-10 18:02:28+00:00', 'masked_author': 'username_1', 'text': 'Maybe @username_4 has some idea how this could be handled?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 182573625.0, 'datetime': '2016-02-10 20:37:52+00:00', 'masked_author': 'username_2', 'text': ""I'm not sure it's worth a different channel.\r\n\r\nBut I wonder if we should give the package a different name, otherwise things can get pretty tangled up:\r\n\r\ngdal-cf\r\nor ????\r\n\r\n(cf for conda forge...)\r\n\r\nThat means that anyone using it has to change the dependency, but are there going to be any packages outside of conda-forge that depend on a conda-forge special build???"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ocefpaf', 'comment_id': 182580090.0, 'datetime': '2016-02-10 20:59:31+00:00', 'masked_author': 'username_0', 'text': ':-1:  that can be confusing.  We can maybe ""sign"" the packages with a build string like\r\n\r\n```\r\nbuild:\r\n    string: conda-forge\r\n```\r\n\r\nBut IMO just having the package in a different channel should be enough to disambiguate.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'JanSchulz', 'comment_id': 182581264.0, 'datetime': '2016-02-10 21:03:30+00:00', 'masked_author': 'username_1', 'text': 'The reason for a different channel is IMO that I suspect that at some point users will add conda-forge to their default channels and a different channel than that means that users an get the updated/fixed version with `conda install -c whatever matplotlib` but not on a simple `conda update --all`.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 182600980.0, 'datetime': '2016-02-10 22:04:54+00:00', 'masked_author': 'username_2', 'text': 'I\'m not sure the channel disambiguates -- does conda prioritize default or your other channels?\r\n\r\nBut I wonder where all this goes -- with PyPi, it\'s up to each package maintainer to keep things up to date. with anaconda, it\'s up to third parties -- mainly continuum. so if they don\'t, then what?\r\n\r\nI\'m hoping continuum will adopt a more community model, where folks can easily provide PRs -- it seems it would only save them work. So we\'ll see.\r\n\r\nIn the meantime, conda-forge may become the community channel, and I""d say if you want the latest and greatest, then you add that channel -- and you\'ll get the new MPL, or whatever, if conda-forge provides a newer one than default.\r\n\r\nWe will probably want to clean things out as continuum catches up.\r\n\r\nI\'m still wondering about the naming though:\r\n\r\ncontinuum builds package-1.2.1\r\n\r\na new version comes out, and folks want it -- but continuum is being slow on teh draw.\r\n\r\nconda-forge provides package-1.3.1\r\n\r\nall is good.\r\n\r\nnow continuum catches up and builds a package-1.3.1 -- now there are two, with the same version. And maybe they are even incompatible in some way. This could make a mess for our users.\r\n\r\nIf we go with Jan\'s approach, then this would be cleaner, but users would have to explicilty make a point of getting a newer version -- I think that would be awkward and often missed as an option.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'JanSchulz', 'comment_id': 182603644.0, 'datetime': '2016-02-10 22:15:51+00:00', 'masked_author': 'username_1', 'text': 'As this probably requires changes  in conda, I would vote for `1.3.0_real_1.3.1` which sorts before `1.3.1`, but after `1.3.0`.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'JanSchulz', 'comment_id': 182605310.0, 'datetime': '2016-02-10 22:22:35+00:00', 'masked_author': 'username_1', 'text': 'Hah, it seems conda already implments such a scheme, so `1.3.1.cf` is lower than `1.3.1`\r\nhttps://github.com/conda/conda/blob/2ba04a6b2617227de578f4af54ff11115f97ca5c/conda/version.py#L81', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 182606333.0, 'datetime': '2016-02-10 22:25:31+00:00', 'masked_author': 'username_2', 'text': 'nice!, maybe we can use that, then.\r\n\r\n-CHB', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ocefpaf', 'comment_id': 182609430.0, 'datetime': '2016-02-10 22:33:24+00:00', 'masked_author': 'username_0', 'text': ':+1:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'JanSchulz', 'comment_id': 182615104.0, 'datetime': '2016-02-10 22:41:01+00:00', 'masked_author': 'username_1', 'text': 'This is probably https://github.com/conda/conda/issues/1967', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'pelson', 'comment_id': 182750552.0, 'datetime': '2016-02-11 07:41:21+00:00', 'masked_author': 'username_3', 'text': ""This is the real problem here. We have, in the past, fixed packages (on IOOS and SciTools) which Continuum package, often by releasing a newer version. The problem comes when Continuum update the version of the software they package, but don't actually fix the problem. This has happened on several occasions with packages such as Shapely and pyproj. From a user's perspective, they are just updating their software and it goes from a functional state to a non-functional state - not really ideal. Because of the lack of a repository of canonical recipe source, all we have been able to do is report a problem with the package, not actually fix it (i.e. in the form of a PR).\r\n\r\n-----------\r\n\r\n@username_7, @username_6 and @username_5 have all expressed an opinion on the subject of this issue in the past. Do any of you have comments on when it should be the place of conda-forge to package software which is already being packaged by Continuum?"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcg1969', 'comment_id': 182967315.0, 'datetime': '2016-02-11 17:28:36+00:00', 'masked_author': 'username_4', 'text': '@username_1 thanks for pinging me. There\'s not a whole lot I can officially say yet, except that we recognize the need to support alternatives to Continuum\'s `default` channels. We\'re actively working on a particular community channel solution, but it is not the only way forward, and it _shouldn\'t_ be. We\'ve been watching the Conda Forge project with enthusiasm. As we talk more we may be able to come up with some specific ways Continuum can help with it. But having an effort like this that Continuum _does not control_ is beneficial to the Python community at large, so I\'m grateful you\'re working on it.\r\n\r\nI see three different problems with the default channel:\r\n\r\n1. Not every package people want can be, or should be, available there.\r\n2. Continuum updates those packages less frequently than the primary developers of the packages.\r\n3. The packages may not be compiled with the same options that some users like to see.\r\n\r\nAll three of these issues are an inevitable consequence of Continuum\'s finite resources for building and supporting packages. We certainly acknowledge that this isn\'t going to satisfy people who regularly bump up against one of these three problems. Heck I bump up against all three of these problems myself.\r\n\r\nMy particular perspective, as many of you know who have been watching my conda fixes recently, is on the _dependency solver_. I\'ve been spending time overhauling it, and it\'s certainly going to fix some of the issues like `conda update --all` being slow, `conda remove` potentially breaking installs, etc. I\'m glad @username_3 is confirming that my improvements are beginning to make a difference. \r\n\r\nBut honestly, the mathematics of the solver isn\'t really the issue here, at least not directly. What you are discussing in this thread is basically the challenge of _channel clashes_. That is: how should conda handle things when two or more channels release versions of the same package? At the moment, conda effectively ""merges"" the channels together, so that the packages interleave with each other purely based on version and build numbers. That\'s clearly not a workable solution. For one thing, build numbers don\'t have meaning across channels; so for instance, build 1 from channel A may actually be _newer_ than build 2 from channel B, and conda doesn\'t know that. This is something we need to decide on a fix for.\r\n\r\nWhat we need, it seems to me, is to identify specific improvements to conda that would greatly improve the ability to use alternate, community-driven package channels. For instance:\r\n\r\n1) A fix for conda that untangles packages/channel conflicts. For instance, we could say that the highest-priority channel is always preferred for a package, and any packages by the same name in lower-prioirity channels are ignored. But I could see a variety of other strategies, and perhaps conda should adopt several, choose on as a default, but make the others available by configuration.\r\n\r\n2) An enhancement to conda that allows channel preferences to be adopted on a _per-package_ and or _per-environment_ basis. For example, perhaps I add the `conda-forge` channel as a lower-priority channel, but I actually prefer one of its packages to the one provided in `default`. There should be a way to specify that priority preference and persist it across updates and later installations.\r\n\r\nThis is the kind of thinking that would be very helpful for me personally. We really do want `conda` to be adopted more widely---heck, we\'d be pleased if someone built their own Python distribution that used `conda` as a packaging model. And we\'d like to find ways to enable groups like Conda Forge to flourish without having to wait on us. I actually do think that there are some changes to `conda` that we can push through in the short term that will greatly improve our ability to work in parallel.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ocefpaf', 'comment_id': 182968626.0, 'datetime': '2016-02-11 17:33:38+00:00', 'masked_author': 'username_0', 'text': 'Having a way to specify channel preference globally or per env would be a really good addition to conda.\r\n\r\n:+1:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcg1969', 'comment_id': 183050915.0, 'datetime': '2016-02-11 20:34:14+00:00', 'masked_author': 'username_4', 'text': 'I would really rather we tackle the channel collision problem _correctly_ than to utilize weird version numbers or (even worse) track_features to disambiguate.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'stefanv', 'comment_id': 183070751.0, 'datetime': '2016-02-11 21:46:16+00:00', 'masked_author': 'username_5', 'text': 'If we could get Continuum to open recipes (or adopt community recipes upon\nsubmission, and then open those up), then perhaps much of the problem can\nbe avoided? Ideally, we do not want multiple versions of numpy with the\nsame version tag floating around.\n\nAn alternative path is to build everything you need into your own channel.\n\nFor mixed channels, I don\'t see a straightforward way of resolving what to\ninstall without additional meta-data. In Debian there is the concept of\n""pinning"", which allows you to fix certain packages in place.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 183072578.0, 'datetime': '2016-02-11 21:50:55+00:00', 'masked_author': 'username_2', 'text': '@username_4: absolutely -- but we need help from conda itself to do it ""right"" -- are you speaking for continuum, hard to tell :-)\r\n\r\n@username_0 wrote: ""Having a way to specify channel preference globally or per env would be a really good addition to conda.""\r\n\r\nI think that would actually be a simple solution that would mostly solve the problem at hand -- folks could put the IOS channel, or conda-forge channel at their first preference, and then they would get the latest and greatest.\r\n\r\nGranted, the default channel may get updated in a way that leapfrogs conda-forge, but I think it will be up to whoever is maintaining the conda-forge package to keep an eye on that.\r\n\r\nAnd the default channel is clearly the upstream one -- conda-forge will be following its lead, so that could work.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 183077043.0, 'datetime': '2016-02-11 22:00:03+00:00', 'masked_author': 'username_2', 'text': 'I\'ve been thinking a bit about how this works with PyPi (and PyPi does work well, for the things i works well for, i.e. pure-python packages)\r\n\r\nIt is a totally different model -- PyPa only provides the infrastructure -- each and every package is maintained by individual package maintainers. Ideally, conda packaging could go that way, but it\'s going to be a long time (or never) before package authors in general support conda. (never mind non-python stuff....)\r\n\r\nBy my idea, at least, is that conda-forge becomes the PyPi-like place for conda packages -- it will start (has started) with groups of packages that are not in the default channel being maintained by a third party, but hopefully individual package authors will start to maintain their own packages. So we need to design the infrastructure to support that.\r\n\r\nIn fact, as a package author steps up to maintain a package, maybe it could even be removed from the default channel. In the long run, maybe continuum will need to maintain few packages, and rather, have Anaconda be the ""curated"" selection, but much of it would be pulled in from the authors\' builds (OK, maybe that\'s a fantasy).\r\n\r\nAnyway, what all this means is that it should be very easy for a package author to push builds to conda-forge, like it is now with PyPi being integrated into the PyPa stack (distutils, setuptools, pip, I""ve lost track...)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'JanSchulz', 'comment_id': 183078119.0, 'datetime': '2016-02-11 22:03:00+00:00', 'masked_author': 'username_1', 'text': 'One easy idea would be to add somethign like this:\r\n\r\n```\r\nconda install -c conda-forge --pin-channel matplotlib\r\n```\r\n\r\nThat would add an entry to the config file that matplotlib should be taken from the conda-forge and all other packages with the same name form other channels should be discarded (e.g. simple add a step-0 to the solver which removes all matplotlib packages from other channels from the list of available packages).\r\n\r\nThis will help with the problem of ""fixing"" packages in the default channel (and IMO this should be the only part where conda-forge should package packages in the default channel).\r\n\r\nAnother step would be to configure the ""default"" channel, so that conda does not see the anaconda/Continuum packages at all. Not sure if that is possible today?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 183079074.0, 'datetime': '2016-02-11 22:05:37+00:00', 'masked_author': 'username_2', 'text': ""@username_5: Absolutely!\r\n\r\nIf the default channel was built from (mostly) recipes maintained in a public gitHub project(s), it would be monstrously easier to keep everything up to date and in-sync. We could/would do a lot of the work for continuum.\r\n\r\nAnd they could start one package at a time (shapely?).. it wouldn't have to be a wholesale, all at once move.\r\n\r\nI can imagine it's inertia more than anything else that's prevented this from happening so far, but it's a bit frustrating from outside.\r\n\r\n-CHB"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'JanSchulz', 'comment_id': 183079844.0, 'datetime': '2016-02-11 22:08:02+00:00', 'masked_author': 'username_1', 'text': 'submission, and then open those up), then perhaps much of the problem can\r\nbe avoided?\r\n\r\nI think it would already be enough if Continuum would add all their package recipes (as they are currently used -> the [matplotlib recipe in the conda-recipes repo](https://github.com/conda/conda-recipes/tree/master/python/matplotlib) is out of date) and accept PRs for already included packages. I would be happy to add patches there if I know that they land on my HD a day after they are merged... Contiuum still would have the final say, it would speed up the updates on new upstream releases, and Continuum would have less work... (cc: @username_4 :-) )', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'tacaswell', 'comment_id': 183081384.0, 'datetime': '2016-02-11 22:14:18+00:00', 'masked_author': 'username_6', 'text': ""@username_4 articulated many of my thoughts more coherently than I would have, I think channel-level precedence is the probably the right way to fix this, but I would like a way to control (maybe at the package level) if it goes with newest-possible or prefers a specific channel.  \r\n\r\nI was also thinking of the debian idea of 'pinning' as a model for how to do this.\r\n\r\nFor day-job we have been making aggressive use of 'postN' versioning (pulled directly from git describe via versioneer) which helps the case where the issue is fixes from up-stream project is adding/fixing things.  Although, this can get funny if you are packing commits from side-branches and definitely does not help if the difference is different sets of locally applied patches or build configuration."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 183084661.0, 'datetime': '2016-02-11 22:27:34+00:00', 'masked_author': 'username_7', 'text': 'Pinning channel might be ok as long as it is per environment.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ocefpaf', 'comment_id': 183084676.0, 'datetime': '2016-02-11 22:27:38+00:00', 'masked_author': 'username_0', 'text': '@username_6 my Linux distro (OpenSUSE) does exactly that.  I can set repository preferences that will be used when updating the system, but I can also do a ""distribution upgrade"" that will get the newest-possible from all repositories. This operations issues warnings stating that the user is responsible for the system stability when adding third party repository and performing the distribution upgrade. Conda is dangerously confusing with that!  I can see tons of users breaking their system using conda-forge packages and going to Continuum mailing list to complain.\r\n\r\nWith that said. This behavior might be a long-term goal.  Right now I believe that a global channel preference is already a big win.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ocefpaf', 'comment_id': 183085414.0, 'datetime': '2016-02-11 22:29:42+00:00', 'masked_author': 'username_0', 'text': 'Agreed.\r\n\r\nhttps://github.com/conda/conda/issues/982', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'JanSchulz', 'comment_id': 183121265.0, 'datetime': '2016-02-12 00:16:36+00:00', 'masked_author': 'username_1', 'text': 'For a idea on how to mark package/channel combinations as good/bad: https://github.com/conda/conda/issues/2067', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jjhelmus', 'comment_id': 197030056.0, 'datetime': '2016-03-15 21:33:40+00:00', 'masked_author': 'username_8', 'text': 'That sounds like a challenge!  Accepted, [acpd, Another Conda-base Python Distribution](https://github.com/acpd/acpd).\r\n\r\nOn that topic and related to packaging software already in the default conda channel, would it be possible for someone from Continuum to clarify the license of the recipes in the [ContinuumIO/anaconda-recipes](https://github.com/ContinuumIO/anaconda-recipes) repository?  A number of those are prime candidates for use in conda-forge.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 197042418.0, 'datetime': '2016-03-15 21:54:48+00:00', 'masked_author': 'username_7', 'text': 'Nice! Do you have any thoughts on their integration into conda-forge, @username_8?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jjhelmus', 'comment_id': 197104204.0, 'datetime': '2016-03-16 01:42:40+00:00', 'masked_author': 'username_8', 'text': 'Long term I think they could be integrated into conda-forge, but first some logistics need to be worked out.  Having a conda-forge version of conda clobber the Continuum version would not be good.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 197112996.0, 'datetime': '2016-03-16 02:05:49+00:00', 'masked_author': 'username_7', 'text': 'Maybe they could be placed under a special label that is different from `main` so they could be opted into instead of installed by default when adding conda-forge.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jjhelmus', 'comment_id': 197117161.0, 'datetime': '2016-03-16 02:24:23+00:00', 'masked_author': 'username_8', 'text': 'I could be wrong but I do not think having a non `main` label is taken into account when doing a conda install from Anaconda.org.  Having a separate channel for these packages might be a possibility but it seem liked the consensus in this issue was that this was not an ideal situation.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'msarahan', 'comment_id': 197117472.0, 'datetime': '2016-03-16 02:26:49+00:00', 'masked_author': 'username_9', 'text': 'Anaconda-recipes is BSD, same as Conda-recipes.  Sorry that wasn\'t posted.  I have added it.  It is our intent to move everything in anaconda-recipes to the conda-forge-feeding-community-channel plan.  If anyone would like to help in that effort, we\'d appreciate it.  The gist of that plan is:\r\n\r\n1. We move recipes from the internal repo, anaconda-recipes, and conda-recipes to conda-forge.  Those other places are either shut down or replaced with links or git submodules (like the ""feedstocks"" repo in conda-forge)\r\n2. We mirror or link packages built by conda-forge on our ""community"" anaconda.org channel.  There may be other sources of packages there, also.\r\n3. We run a validation process on packages (inspect recipe, run test suites, verify package contents against a build of the recipe).  Once verified, these packages will become the content on the default channel.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jjhelmus', 'comment_id': 197118841.0, 'datetime': '2016-03-16 02:34:24+00:00', 'masked_author': 'username_8', 'text': 'Great, thanks for the clarification @username_9', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 197120321.0, 'datetime': '2016-03-16 02:39:36+00:00', 'masked_author': 'username_7', 'text': 'Will this verification process be done in the open? For instance, will the scripts for this verification be placed in a public repo? I imagine that it will be nice to include these checks in the process of determining whether a package gets added on this side, as well.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'msarahan', 'comment_id': 197128883.0, 'datetime': '2016-03-16 03:02:18+00:00', 'masked_author': 'username_9', 'text': 'Great idea.  There is no security in obscurity, and I would appreciate all of your support in developing this process / tool.  I will come up with a repo for it tomorrow after some discussion internally on where it fits.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 197385496.0, 'datetime': '2016-03-16 15:33:38+00:00', 'masked_author': 'username_2', 'text': 'This sounds like the end game is to have the default channel host all\ncontinuum packages, as well as all community-maintained packages.\n\nSo will there be any place for a ""community"" or ""cons-forge"" channel at all?\n\nOn the one hand -- great for the user community. On the other hand, I\nhave a hard-to-define impression that there will still be a need for\n""something"" in between the default channel and a random scattering of\nchannels on Anaconda.org.\n\nI.e. Multiple levels of ""trust"":\n\nAnaconda: tested by continuum and all known to work together.\n\nDefault: tested by continuum, with the lastest and greatest.\n\nCommunity: curated by a trusted community, maybe experimental builds,\nrelease candidates, etc.\n\nArbitrary Anaconda.org: Buyer beware !\n\n-CHB', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'msarahan', 'comment_id': 197391328.0, 'datetime': '2016-03-16 15:47:25+00:00', 'masked_author': 'username_9', 'text': 'Your hierarchy sounds pretty reasonable, and very much in line with what I have in mind.  The default channel is less ""hosting all continuum packages"" and more ""hosting continuum-verified community-maintained packages.""  Continuum is participating in the maintenance as well, not just pawning it off.  However, it is a reduction of Continuum\'s role as ""authoritative builder"" to ""tester/verifier/integrator of packages built by a standard community-accessible system.""  The default channel still involves human verification on our end, and will trail the community channel to some extent.  More importantly, the community channel\'s critical place is an aggregator, where a single central channel combines authoritative packages from multiple other channels.  This hopefully will help all kinds of package conflict and channel priority issues.\r\n\r\nI see arbitrary anaconda.org less as ""buyer beware"" and more as ""YMMV.""  If small channels want to play ball with standards and all that, they\'ll be very welcome in the community channel.  A very easy way to do that would be to just contribute packages to conda-forge.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 197395390.0, 'datetime': '2016-03-16 15:57:12+00:00', 'masked_author': 'username_2', 'text': ""well, sure -- the point was that if you use an arbitrary anaconda.org channel,\nit is up to you to confirm who built it, whether it suites your needs, and\nwhether it is safe.\n\nI haven't heard of any obuses, but one certainly COULD put all kinds of\ndangerous software up on an anaconda.org channel -- makes me nervous!\n\n-CHB\n\n\n-- \n\nChristopher Barker, Ph.D.\nOceanographer\n\nEmergency Response Division\nNOAA/NOS/OR&R            (206) 526-6959   voice\n7600 Sand Point Way NE   (206) 526-6329   fax\nSeattle, WA  98115       (206) 526-6317   main reception\n\nlyhxr@example.com"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 197407650.0, 'datetime': '2016-03-16 16:21:59+00:00', 'masked_author': 'username_7', 'text': 'Sounds good. Feel free to ping me when it is up. Would be nice to get a feeling as to the requirements for validation to start.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 197500819.0, 'datetime': '2016-03-16 19:24:22+00:00', 'masked_author': 'username_7', 'text': 'cc @username_10', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'patricksnape', 'comment_id': 198416527.0, 'datetime': '2016-03-18 15:43:06+00:00', 'masked_author': 'username_10', 'text': ""Thanks for cc'ing me @username_7. This sounds amazing. It would be really really good to have a sort of staggered release schedule whereby the community thinks things are good to ship onto conda-forge and then continuum eventually pulls them onto mainline once verified. This will be great for much smaller packages too.\r\n\r\nIf we decide on the protocol for all of this I'd be really happy to evangelise it by writing some blog posts/documentation about how package maintainers can easily opt into conda in a similar manner as they do to PyPi but via conda-forge!\r\n\r\nI suppose I should start submitting some of the recipes I have like opencv that will likely be widely useful! I need to get a feel for how conda-forge works yet but I'd be really happy to move away from hosting my own packages for other big projects if possible."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 198420813.0, 'datetime': '2016-03-18 15:48:50+00:00', 'masked_author': 'username_7', 'text': 'Not sure if this is up your alley, @hajs, but I figured you might be interested in this sort of system and with your wide breadth of recipes we would certainly appreciate your feedback going forward and any contributions you would be willing to me.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'njsmith', 'comment_id': 198474850.0, 'datetime': '2016-03-18 18:05:02+00:00', 'masked_author': 'username_11', 'text': 'Just a quick comment: it might be worth studying the way the Fedora/rhel/centos ecosystem works in detail for inspiration, since it sounds like you might be moving towards reinventing large parts of it :-)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 198479256.0, 'datetime': '2016-03-18 18:15:09+00:00', 'masked_author': 'username_7', 'text': ""What can we say? We are unreasonable people. We want a package manager that is cross platform, doesn't require `sudo`, and let's Python be awesome. :smile:"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ocefpaf', 'comment_id': 198480021.0, 'datetime': '2016-03-18 18:17:11+00:00', 'masked_author': 'username_0', 'text': 'I am stealing that phrase next time I have to prepare a presentation on conda/conda-forge :wink:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'msarahan', 'comment_id': 198490747.0, 'datetime': '2016-03-18 18:44:24+00:00', 'masked_author': 'username_9', 'text': ""Thanks, @username_11 - I would do well to study that, since I have been proposing much of this process.  It makes perfect sense now that you mention it, but I've had my head stuck in Windows and Ubuntu sand for too long to be aware of it.  I'll go study.\r\n\r\n@username_7 and @username_0, I believe his comment is aimed at the process of community-developed packages feeding into an enterprise system (which then may spawn a community-led enterprise system), more than he is talking about build strategies of any given recipe."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 198514403.0, 'datetime': '2016-03-18 19:42:48+00:00', 'masked_author': 'username_7', 'text': '@username_12, given your views on packaging and the value of `conda` not to mention your [extensive recipe collection]( https://github.com/ActivisionGameScience/ags_conda_recipes ), we would be really interested in working with you to help get this all integrated into conda-forge. It will definitely help us and should help you reduce your maintenance burden. Please let us know how we can help.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'njsmith', 'comment_id': 198525972.0, 'datetime': '2016-03-18 20:17:50+00:00', 'masked_author': 'username_11', 'text': 'Exactly -- the social technology, not the code technology :-).', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 198579203.0, 'datetime': '2016-03-18 23:16:20+00:00', 'masked_author': 'username_7', 'text': 'This is clear.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'tacaswell', 'comment_id': 198585306.0, 'datetime': '2016-03-18 23:43:38+00:00', 'masked_author': 'username_6', 'text': 'centos:fedora:RHEL :: conda-forge:anaconda:anaconda-enterprise', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'njsmith', 'comment_id': 198585315.0, 'datetime': '2016-03-18 23:43:40+00:00', 'masked_author': 'username_11', 'text': 'I don\'t know that conda would necessarily want to follow the exact evolution of the RH ecosystem, but Fedora, RHEL, and CentOS are 3 closely related systems that share lots of engineering work but make different kinds of trade-offs and target different market segments -- Fedora as a fast-moving  project with an emphasis on free software ideals and community-led-governance (but with support from RH for infrastructure like servers and legal compliance), that also serves as a beta testing ground for RHEL; RHEL as the commercially supported ultra-stable enterprise platform, and CentOS as a free version of RHEL without the commercial support for those who want a slow-moving enterprise-y product and to take advantage of RH\'s QA, but don\'t want to pay for it. (There\'s definitely a desire in the community a ""CentOS Anaconda"" -- cf. the repeated complaints about the closed build recipes for core packages.) All together these form a neat ecosystem in which the different parse support each other -- e.g. CentOS might sound like a competitor to RHEL, but in fact it\'s RH themselves manage it and see it as a kind of loss leader that gets people into their ecosystem, makes it easier for third-parties to support RHEL (see e.g. the use of CentOS docker images for building Anaconda packages!), and soaks up the cheap customers so that RHEL can focus on the much more lucrative enterprise market.\r\n\r\n...I\'m actually a bit surprised that I haven\'t heard anything about Continuum aggressively trying to poach members of RH senior management, the business model parallels are really strong both in terms of the specific distro stuff + the emphasis on contributing upstream to community OSS projects, and RH is the best in the world at making that business model work both on the money side and the community side :-). Maybe (probably) I\'m just not in those conversations...', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 198586467.0, 'datetime': '2016-03-18 23:53:46+00:00', 'masked_author': 'username_7', 'text': ""If they weren't thinking it before... :)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'sstirlin', 'comment_id': 198607044.0, 'datetime': '2016-03-19 01:32:26+00:00', 'masked_author': 'username_12', 'text': ""@username_7 This is definitely an interesting project.  You're really taking it to the next level.  I'm intrigued.\r\n\r\nQuick question:  how are you handling different recipes for different versions?  For example, the recipe to build cmake 3.5.0 will be different than the recipe to build cmake 3.3.2.\r\n\r\nI maintain a separate recipe for each version.  Sometimes I even need separate recipes to build against numpy 1.8 vs 1.9 vs 1.10."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 198639850.0, 'datetime': '2016-03-19 05:42:16+00:00', 'masked_author': 'username_7', 'text': 'cc @stuarteberg @username_15', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'pelson', 'comment_id': 198651157.0, 'datetime': '2016-03-19 07:14:59+00:00', 'masked_author': 'username_3', 'text': 'That\'s yet to be *fully* fleshed out, the phraseology to date has been ""one recipe, one repository"", but from the very beginning in my head this has really been more like ""one package, one repository"". In precisely the same way as one would manage two versions of the same software in a repo, we can manage two versions of a recipe in a repo - with branches. [GDAL-feedstock](https://github.com/conda-forge/gdal-feedstock) was the first feedstock to make use of branches in this way, and in truth we haven\'t yet followed that through into the infrastructure (e.g. are the maintainers of the feedstock the union of the maintainers in the various recipes etc.).', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 198743459.0, 'datetime': '2016-03-19 16:27:09+00:00', 'masked_author': 'username_7', 'text': 'I opened an issue ( https://github.com/conda-forge/conda-forge.github.io/issues/50 ) to discuss the versioning point more and come up with a standard for solving this kind of problem.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 201619228.0, 'datetime': '2016-03-26 00:40:42+00:00', 'masked_author': 'username_7', 'text': ""I have tried to answer your question here, @username_13, because it feels like a policy/community direction question that is closely related to the transition and where we go from here. So, didn't want it to get lost in some unrelated merged PR. Sorry it has gotten so long. It just got me thinking about how we move forward. :smile:\r\n\r\nHere are my thoughts on it and some related things to this transition. Other people may have thoughts on this, as well. It would be good if we can figure out the right way forward on the movement of recipes here (from conda-recipes and possibly other sources) and how to provide that information to others (particularly in terms of volume).\r\n\r\nWhen I move and update a recipe from conda-recipes (or anaconda-recipes) to here, I try to follow these [guidelines]( https://github.com/conda-forge/staged-recipes/issues/139 ). As part of that, I notify people who have modified the history of the recipe because they may be interested in the package it builds as they may be using it as a dependency for something. In addition, I may try to notify a core maintainer of the project or so. This process helps to generally increase awareness about conda-forge (in some cases conda) and what we are trying to do here. Also, it allows people to become aware of how the package management ecosystem in conda is changing. Finally, it gives people an opportunity to take a larger role in how packages that are important to them get distributed either by becoming a maintainer, simply submitting patches to improve the build, filing issues about how the package can be improved, or (in the case of core maintainers) notifications about when new releases are coming out so that we can get them in here quickly. All of these help improve the package management ecosystem here, which should in turn benefit the community.\r\n\r\nAdmittedly, the strategy above (of notifying a few potentially interested people) is good for slow, but consistent growth. At this point, we have 165 packages maintained here (at least according to the [conda-forge channel]( https://anaconda.org/conda-forge/ )) and it is continuing to grow. We now have 31 members. Some from Continuum, some from the Python community with various interests, a few have little if nothing to do with Python, but have become interested as this transition has occurred. This allows us to continue to fine tune the performance of our infrastructure (something we have been doing a fair bit of), experiment with things (e.g. alternative Python distributions, use of various compiler features, etc.), and discuss various approaches to interesting and challenging problems in our unique form of package management (e.g. compiler optimizations, runtime selection of AVX and SSE optimizations, API implementation selection, etc.). However, our rate of growth hasn't forced us to make hard decision on these without taking time to consider the options and how best they might be approached. While the right rate of growth is certainly up for discussion, IMHO we are growing at a reasonable rate.\r\n\r\nThe reason I mention the rate of growth here is it affects how we de-dup conda-recipes. Namely different strategies for de-duping will have different affects on how quickly our community grows. That being said, we should probably figure out how de-duping is going to occur between here and conda-recipes as maintaining two versions is of no benefit to anyone and a bit confusing too. Here are some options that have been considered and some other ones I am now thinking of, which I have cobbled together into a rough plan that would happen over time (though feedback is definitely welcome and by no means am I saying we need to commit to this). Maybe some combination of these is the right solution. There are probably more, as well.\r\n \r\n1. Mark transferred recipes as deprecated with information about where to go for their current copies.\r\n2. Place a note in the conda-recipes (and anaconda-recipes) Readme explaining that content from there is being curated and moved over here and explain what here is.\r\n3. Replace them with submodules to feedstocks.\r\n4. Remove recipe(s) and/or conda-recipes.\r\n\r\nBy doing, (1) the user is made aware on a per recipe basis that we have shifted it over and that further changes should be made here. While this helps its a bit localized and doesn't address the numerous PRs being added to conda-recipes for new packages. Combined with the existing pings for this movement, it should draw around the same number of people here maybe a few more (who were going to make some modification to it).\r\n\r\nBy doing (2), namely informing users that they should be adding new packages to conda-forge not conda-recipes. This gives them a good chance of getting binaries (something they likely want) even on platforms they may be unable to build on themselves. The low barrier to entry will be particular nice for them to do this. However, we need to keep our eyes open for abandonment. Having a large swath of unmaintained recipes is bad for everyone. This would definitely increase traffic (at least of those that read :wink:). So, we probably want to make sure things are mostly settled down (a significant chunk of the packages have moved guessing half maybe a little less) here before we explore that.\r\n\r\nDoing (3) is a bit tricky (which I will explain), but is to replace deprecated recipes with feedstocks as git submodules. As feedstocks don't have recipes in the top level directory, but one below it makes them a little difficult to use in recursive builds. If we can tweak `conda build` to correct for this issue then (3) will be more reasonable. This may seem redundant compared to the other steps (particular 1) as this (3) is the biggest attention grabber that suggests things have moved and immediately links the user to their new location. Though that combined with the technical issues is a reason to hold off on it until we are ready for that level of traffic.\r\n\r\nFinally, at some point, we may want to eliminate conda-recipes (4). However, this may depend on whether (3) can be accomplished successfully and how confusing it is. We will need to have some sort of deprecation notice on the conda-recipe's Readme. Anyone that we wouldn't have gotten will be here, so things should be pretty stable at that point and we may already have most of conda-recipes here.\r\n\r\nThis all up for discussion and none of it is set in stone. Though it is something that I felt like sharing for discussion. We need to deprecate conda-recipes, but we need to do it with an eye towards how well we can saturate the demand here.\r\n\r\nThoughts? Questions? Feedback? Is it all totally wrong? :stuck_out_tongue_winking_eye:"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'pelson', 'comment_id': 201744838.0, 'datetime': '2016-03-26 09:37:25+00:00', 'masked_author': 'username_3', 'text': ""That was a long comment! :smile: \r\nI completely agree with the growth - you've been an invaluable ambassador for conda-forge over the last few weeks, and many of the (IMHO impressive) 31 contributors are down in no small part to you :+1: \r\n\r\nI'd like to explore option 1 some more, as I think that is the only way we can truly maintain community recipes which are tested on the platforms they claim to work for."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mwcraig', 'comment_id': 202685466.0, 'datetime': '2016-03-29 03:13:07+00:00', 'masked_author': 'username_13', 'text': ""While thinking about this on my own before I found time to read your comment and the guidelines, I was leaning towards a request to add the package of interest (astropy) here and make a simultaneous pull request to delete the astropy repo in conda-recipes, which is very badly out of date (its version is 0.2.x and astropy is up to 1.1.X).\r\n\r\nI could see adding a deprecation note instead to the astropy; the broader question about transitioning is more difficult.\r\n\r\nOnce we are confident the infrastructure can scale I think an announcement to the conda and anaconda email lists from someone at Continuum indicating the Future of Conda Recipe Hosting would be helpful, with the eventual elimination of conda-recipes the end goal. A dashboard like the one at https://conda-forge.github.io//feedstocks.html could be used to point people to the correct repo for a particular package.\r\n\r\nPart of the transition should include, at some point, turning off new PRs to conda-recipes, and getting the currently open PRs there either merged before migrating recipes or migrating the PRs.\r\n  \r\nIn terms of the options you laid out I'm advocating for (1) short term, followed by (2) once we know what scales here.\r\n\r\nOnce a recipe works here I'd be inclined to delete it in conda-recipes, or replace the recipe there with a meta.yaml that just contains a link to the feedstock. A submodule would work too -- I don't know how widely conda-recipes is used for building large sets of packages.\r\n\r\nEventually (4) is necessary, I think. Given enough lead time (6 months or a year?) it shouldn't cause much disruption."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'msarahan', 'comment_id': 202686925.0, 'datetime': '2016-03-29 03:20:08+00:00', 'masked_author': 'username_9', 'text': ""I don't think killing conda-recipes is the right way.  Its contents should definitely live elsewhere, but conda-recipes itself is an important aggregation, and contains more than just Python packages (which is the primary focus of conda forge at the moment).  Conda recipes could also serve to collect recipes (submodules) from sources other than conda-forge, if any project wants to maintain their recipe themselves, outside of conda-forge.  I'm in favor of 1 and 2 now,  with 3 (with conda-build fixes) down the road a bit."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 203995870.0, 'datetime': '2016-03-31 15:51:55+00:00', 'masked_author': 'username_7', 'text': 'Give your thoughts on channel de-duping, I was curious if you had any thoughts on [this]( https://github.com/conda-forge/conda-forge.github.io/issues/22#issuecomment-201619228 ), @username_4?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'janschulz', 'comment_id': 204044746.0, 'datetime': '2016-03-31 17:38:49+00:00', 'masked_author': 'username_14', 'text': 'Some examples:\r\n\r\n|package |default | conda forge | default| explanation|\r\n|-----------|------------|-------------------|------------|------------------|\r\n|matplotlib | 1.5.0 | 1.5.1.cf | --| just the conda-forge copy of matplotlib to get new upstream versions earlier -> when `default`catches up, the `default`channel is prefered|\r\n|matplotlib | 1.5.1 | 1.5.1.cf1 | --| `default`catches up, but has a different recipe -> conda-forge needs to release a new package to catch up -> `1` after  `cf`|\r\n|matplotlib | 1.5.1 | 1.5.1.1cf | --| A fix for the package in `default` (`1` in front of `cf`), conda-forge is prefered until `default` has a new version (either upstream or with a build string)|\r\n|whatever| --- | 1.1.cf|1.1| `default` gets the recipe from conda-forge and removes the cf build line and the package is sorted higher and is now installed from `default`|', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jjhelmus', 'comment_id': 204958140.0, 'datetime': '2016-04-03 12:22:18+00:00', 'masked_author': 'username_8', 'text': ""After reading all the various suggestions which involve name mangling and custom version numbers, I'm thinking that @username_14's original suggestion of having a separate channel for conda-forge packages which are also present in default channel seems like a great solution.  If we moved all the duplicated packages into a new channel, say conda-forge-core, then users would need to explicitly add that channel or specify it in a conda install command."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ocefpaf', 'comment_id': 205000351.0, 'datetime': '2016-04-03 15:43:42+00:00', 'masked_author': 'username_0', 'text': ""I don't like the idea of more channels. IMO our goal should be quite the opposite: improve the communication to get fixes/updates/patches from conda-forge into the default channel. We don't have a concrete example of that happening right now, but @username_9 and others are present here and monitoring the activity. I see that as a win.\r\n\r\nWe do have a different problem regarding same package and version/build number. I think that must be fixed in `conda`. All we can do for ow is to bump our build number to a higher value than the default channel to avoid conflicts."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ocefpaf', 'comment_id': 205000742.0, 'datetime': '2016-04-03 15:46:58+00:00', 'masked_author': 'username_0', 'text': 'I am closing this issue as I believe we already know what to do when submitting a package that is already in the default channel. Just write the reason why are you submitting the package to conda-forge in the PR (e.g.: new patch to solve X, missing dependencies, latest version, etc).', 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'ocefpaf', 'comment_id': None, 'datetime': '2016-04-03 15:47:00+00:00', 'masked_author': 'username_0', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'created', 'author': 'janschulz', 'comment_id': 205006440.0, 'datetime': '2016-04-03 16:18:58+00:00', 'masked_author': 'username_14', 'text': '@username_0 This solution is not enough when continuum starts to import packages form conda-forge into default.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 205006678.0, 'datetime': '2016-04-03 16:21:26+00:00', 'masked_author': 'username_7', 'text': 'Please see this PR ( https://github.com/conda/conda/pull/2323 ), which is trying to better address channel conflicts.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ocefpaf', 'comment_id': 205007247.0, 'datetime': '2016-04-03 16:31:05+00:00', 'masked_author': 'username_0', 'text': 'Why not? If they keep up the pace we can just drop our version. If not we can keep on releasing and hope that conda/conda#2323 will allow them to live happy together.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'janschulz', 'comment_id': 205009438.0, 'datetime': '2016-04-03 16:59:11+00:00', 'masked_author': 'username_14', 'text': 'Because packages will end up with different things in them but exactly the same version numbers (as long as continuum does not start importing the binary packages, which IMO is not a good idea as they would have to trust every member of an org with now already 41 people in it). This will lead to things like one version having a fixed openssl included and the other version not simple because of the time when the versions were build. It might only happen a few times per package but when conda-forge has ~1000 packages, this adds up due to maintainance burden for hard to debug situations.\r\n\r\nIf this gets worse by having two different packages in these two channels (as it is currently--or at least can be--the case with the mpl package), this results in an even greater nightmare...\r\n\r\nI don\'t say the above enhancement is bad: it\'s actually great, but I think it\'s more addressing the problem of having a user channel and overwriting packages in the default channel with other ones and not the problem of two versions having (almost) the same metadata.\r\n\r\nA completely technical solution to the above problem would be if the build string could be split up into three parts: `old_build_number + setting from environment + new_one`. A repackager/ taker can only touch the `new_one` (apart from new upstreams or bugfixes), the original recipe only touches the `old_number` and the condaforge scripts set an environment variable which sets the middle to `cf` and continuum does not set it at all. On build they get mangled into the normal build string which then implements the scheme above. This would ensure that if a user has both channels included, they would get the ""right"" package (=whoever has the higher upstream version and on same upstream version, the default channel wins). This happens without user intervention via pinning.\r\n\r\nAnd you can see on first glance what packages came from the conda-forge channel, even if the user downloaded and installed the package manually.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ocefpaf', 'comment_id': 205012788.0, 'datetime': '2016-04-03 17:13:54+00:00', 'masked_author': 'username_0', 'text': 'I did not take a close at conda/conda#2323 to comment. However, I disagree that the packages have the same metadata. The origin is different and that **is** part of the metadata. (The most important part IMO.)  I think that build strings are redundant and the technical use you recommend will create an unnecessary complexity.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'janschulz', 'comment_id': 205021362.0, 'datetime': '2016-04-03 17:49:27+00:00', 'masked_author': 'username_14', 'text': 'fair enough :-) If it becomes a problem in the future, it can be solved then...', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ChrisBarker-NOAA', 'comment_id': 205025495.0, 'datetime': '2016-04-03 18:27:00+00:00', 'masked_author': 'username_2', 'text': '<https://github.com/conda-forge/conda-forge.github.io/issues/22#issuecomment-205012788>', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcg1969', 'comment_id': 205027391.0, 'datetime': '2016-04-03 18:42:33+00:00', 'masked_author': 'username_4', 'text': 'Yes, please do offer feedback on https://github.com/conda/conda/pull/2323 . It is subject to improvement---both before we merge it and after. But conda-forge is definitely one of the reasons that PR was built.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcg1969', 'comment_id': 205029541.0, 'datetime': '2016-04-03 18:46:15+00:00', 'masked_author': 'username_4', 'text': ""My view of build strings is that they serve exactly one purpose: to prevent duplicate filenames---and, in doing so, to allow users to specify a specific build of a package when they need to. I don't think it is a good idea to endow them with any semantic content that the underlying solver must depend upon. \r\n\r\nWe should be relying on channels (now that 2323 is in the pipeline), dependency differences, and features to achieve differentiation. And if those are insufficient, we should come up with new metadata approaches. But the filename itself should be irrelevant to the solver.\r\n\r\nThat's not to say that the build string and filename can't be built *from* the metadata, however."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ukoethe', 'comment_id': 205031907.0, 'datetime': '2016-04-03 18:52:01+00:00', 'masked_author': 'username_15', 'text': ""I didn't follow the discussion in detail, but would like to point out that it is possible  to add version tags to version numbers in order to disambiguate variants, like `foo-1.2.3.tag1.propA`  vs. `foo-1.2.3.tag2.propB`. Other packages can use these to refine requirements:\r\n```\r\nrequirements:\r\n  run:\r\n    - foo   *.tag1*    # won't pick up *.tag2*\r\n```\r\nI don't claim that this is necessarily a good solution, but it might be another useful trick to address the ambiguity problem."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcg1969', 'comment_id': 205032596.0, 'datetime': '2016-04-03 18:53:33+00:00', 'masked_author': 'username_4', 'text': 'I think that channels and subchannels in particular will become very powerful once something like 2323 is implemented. I think that may be the proper way to host multiple variants of the same package.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ocefpaf', 'comment_id': 205043208.0, 'datetime': '2016-04-03 19:50:09+00:00', 'masked_author': 'username_0', 'text': ':+1:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 205043278.0, 'datetime': '2016-04-03 19:51:14+00:00', 'masked_author': 'username_7', 'text': 'Hmm...not sure I see how subchannels work or how that will fit into our infrastructure yet.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 209123044.0, 'datetime': '2016-04-12 22:04:54+00:00', 'masked_author': 'username_7', 'text': '@gpilab, I noticed your channel recently and noticed that we have a lot of overlap in terms of packages we provide. Maybe you would be interested in getting packages from conda-forge. Also, as those packages are some of your dependencies, maybe being added as maintainers to the would be useful to you. I would be really interested in helping you figure your way around conda-forge. Feel free to give me a ping. :smile:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 209145974.0, 'datetime': '2016-04-12 23:16:01+00:00', 'masked_author': 'username_7', 'text': '@NLeSC, noticed that you have a variety of interesting packages some present here and some not yet present (though we are eager to add). Given this is quickly becoming the place to get packages that may not yet be packaged by Continuum and we do the builds in automated VMs in very clean environments, I think you might benefit by adding some of your packages here. Also, feel free to sign up for packages that are valuable to your effort. If you need any help figuring out what is going on, please feel free to ping me and I will be happy to get you started. :smile:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'danielfrg', 'comment_id': 209772915.0, 'datetime': '2016-04-14 05:45:11+00:00', 'masked_author': 'username_16', 'text': ""I am not catch up on all this discussion around conda-forge so I am not sure if this is the best place to do it sorry if not. I am very exited to see progress on this, great work!\r\n\r\nWith the new [conda constructor](https://github.com/conda/constructor) its really easy to make a custom conda distribution with custom packages from a conda channel. I just tested it with a file like this:\r\n\r\n```\r\nname: centonda\r\nversion: 1.0.0\r\n\r\nchannels:\r\n  - http://repo.continuum.io/pkgs/free/\r\n  - https://conda.anaconda.org/conda-forge\r\n\r\nspecs:\r\n  - python\r\n  - conda\r\n  - anyjson\r\n```\r\n\r\nAt the moment you still need `http://repo.continuum.io/pkgs/free/` in the channels list to have `python` and `conda` but you can see the idea, if these packages are on the `conda-forge` channel it would be possible to create a distribution with community created packages.\r\n\r\nIt would also be possible to make that custom distribution point to the `conda-forge` channel by default. Not as straight forward but possible, see https://github.com/conda/constructor/issues/16.\r\n\r\nJust wanted to mention this as a possibility because I haven't seen anybody discuss this option."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'pelson', 'comment_id': 209776593.0, 'datetime': '2016-04-14 06:08:14+00:00', 'masked_author': 'username_3', 'text': ""Why wouldn't they be - this is a community packaging project üòâ  üòÑ"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'danielfrg', 'comment_id': 209977086.0, 'datetime': '2016-04-14 14:41:13+00:00', 'masked_author': 'username_16', 'text': 'Definitely! Thats what I meant, a distribution with only community created packages, all open :)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'pelson', 'comment_id': 209980262.0, 'datetime': '2016-04-14 14:47:31+00:00', 'masked_author': 'username_3', 'text': ""To be fair, this repo does now contain all of the anaconda recipes which are in the conda-build form: https://github.com/ContinuumIO/anaconda-recipes\r\n\r\nBut I still don't know if that is the canonical repository..."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jakirkham', 'comment_id': 215306990.0, 'datetime': '2016-04-28 04:25:34+00:00', 'masked_author': 'username_7', 'text': '@pkgw, noticed that you have a variety of interesting packages some present here and some not yet present (though we are eager to add). Given this is quickly becoming the place to get packages that may not yet be packaged by Continuum and we do the builds in automated CI VMs in very clean environments, I think you might benefit by adding some of your packages here. Also, feel free to sign up for packages that are valuable to your effort. If you need any help figuring out what is going on, please feel free to ping me and I will be happy to get you started. :smile:', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: When to package software which is already in the default conda channel
username_0: (@username_1 brought this up in https://github.com/conda-forge/conda-forge.github.io/issues/16#issuecomment-182430891)

I Agreed with @username_1 that we should avoid as much as possible to add packages in conda-forge that are available in the default channel.

However, we already have a few redundant packages (`pyproj`, `shapely`, `geos`, and more to come soon). The reason for thw redundancy is that those packages are partially broken in the default channel.
(And we could not find a proper channel of communication to send the recipe patch back to them.)

Maybe, when fixing a default channel package we should allow the package addition here as long as there is a plan to send that fix back to the default channel, and to remove the package from conda-forge once that happens.
<issue_comment>username_1: Maybe register a new channel: ""temporary-fixes""?
<issue_comment>username_1: Maybe @username_4 has some idea how this could be handled?
<issue_comment>username_2: I'm not sure it's worth a different channel.

But I wonder if we should give the package a different name, otherwise things can get pretty tangled up:

gdal-cf
or ????

(cf for conda forge...)

That means that anyone using it has to change the dependency, but are there going to be any packages outside of conda-forge that depend on a conda-forge special build???
<issue_comment>username_0: :-1:  that can be confusing.  We can maybe ""sign"" the packages with a build string like

```
build:
    string: conda-forge
```

But IMO just having the package in a different channel should be enough to disambiguate.
<issue_comment>username_1: The reason for a different channel is IMO that I suspect that at some point users will add conda-forge to their default channels and a different channel than that means that users an get the updated/fixed version with `conda install -c whatever matplotlib` but not on a simple `conda update --all`.
<issue_comment>username_2: I'm not sure the channel disambiguates -- does conda prioritize default or your other channels?

But I wonder where all this goes -- with PyPi, it's up to each package maintainer to keep things up to date. with anaconda, it's up to third parties -- mainly continuum. so if they don't, then what?

I'm hoping continuum will adopt a more community model, where folks can easily provide PRs -- it seems it would only save them work. So we'll see.

In the meantime, conda-forge may become the community channel, and I""d say if you want the latest and greatest, then you add that channel -- and you'll get the new MPL, or whatever, if conda-forge provides a newer one than default.

We will probably want to clean things out as continuum catches up.

I'm still wondering about the naming though:

continuum builds package-1.2.1

a new version comes out, and folks want it -- but continuum is being slow on teh draw.

conda-forge provides package-1.3.1

all is good.

now continuum catches up and builds a package-1.3.1 -- now there are two, with the same version. And maybe they are even incompatible in some way. This could make a mess for our users.

If we go with Jan's approach, then this would be cleaner, but users would have to explicilty make a point of getting a newer version -- I think that would be awkward and often missed as an option.
<issue_comment>username_1: As this probably requires changes  in conda, I would vote for `1.3.0_real_1.3.1` which sorts before `1.3.1`, but after `1.3.0`.
<issue_comment>username_1: Hah, it seems conda already implments such a scheme, so `1.3.1.cf` is lower than `1.3.1`
https://github.com/conda/conda/blob/2ba04a6b2617227de578f4af54ff11115f97ca5c/conda/version.py#L81
<issue_comment>username_2: nice!, maybe we can use that, then.

-CHB
<issue_comment>username_0: :+1:
<issue_comment>username_1: This is probably https://github.com/conda/conda/issues/1967
<issue_comment>username_3: This is the real problem here. We have, in the past, fixed packages (on IOOS and SciTools) which Continuum package, often by releasing a newer version. The problem comes when Continuum update the version of the software they package, but don't actually fix the problem. This has happened on several occasions with packages such as Shapely and pyproj. From a user's perspective, they are just updating their software and it goes from a functional state to a non-functional state - not really ideal. Because of the lack of a repository of canonical recipe source, all we have been able to do is report a problem with the package, not actually fix it (i.e. in the form of a PR).

-----------

@username_7, @username_6 and @username_5 have all expressed an opinion on the subject of this issue in the past. Do any of you have comments on when it should be the place of conda-forge to package software which is already being packaged by Continuum?
<issue_comment>username_4: @username_1 thanks for pinging me. There's not a whole lot I can officially say yet, except that we recognize the need to support alternatives to Continuum's `default` channels. We're actively working on a particular community channel solution, but it is not the only way forward, and it _shouldn't_ be. We've been watching the Conda Forge project with enthusiasm. As we talk more we may be able to come up with some specific ways Continuum can help with it. But having an effort like this that Continuum _does not control_ is beneficial to the Python community at large, so I'm grateful you're working on it.

I see three different problems with the default channel:

1. Not every package people want can be, or should be, available there.
2. Continuum updates those packages less frequently than the primary developers of the packages.
3. The packages may not be compiled with the same options that some users like to see.

All three of these issues are an inevitable consequence of Continuum's finite resources for building and supporting packages. We certainly acknowledge that this isn't going to satisfy people who regularly bump up against one of these three problems. Heck I bump up against all three of these problems myself.

My particular perspective, as many of you know who have been watching my conda fixes recently, is on the _dependency solver_. I've been spending time overhauling it, and it's certainly going to fix some of the issues like `conda update --all` being slow, `conda remove` potentially breaking installs, etc. I'm glad @username_3 is confirming that my improvements are beginning to make a difference. 

But honestly, the mathematics of the solver isn't really the issue here, at least not directly. What you are discussing in this thread is basically the challenge of _channel clashes_. That is: how should conda handle things when two or more channels release versions of the same package? At the moment, conda effectively ""merges"" the channels together, so that the packages interleave with each other purely based on version and build numbers. That's clearly not a workable solution. For one thing, build numbers don't have meaning across channels; so for instance, build 1 from channel A may actually be _newer_ than build 2 from channel B, and conda doesn't know that. This is something we need to decide on a fix for.

What we need, it seems to me, is to identify specific improvements to conda that would greatly improve the ability to use alternate, community-driven package channels. For instance:

1) A fix for conda that untangles packages/channel conflicts. For instance, we could say that the highest-priority channel is always preferred for a package, and any packages by the same name in lower-prioirity channels are ignored. But I could see a variety of other strategies, and perhaps conda should adopt several, choose on as a default, but make the others available by configuration.

2) An enhancement to conda that allows channel preferences to be adopted on a _per-package_ and or _per-environment_ basis. For example, perhaps I add the `conda-forge` channel as a lower-priority channel, but I actually prefer one of its packages to the one provided in `default`. There should be a way to specify that priority preference and persist it across updates and later installations.

This is the kind of thinking that would be very helpful for me personally. We really do want `conda` to be adopted more widely---heck, we'd be pleased if someone built their own Python distribution that used `conda` as a packaging model. And we'd like to find ways to enable groups like Conda Forge to flourish without having to wait on us. I actually do think that there are some changes to `conda` that we can push through in the short term that will greatly improve our ability to work in parallel.
<issue_comment>username_0: Having a way to specify channel preference globally or per env would be a really good addition to conda.

:+1:
<issue_comment>username_4: I would really rather we tackle the channel collision problem _correctly_ than to utilize weird version numbers or (even worse) track_features to disambiguate.
<issue_comment>username_5: If we could get Continuum to open recipes (or adopt community recipes upon
submission, and then open those up), then perhaps much of the problem can
be avoided? Ideally, we do not want multiple versions of numpy with the
same version tag floating around.

An alternative path is to build everything you need into your own channel.

For mixed channels, I don't see a straightforward way of resolving what to
install without additional meta-data. In Debian there is the concept of
""pinning"", which allows you to fix certain packages in place.
<issue_comment>username_2: @username_4: absolutely -- but we need help from conda itself to do it ""right"" -- are you speaking for continuum, hard to tell :-)

@username_0 wrote: ""Having a way to specify channel preference globally or per env would be a really good addition to conda.""

I think that would actually be a simple solution that would mostly solve the problem at hand -- folks could put the IOS channel, or conda-forge channel at their first preference, and then they would get the latest and greatest.

Granted, the default channel may get updated in a way that leapfrogs conda-forge, but I think it will be up to whoever is maintaining the conda-forge package to keep an eye on that.

And the default channel is clearly the upstream one -- conda-forge will be following its lead, so that could work.
<issue_comment>username_2: I've been thinking a bit about how this works with PyPi (and PyPi does work well, for the things i works well for, i.e. pure-python packages)

It is a totally different model -- PyPa only provides the infrastructure -- each and every package is maintained by individual package maintainers. Ideally, conda packaging could go that way, but it's going to be a long time (or never) before package authors in general support conda. (never mind non-python stuff....)

By my idea, at least, is that conda-forge becomes the PyPi-like place for conda packages -- it will start (has started) with groups of packages that are not in the default channel being maintained by a third party, but hopefully individual package authors will start to maintain their own packages. So we need to design the infrastructure to support that.

In fact, as a package author steps up to maintain a package, maybe it could even be removed from the default channel. In the long run, maybe continuum will need to maintain few packages, and rather, have Anaconda be the ""curated"" selection, but much of it would be pulled in from the authors' builds (OK, maybe that's a fantasy).

Anyway, what all this means is that it should be very easy for a package author to push builds to conda-forge, like it is now with PyPi being integrated into the PyPa stack (distutils, setuptools, pip, I""ve lost track...)
<issue_comment>username_1: One easy idea would be to add somethign like this:

```
conda install -c conda-forge --pin-channel matplotlib
```

That would add an entry to the config file that matplotlib should be taken from the conda-forge and all other packages with the same name form other channels should be discarded (e.g. simple add a step-0 to the solver which removes all matplotlib packages from other channels from the list of available packages).

This will help with the problem of ""fixing"" packages in the default channel (and IMO this should be the only part where conda-forge should package packages in the default channel).

Another step would be to configure the ""default"" channel, so that conda does not see the anaconda/Continuum packages at all. Not sure if that is possible today?
<issue_comment>username_2: @username_5: Absolutely!

If the default channel was built from (mostly) recipes maintained in a public gitHub project(s), it would be monstrously easier to keep everything up to date and in-sync. We could/would do a lot of the work for continuum.

And they could start one package at a time (shapely?).. it wouldn't have to be a wholesale, all at once move.

I can imagine it's inertia more than anything else that's prevented this from happening so far, but it's a bit frustrating from outside.

-CHB
<issue_comment>username_1: submission, and then open those up), then perhaps much of the problem can
be avoided?

I think it would already be enough if Continuum would add all their package recipes (as they are currently used -> the [matplotlib recipe in the conda-recipes repo](https://github.com/conda/conda-recipes/tree/master/python/matplotlib) is out of date) and accept PRs for already included packages. I would be happy to add patches there if I know that they land on my HD a day after they are merged... Contiuum still would have the final say, it would speed up the updates on new upstream releases, and Continuum would have less work... (cc: @username_4 :-) )
<issue_comment>username_6: @username_4 articulated many of my thoughts more coherently than I would have, I think channel-level precedence is the probably the right way to fix this, but I would like a way to control (maybe at the package level) if it goes with newest-possible or prefers a specific channel.  

I was also thinking of the debian idea of 'pinning' as a model for how to do this.

For day-job we have been making aggressive use of 'postN' versioning (pulled directly from git describe via versioneer) which helps the case where the issue is fixes from up-stream project is adding/fixing things.  Although, this can get funny if you are packing commits from side-branches and definitely does not help if the difference is different sets of locally applied patches or build configuration.
<issue_comment>username_7: Pinning channel might be ok as long as it is per environment.
<issue_comment>username_0: @username_6 my Linux distro (OpenSUSE) does exactly that.  I can set repository preferences that will be used when updating the system, but I can also do a ""distribution upgrade"" that will get the newest-possible from all repositories. This operations issues warnings stating that the user is responsible for the system stability when adding third party repository and performing the distribution upgrade. Conda is dangerously confusing with that!  I can see tons of users breaking their system using conda-forge packages and going to Continuum mailing list to complain.

With that said. This behavior might be a long-term goal.  Right now I believe that a global channel preference is already a big win.
<issue_comment>username_0: Agreed.

https://github.com/conda/conda/issues/982
<issue_comment>username_1: For a idea on how to mark package/channel combinations as good/bad: https://github.com/conda/conda/issues/2067
<issue_comment>username_8: That sounds like a challenge!  Accepted, [acpd, Another Conda-base Python Distribution](https://github.com/acpd/acpd).

On that topic and related to packaging software already in the default conda channel, would it be possible for someone from Continuum to clarify the license of the recipes in the [ContinuumIO/anaconda-recipes](https://github.com/ContinuumIO/anaconda-recipes) repository?  A number of those are prime candidates for use in conda-forge.
<issue_comment>username_7: Nice! Do you have any thoughts on their integration into conda-forge, @username_8?
<issue_comment>username_8: Long term I think they could be integrated into conda-forge, but first some logistics need to be worked out.  Having a conda-forge version of conda clobber the Continuum version would not be good.
<issue_comment>username_7: Maybe they could be placed under a special label that is different from `main` so they could be opted into instead of installed by default when adding conda-forge.
<issue_comment>username_8: I could be wrong but I do not think having a non `main` label is taken into account when doing a conda install from Anaconda.org.  Having a separate channel for these packages might be a possibility but it seem liked the consensus in this issue was that this was not an ideal situation.
<issue_comment>username_9: Anaconda-recipes is BSD, same as Conda-recipes.  Sorry that wasn't posted.  I have added it.  It is our intent to move everything in anaconda-recipes to the conda-forge-feeding-community-channel plan.  If anyone would like to help in that effort, we'd appreciate it.  The gist of that plan is:

1. We move recipes from the internal repo, anaconda-recipes, and conda-recipes to conda-forge.  Those other places are either shut down or replaced with links or git submodules (like the ""feedstocks"" repo in conda-forge)
2. We mirror or link packages built by conda-forge on our ""community"" anaconda.org channel.  There may be other sources of packages there, also.
3. We run a validation process on packages (inspect recipe, run test suites, verify package contents against a build of the recipe).  Once verified, these packages will become the content on the default channel.
<issue_comment>username_8: Great, thanks for the clarification @username_9
<issue_comment>username_7: Will this verification process be done in the open? For instance, will the scripts for this verification be placed in a public repo? I imagine that it will be nice to include these checks in the process of determining whether a package gets added on this side, as well.
<issue_comment>username_9: Great idea.  There is no security in obscurity, and I would appreciate all of your support in developing this process / tool.  I will come up with a repo for it tomorrow after some discussion internally on where it fits.
<issue_comment>username_2: This sounds like the end game is to have the default channel host all
continuum packages, as well as all community-maintained packages.

So will there be any place for a ""community"" or ""cons-forge"" channel at all?

On the one hand -- great for the user community. On the other hand, I
have a hard-to-define impression that there will still be a need for
""something"" in between the default channel and a random scattering of
channels on Anaconda.org.

I.e. Multiple levels of ""trust"":

Anaconda: tested by continuum and all known to work together.

Default: tested by continuum, with the lastest and greatest.

Community: curated by a trusted community, maybe experimental builds,
release candidates, etc.

Arbitrary Anaconda.org: Buyer beware !

-CHB
<issue_comment>username_9: Your hierarchy sounds pretty reasonable, and very much in line with what I have in mind.  The default channel is less ""hosting all continuum packages"" and more ""hosting continuum-verified community-maintained packages.""  Continuum is participating in the maintenance as well, not just pawning it off.  However, it is a reduction of Continuum's role as ""authoritative builder"" to ""tester/verifier/integrator of packages built by a standard community-accessible system.""  The default channel still involves human verification on our end, and will trail the community channel to some extent.  More importantly, the community channel's critical place is an aggregator, where a single central channel combines authoritative packages from multiple other channels.  This hopefully will help all kinds of package conflict and channel priority issues.

I see arbitrary anaconda.org less as ""buyer beware"" and more as ""YMMV.""  If small channels want to play ball with standards and all that, they'll be very welcome in the community channel.  A very easy way to do that would be to just contribute packages to conda-forge.
<issue_comment>username_2: well, sure -- the point was that if you use an arbitrary anaconda.org channel,
it is up to you to confirm who built it, whether it suites your needs, and
whether it is safe.

I haven't heard of any obuses, but one certainly COULD put all kinds of
dangerous software up on an anaconda.org channel -- makes me nervous!

-CHB


-- 

Christopher Barker, Ph.D.
Oceanographer

Emergency Response Division
NOAA/NOS/OR&R            (206) 526-6959   voice
7600 Sand Point Way NE   (206) 526-6329   fax
Seattle, WA  98115       (206) 526-6317   main reception

Chris.Barker@noaa.gov
<issue_comment>username_7: Sounds good. Feel free to ping me when it is up. Would be nice to get a feeling as to the requirements for validation to start.
<issue_comment>username_7: cc @username_10
<issue_comment>username_10: Thanks for cc'ing me @username_7. This sounds amazing. It would be really really good to have a sort of staggered release schedule whereby the community thinks things are good to ship onto conda-forge and then continuum eventually pulls them onto mainline once verified. This will be great for much smaller packages too.

If we decide on the protocol for all of this I'd be really happy to evangelise it by writing some blog posts/documentation about how package maintainers can easily opt into conda in a similar manner as they do to PyPi but via conda-forge!

I suppose I should start submitting some of the recipes I have like opencv that will likely be widely useful! I need to get a feel for how conda-forge works yet but I'd be really happy to move away from hosting my own packages for other big projects if possible.
<issue_comment>username_7: Not sure if this is up your alley, @hajs, but I figured you might be interested in this sort of system and with your wide breadth of recipes we would certainly appreciate your feedback going forward and any contributions you would be willing to me.
<issue_comment>username_11: Just a quick comment: it might be worth studying the way the Fedora/rhel/centos ecosystem works in detail for inspiration, since it sounds like you might be moving towards reinventing large parts of it :-)
<issue_comment>username_7: What can we say? We are unreasonable people. We want a package manager that is cross platform, doesn't require `sudo`, and let's Python be awesome. :smile:
<issue_comment>username_0: I am stealing that phrase next time I have to prepare a presentation on conda/conda-forge :wink:
<issue_comment>username_9: Thanks, @username_11 - I would do well to study that, since I have been proposing much of this process.  It makes perfect sense now that you mention it, but I've had my head stuck in Windows and Ubuntu sand for too long to be aware of it.  I'll go study.

@username_7 and @username_0, I believe his comment is aimed at the process of community-developed packages feeding into an enterprise system (which then may spawn a community-led enterprise system), more than he is talking about build strategies of any given recipe.
<issue_comment>username_7: @username_12, given your views on packaging and the value of `conda` not to mention your [extensive recipe collection]( https://github.com/ActivisionGameScience/ags_conda_recipes ), we would be really interested in working with you to help get this all integrated into conda-forge. It will definitely help us and should help you reduce your maintenance burden. Please let us know how we can help.
<issue_comment>username_11: Exactly -- the social technology, not the code technology :-).
<issue_comment>username_7: This is clear.
<issue_comment>username_6: centos:fedora:RHEL :: conda-forge:anaconda:anaconda-enterprise
<issue_comment>username_11: I don't know that conda would necessarily want to follow the exact evolution of the RH ecosystem, but Fedora, RHEL, and CentOS are 3 closely related systems that share lots of engineering work but make different kinds of trade-offs and target different market segments -- Fedora as a fast-moving  project with an emphasis on free software ideals and community-led-governance (but with support from RH for infrastructure like servers and legal compliance), that also serves as a beta testing ground for RHEL; RHEL as the commercially supported ultra-stable enterprise platform, and CentOS as a free version of RHEL without the commercial support for those who want a slow-moving enterprise-y product and to take advantage of RH's QA, but don't want to pay for it. (There's definitely a desire in the community a ""CentOS Anaconda"" -- cf. the repeated complaints about the closed build recipes for core packages.) All together these form a neat ecosystem in which the different parse support each other -- e.g. CentOS might sound like a competitor to RHEL, but in fact it's RH themselves manage it and see it as a kind of loss leader that gets people into their ecosystem, makes it easier for third-parties to support RHEL (see e.g. the use of CentOS docker images for building Anaconda packages!), and soaks up the cheap customers so that RHEL can focus on the much more lucrative enterprise market.

...I'm actually a bit surprised that I haven't heard anything about Continuum aggressively trying to poach members of RH senior management, the business model parallels are really strong both in terms of the specific distro stuff + the emphasis on contributing upstream to community OSS projects, and RH is the best in the world at making that business model work both on the money side and the community side :-). Maybe (probably) I'm just not in those conversations...
<issue_comment>username_7: If they weren't thinking it before... :)
<issue_comment>username_12: @username_7 This is definitely an interesting project.  You're really taking it to the next level.  I'm intrigued.

Quick question:  how are you handling different recipes for different versions?  For example, the recipe to build cmake 3.5.0 will be different than the recipe to build cmake 3.3.2.

I maintain a separate recipe for each version.  Sometimes I even need separate recipes to build against numpy 1.8 vs 1.9 vs 1.10.
<issue_comment>username_7: cc @stuarteberg @username_15
<issue_comment>username_3: That's yet to be *fully* fleshed out, the phraseology to date has been ""one recipe, one repository"", but from the very beginning in my head this has really been more like ""one package, one repository"". In precisely the same way as one would manage two versions of the same software in a repo, we can manage two versions of a recipe in a repo - with branches. [GDAL-feedstock](https://github.com/conda-forge/gdal-feedstock) was the first feedstock to make use of branches in this way, and in truth we haven't yet followed that through into the infrastructure (e.g. are the maintainers of the feedstock the union of the maintainers in the various recipes etc.).
<issue_comment>username_7: I opened an issue ( https://github.com/conda-forge/conda-forge.github.io/issues/50 ) to discuss the versioning point more and come up with a standard for solving this kind of problem.
<issue_comment>username_7: I have tried to answer your question here, @username_13, because it feels like a policy/community direction question that is closely related to the transition and where we go from here. So, didn't want it to get lost in some unrelated merged PR. Sorry it has gotten so long. It just got me thinking about how we move forward. :smile:

Here are my thoughts on it and some related things to this transition. Other people may have thoughts on this, as well. It would be good if we can figure out the right way forward on the movement of recipes here (from conda-recipes and possibly other sources) and how to provide that information to others (particularly in terms of volume).

When I move and update a recipe from conda-recipes (or anaconda-recipes) to here, I try to follow these [guidelines]( https://github.com/conda-forge/staged-recipes/issues/139 ). As part of that, I notify people who have modified the history of the recipe because they may be interested in the package it builds as they may be using it as a dependency for something. In addition, I may try to notify a core maintainer of the project or so. This process helps to generally increase awareness about conda-forge (in some cases conda) and what we are trying to do here. Also, it allows people to become aware of how the package management ecosystem in conda is changing. Finally, it gives people an opportunity to take a larger role in how packages that are important to them get distributed either by becoming a maintainer, simply submitting patches to improve the build, filing issues about how the package can be improved, or (in the case of core maintainers) notifications about when new releases are coming out so that we can get them in here quickly. All of these help improve the package management ecosystem here, which should in turn benefit the community.

Admittedly, the strategy above (of notifying a few potentially interested people) is good for slow, but consistent growth. At this point, we have 165 packages maintained here (at least according to the [conda-forge channel]( https://anaconda.org/conda-forge/ )) and it is continuing to grow. We now have 31 members. Some from Continuum, some from the Python community with various interests, a few have little if nothing to do with Python, but have become interested as this transition has occurred. This allows us to continue to fine tune the performance of our infrastructure (something we have been doing a fair bit of), experiment with things (e.g. alternative Python distributions, use of various compiler features, etc.), and discuss various approaches to interesting and challenging problems in our unique form of package management (e.g. compiler optimizations, runtime selection of AVX and SSE optimizations, API implementation selection, etc.). However, our rate of growth hasn't forced us to make hard decision on these without taking time to consider the options and how best they might be approached. While the right rate of growth is certainly up for discussion, IMHO we are growing at a reasonable rate.

The reason I mention the rate of growth here is it affects how we de-dup conda-recipes. Namely different strategies for de-duping will have different affects on how quickly our community grows. That being said, we should probably figure out how de-duping is going to occur between here and conda-recipes as maintaining two versions is of no benefit to anyone and a bit confusing too. Here are some options that have been considered and some other ones I am now thinking of, which I have cobbled together into a rough plan that would happen over time (though feedback is definitely welcome and by no means am I saying we need to commit to this). Maybe some combination of these is the right solution. There are probably more, as well.
 
1. Mark transferred recipes as deprecated with information about where to go for their current copies.
2. Place a note in the conda-recipes (and anaconda-recipes) Readme explaining that content from there is being curated and moved over here and explain what here is.
3. Replace them with submodules to feedstocks.
4. Remove recipe(s) and/or conda-recipes.

By doing, (1) the user is made aware on a per recipe basis that we have shifted it over and that further changes should be made here. While this helps its a bit localized and doesn't address the numerous PRs being added to conda-recipes for new packages. Combined with the existing pings for this movement, it should draw around the same number of people here maybe a few more (who were going to make some modification to it).

By doing (2), namely informing users that they should be adding new packages to conda-forge not conda-recipes. This gives them a good chance of getting binaries (something they likely want) even on platforms they may be unable to build on themselves. The low barrier to entry will be particular nice for them to do this. However, we need to keep our eyes open for abandonment. Having a large swath of unmaintained recipes is bad for everyone. This would definitely increase traffic (at least of those that read :wink:). So, we probably want to make sure things are mostly settled down (a significant chunk of the packages have moved guessing half maybe a little less) here before we explore that.

Doing (3) is a bit tricky (which I will explain), but is to replace deprecated recipes with feedstocks as git submodules. As feedstocks don't have recipes in the top level directory, but one below it makes them a little difficult to use in recursive builds. If we can tweak `conda build` to correct for this issue then (3) will be more reasonable. This may seem redundant compared to the other steps (particular 1) as this (3) is the biggest attention grabber that suggests things have moved and immediately links the user to their new location. Though that combined with the technical issues is a reason to hold off on it until we are ready for that level of traffic.

Finally, at some point, we may want to eliminate conda-recipes (4). However, this may depend on whether (3) can be accomplished successfully and how confusing it is. We will need to have some sort of deprecation notice on the conda-recipe's Readme. Anyone that we wouldn't have gotten will be here, so things should be pretty stable at that point and we may already have most of conda-recipes here.

This all up for discussion and none of it is set in stone. Though it is something that I felt like sharing for discussion. We need to deprecate conda-recipes, but we need to do it with an eye towards how well we can saturate the demand here.

Thoughts? Questions? Feedback? Is it all totally wrong? :stuck_out_tongue_winking_eye:
<issue_comment>username_3: That was a long comment! :smile: 
I completely agree with the growth - you've been an invaluable ambassador for conda-forge over the last few weeks, and many of the (IMHO impressive) 31 contributors are down in no small part to you :+1: 

I'd like to explore option 1 some more, as I think that is the only way we can truly maintain community recipes which are tested on the platforms they claim to work for.
<issue_comment>username_13: While thinking about this on my own before I found time to read your comment and the guidelines, I was leaning towards a request to add the package of interest (astropy) here and make a simultaneous pull request to delete the astropy repo in conda-recipes, which is very badly out of date (its version is 0.2.x and astropy is up to 1.1.X).

I could see adding a deprecation note instead to the astropy; the broader question about transitioning is more difficult.

Once we are confident the infrastructure can scale I think an announcement to the conda and anaconda email lists from someone at Continuum indicating the Future of Conda Recipe Hosting would be helpful, with the eventual elimination of conda-recipes the end goal. A dashboard like the one at https://conda-forge.github.io//feedstocks.html could be used to point people to the correct repo for a particular package.

Part of the transition should include, at some point, turning off new PRs to conda-recipes, and getting the currently open PRs there either merged before migrating recipes or migrating the PRs.
  
In terms of the options you laid out I'm advocating for (1) short term, followed by (2) once we know what scales here.

Once a recipe works here I'd be inclined to delete it in conda-recipes, or replace the recipe there with a meta.yaml that just contains a link to the feedstock. A submodule would work too -- I don't know how widely conda-recipes is used for building large sets of packages.

Eventually (4) is necessary, I think. Given enough lead time (6 months or a year?) it shouldn't cause much disruption.
<issue_comment>username_9: I don't think killing conda-recipes is the right way.  Its contents should definitely live elsewhere, but conda-recipes itself is an important aggregation, and contains more than just Python packages (which is the primary focus of conda forge at the moment).  Conda recipes could also serve to collect recipes (submodules) from sources other than conda-forge, if any project wants to maintain their recipe themselves, outside of conda-forge.  I'm in favor of 1 and 2 now,  with 3 (with conda-build fixes) down the road a bit.
<issue_comment>username_7: Give your thoughts on channel de-duping, I was curious if you had any thoughts on [this]( https://github.com/conda-forge/conda-forge.github.io/issues/22#issuecomment-201619228 ), @username_4?
<issue_comment>username_14: Some examples:

|package |default | conda forge | default| explanation|
|-----------|------------|-------------------|------------|------------------|
|matplotlib | 1.5.0 | 1.5.1.cf | --| just the conda-forge copy of matplotlib to get new upstream versions earlier -> when `default`catches up, the `default`channel is prefered|
|matplotlib | 1.5.1 | 1.5.1.cf1 | --| `default`catches up, but has a different recipe -> conda-forge needs to release a new package to catch up -> `1` after  `cf`|
|matplotlib | 1.5.1 | 1.5.1.1cf | --| A fix for the package in `default` (`1` in front of `cf`), conda-forge is prefered until `default` has a new version (either upstream or with a build string)|
|whatever| --- | 1.1.cf|1.1| `default` gets the recipe from conda-forge and removes the cf build line and the package is sorted higher and is now installed from `default`|
<issue_comment>username_8: After reading all the various suggestions which involve name mangling and custom version numbers, I'm thinking that @username_14's original suggestion of having a separate channel for conda-forge packages which are also present in default channel seems like a great solution.  If we moved all the duplicated packages into a new channel, say conda-forge-core, then users would need to explicitly add that channel or specify it in a conda install command.
<issue_comment>username_0: I don't like the idea of more channels. IMO our goal should be quite the opposite: improve the communication to get fixes/updates/patches from conda-forge into the default channel. We don't have a concrete example of that happening right now, but @username_9 and others are present here and monitoring the activity. I see that as a win.

We do have a different problem regarding same package and version/build number. I think that must be fixed in `conda`. All we can do for ow is to bump our build number to a higher value than the default channel to avoid conflicts.
<issue_comment>username_0: I am closing this issue as I believe we already know what to do when submitting a package that is already in the default channel. Just write the reason why are you submitting the package to conda-forge in the PR (e.g.: new patch to solve X, missing dependencies, latest version, etc).<issue_closed>
<issue_comment>username_14: @username_0 This solution is not enough when continuum starts to import packages form conda-forge into default.
<issue_comment>username_7: Please see this PR ( https://github.com/conda/conda/pull/2323 ), which is trying to better address channel conflicts.
<issue_comment>username_0: Why not? If they keep up the pace we can just drop our version. If not we can keep on releasing and hope that conda/conda#2323 will allow them to live happy together.
<issue_comment>username_14: Because packages will end up with different things in them but exactly the same version numbers (as long as continuum does not start importing the binary packages, which IMO is not a good idea as they would have to trust every member of an org with now already 41 people in it). This will lead to things like one version having a fixed openssl included and the other version not simple because of the time when the versions were build. It might only happen a few times per package but when conda-forge has ~1000 packages, this adds up due to maintainance burden for hard to debug situations.

If this gets worse by having two different packages in these two channels (as it is currently--or at least can be--the case with the mpl package), this results in an even greater nightmare...

I don't say the above enhancement is bad: it's actually great, but I think it's more addressing the problem of having a user channel and overwriting packages in the default channel with other ones and not the problem of two versions having (almost) the same metadata.

A completely technical solution to the above problem would be if the build string could be split up into three parts: `old_build_number + setting from environment + new_one`. A repackager/ taker can only touch the `new_one` (apart from new upstreams or bugfixes), the original recipe only touches the `old_number` and the condaforge scripts set an environment variable which sets the middle to `cf` and continuum does not set it at all. On build they get mangled into the normal build string which then implements the scheme above. This would ensure that if a user has both channels included, they would get the ""right"" package (=whoever has the higher upstream version and on same upstream version, the default channel wins). This happens without user intervention via pinning.

And you can see on first glance what packages came from the conda-forge channel, even if the user downloaded and installed the package manually.
<issue_comment>username_0: I did not take a close at conda/conda#2323 to comment. However, I disagree that the packages have the same metadata. The origin is different and that **is** part of the metadata. (The most important part IMO.)  I think that build strings are redundant and the technical use you recommend will create an unnecessary complexity.
<issue_comment>username_14: fair enough :-) If it becomes a problem in the future, it can be solved then...
<issue_comment>username_2: <https://github.com/conda-forge/conda-forge.github.io/issues/22#issuecomment-205012788>
<issue_comment>username_4: Yes, please do offer feedback on https://github.com/conda/conda/pull/2323 . It is subject to improvement---both before we merge it and after. But conda-forge is definitely one of the reasons that PR was built.
<issue_comment>username_4: My view of build strings is that they serve exactly one purpose: to prevent duplicate filenames---and, in doing so, to allow users to specify a specific build of a package when they need to. I don't think it is a good idea to endow them with any semantic content that the underlying solver must depend upon. 

We should be relying on channels (now that 2323 is in the pipeline), dependency differences, and features to achieve differentiation. And if those are insufficient, we should come up with new metadata approaches. But the filename itself should be irrelevant to the solver.

That's not to say that the build string and filename can't be built *from* the metadata, however.
<issue_comment>username_15: I didn't follow the discussion in detail, but would like to point out that it is possible  to add version tags to version numbers in order to disambiguate variants, like `foo-1.2.3.tag1.propA`  vs. `foo-1.2.3.tag2.propB`. Other packages can use these to refine requirements:
```
requirements:
  run:
    - foo   *.tag1*    # won't pick up *.tag2*
```
I don't claim that this is necessarily a good solution, but it might be another useful trick to address the ambiguity problem.
<issue_comment>username_4: I think that channels and subchannels in particular will become very powerful once something like 2323 is implemented. I think that may be the proper way to host multiple variants of the same package.
<issue_comment>username_0: :+1:
<issue_comment>username_7: Hmm...not sure I see how subchannels work or how that will fit into our infrastructure yet.
<issue_comment>username_7: @gpilab, I noticed your channel recently and noticed that we have a lot of overlap in terms of packages we provide. Maybe you would be interested in getting packages from conda-forge. Also, as those packages are some of your dependencies, maybe being added as maintainers to the would be useful to you. I would be really interested in helping you figure your way around conda-forge. Feel free to give me a ping. :smile:
<issue_comment>username_7: @NLeSC, noticed that you have a variety of interesting packages some present here and some not yet present (though we are eager to add). Given this is quickly becoming the place to get packages that may not yet be packaged by Continuum and we do the builds in automated VMs in very clean environments, I think you might benefit by adding some of your packages here. Also, feel free to sign up for packages that are valuable to your effort. If you need any help figuring out what is going on, please feel free to ping me and I will be happy to get you started. :smile:
<issue_comment>username_16: I am not catch up on all this discussion around conda-forge so I am not sure if this is the best place to do it sorry if not. I am very exited to see progress on this, great work!

With the new [conda constructor](https://github.com/conda/constructor) its really easy to make a custom conda distribution with custom packages from a conda channel. I just tested it with a file like this:

```
name: centonda
version: 1.0.0

channels:
  - http://repo.continuum.io/pkgs/free/
  - https://conda.anaconda.org/conda-forge

specs:
  - python
  - conda
  - anyjson
```

At the moment you still need `http://repo.continuum.io/pkgs/free/` in the channels list to have `python` and `conda` but you can see the idea, if these packages are on the `conda-forge` channel it would be possible to create a distribution with community created packages.

It would also be possible to make that custom distribution point to the `conda-forge` channel by default. Not as straight forward but possible, see https://github.com/conda/constructor/issues/16.

Just wanted to mention this as a possibility because I haven't seen anybody discuss this option.
<issue_comment>username_3: Why wouldn't they be - this is a community packaging project üòâ  üòÑ
<issue_comment>username_16: Definitely! Thats what I meant, a distribution with only community created packages, all open :)
<issue_comment>username_3: To be fair, this repo does now contain all of the anaconda recipes which are in the conda-build form: https://github.com/ContinuumIO/anaconda-recipes

But I still don't know if that is the canonical repository...
<issue_comment>username_7: @pkgw, noticed that you have a variety of interesting packages some present here and some not yet present (though we are eager to add). Given this is quickly becoming the place to get packages that may not yet be packaged by Continuum and we do the builds in automated CI VMs in very clean environments, I think you might benefit by adding some of your packages here. Also, feel free to sign up for packages that are valuable to your effort. If you need any help figuring out what is going on, please feel free to ping me and I will be happy to get you started. :smile:"
smaranjitghose/awesome-portfolio-websites,818217851,620,,"[{'action': 'opened', 'author': 'vybhav72954', 'comment_id': None, 'datetime': '2021-02-28 14:21:39+00:00', 'masked_author': 'username_0', 'text': 'As this website is powered by JS, HTML and CSS, how about a linter for the same?', 'title': 'How about a JS/HTML/CSS Linter?', 'type': 'issue'}
 {'action': 'closed', 'author': 'vybhav72954', 'comment_id': None, 'datetime': '2021-02-28 14:59:16+00:00', 'masked_author': 'username_0', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'reopened', 'author': 'vybhav72954', 'comment_id': None, 'datetime': '2021-02-28 15:28:19+00:00', 'masked_author': 'username_0', 'text': 'As this website is powered by JS, HTML and CSS, how about a linter for the same?', 'title': 'How about a JS/HTML/CSS Linter?', 'type': 'issue'}
 {'action': 'created', 'author': 'anushbhatia', 'comment_id': 787495439.0, 'datetime': '2021-02-28 18:13:35+00:00', 'masked_author': 'username_1', 'text': ""Sure mention the linter's used for each of them. I would prefer Prettier instead of all these."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'vybhav72954', 'comment_id': 788317147.0, 'datetime': '2021-03-01 21:41:36+00:00', 'masked_author': 'username_0', 'text': 'My suggestions:\r\n\r\n[HTML](https://github.com/htmlhint/HTMLHint)\r\n[CSS](https://stylelint.io/)\r\n[JS](https://eslint.org/)\r\n\r\nI can make actions for these in case you find them interesting.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'anushbhatia', 'comment_id': 788707025.0, 'datetime': '2021-03-02 08:08:29+00:00', 'masked_author': 'username_1', 'text': 'okay great go ahead with them', 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'anushbhatia', 'comment_id': None, 'datetime': '2021-03-03 16:40:14+00:00', 'masked_author': 'username_1', 'text': '', 'title': None, 'type': 'issue'}]","<issue_start><issue_comment>Title: How about a JS/HTML/CSS Linter?
username_0: As this website is powered by JS, HTML and CSS, how about a linter for the same?<issue_closed>
<issue_comment>username_0: As this website is powered by JS, HTML and CSS, how about a linter for the same?
<issue_comment>username_1: Sure mention the linter's used for each of them. I would prefer Prettier instead of all these.
<issue_comment>username_0: My suggestions:

[HTML](https://github.com/htmlhint/HTMLHint)
[CSS](https://stylelint.io/)
[JS](https://eslint.org/)

I can make actions for these in case you find them interesting.
<issue_comment>username_1: okay great go ahead with them<issue_closed>"
