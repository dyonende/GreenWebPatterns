dlang/dlang.org,476598704,2687,"{'number': 2687.0, 'repo': 'dlang.org', 'user_login': 'dlang'}","[{'action': 'opened', 'author': 'Vild', 'comment_id': None, 'datetime': '2019-08-04T22:03:37Z', 'masked_author': 'username_0', 'text': 'Old PR: https://github.com/dlang/dlang.org/pull/2539\r\nOld reverted in: https://github.com/dlang/dlang.org/pull/2541\r\n\r\nI\'ve recreated this PR after this topic have been brought up again in our Discord server.\r\nWe still think that it would be a good idea to have a more official and visible Discord server for those that prefer Discord over IRC. As brought up in the other PR we are willing to make changes to the server, if requested. Difference from the last PR is that it now says ""Community Discord"" instead of just ""Discord"".\r\n\r\n**This should not be merged without further discussion and approval of multiple people.**\r\n\r\n---\r\nText from the old PR:\r\n\r\nAdds the Discord chat link for ""D Language Code Club"" (previously known as ""D Code Club"" and ""Wilds Code Club"") to the Community section. (in the following referred to as ""Server"") Discord is a lot like Slack.\r\n\r\nThe server currently has 500 members, where we usually have around 100 online users. (comparable to IRC) It is the official chat of dplug, code-d and PowerNex. We have topic channels around general Programming, web development and OS development, a user-submitted D resources collection, a user-submitted D projects collection and a News channel about D news from the Announce forum and announcing new dub projects. There are also some off-topic channels. We are currently also working on a imaging library inside a channel on the server there too, which is supposed to eventually also become a GUI library. With that workgroup we are trying to improve certain areas in D.\r\n\r\nWe help a lot of users with their programming questions on the server. Currently the server is administered by @username_3, @M4GNV5 and me. @0xEAB, @rikkimax and @username_1 are additional moderators.\r\n\r\nI think adding the Discord server to the list is a valuable addition because so far it seems that a lot of ""younger"" people visit our Discord instead of the IRC, which is considered a bit dated.', 'title': 'Add community Discord join link to the community section', 'type': 'issue'}
 {'action': 'created', 'author': 'p0nce', 'comment_id': 518227831.0, 'datetime': '2019-08-05 13:10:42+00:00', 'masked_author': 'username_1', 'text': 'Hi, please condider listing Discord prominently, as it is preferred by many from the youth. It has for example, become the primary forum for Rust development, and I know of many teams for which it replaces Slack (being searchable withunlimited history and simpler).', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'CyberShadow', 'comment_id': 520814402.0, 'datetime': '2019-08-13 12:30:09+00:00', 'masked_author': 'username_2', 'text': 'The URL https://discord.gg/bMZk9Q4 redirects me to https://discordapp.com/invite/bMZk9Q4 which has a button to ""Accept Invite"", but when I click it I get an error page:\r\n\r\n![](https://dump.thecybershadow.net/05e94251a1529604de1bd67bf07c25fe/12%3A29%3A20-upload.png)\r\n\r\nThe help link goes to https://support.discordapp.com/hc/en-us/articles/360001556852.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Vild', 'comment_id': 520837357.0, 'datetime': '2019-08-13 13:36:11+00:00', 'masked_author': 'username_0', 'text': 'The invite link works for me, maybe the discord had some temporary problems.\r\nCould you try again?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'CyberShadow', 'comment_id': 520837810.0, 'datetime': '2019-08-13 13:37:23+00:00', 'masked_author': 'username_2', 'text': 'It works fine for me too. Perhaps I needed to log in first.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'p0nce', 'comment_id': 520848614.0, 'datetime': '2019-08-13 14:04:15+00:00', 'masked_author': 'username_1', 'text': ""FWIW, I find the tone of the server very respectful/positive (compared to the NG), since there is banning of abusive users, and 5 active moderators. It used to be more specific to the server's founders but have been under several relift to host more of the D community at large."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'WebFreak001', 'comment_id': 522227464.0, 'datetime': '2019-08-17 11:00:52+00:00', 'masked_author': 'username_3', 'text': 'time for merge yet?', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Add community Discord join link to the community section
username_0: Old PR: https://github.com/dlang/dlang.org/pull/2539
Old reverted in: https://github.com/dlang/dlang.org/pull/2541

I've recreated this PR after this topic have been brought up again in our Discord server.
We still think that it would be a good idea to have a more official and visible Discord server for those that prefer Discord over IRC. As brought up in the other PR we are willing to make changes to the server, if requested. Difference from the last PR is that it now says ""Community Discord"" instead of just ""Discord"".

**This should not be merged without further discussion and approval of multiple people.**

---
Text from the old PR:

Adds the Discord chat link for ""D Language Code Club"" (previously known as ""D Code Club"" and ""Wilds Code Club"") to the Community section. (in the following referred to as ""Server"") Discord is a lot like Slack.

The server currently has 500 members, where we usually have around 100 online users. (comparable to IRC) It is the official chat of dplug, code-d and PowerNex. We have topic channels around general Programming, web development and OS development, a user-submitted D resources collection, a user-submitted D projects collection and a News channel about D news from the Announce forum and announcing new dub projects. There are also some off-topic channels. We are currently also working on a imaging library inside a channel on the server there too, which is supposed to eventually also become a GUI library. With that workgroup we are trying to improve certain areas in D.

We help a lot of users with their programming questions on the server. Currently the server is administered by @username_3, @M4GNV5 and me. @0xEAB, @rikkimax and @username_1 are additional moderators.

I think adding the Discord server to the list is a valuable addition because so far it seems that a lot of ""younger"" people visit our Discord instead of the IRC, which is considered a bit dated.
<issue_comment>username_1: Hi, please condider listing Discord prominently, as it is preferred by many from the youth. It has for example, become the primary forum for Rust development, and I know of many teams for which it replaces Slack (being searchable withunlimited history and simpler).
<issue_comment>username_2: The URL https://discord.gg/bMZk9Q4 redirects me to https://discordapp.com/invite/bMZk9Q4 which has a button to ""Accept Invite"", but when I click it I get an error page:

![](https://dump.thecybershadow.net/05e94251a1529604de1bd67bf07c25fe/12%3A29%3A20-upload.png)

The help link goes to https://support.discordapp.com/hc/en-us/articles/360001556852.
<issue_comment>username_0: The invite link works for me, maybe the discord had some temporary problems.
Could you try again?
<issue_comment>username_2: It works fine for me too. Perhaps I needed to log in first.
<issue_comment>username_1: FWIW, I find the tone of the server very respectful/positive (compared to the NG), since there is banning of abusive users, and 5 active moderators. It used to be more specific to the server's founders but have been under several relift to host more of the D community at large.
<issue_comment>username_3: time for merge yet?"
ethereum/ethereum-org-website,675914648,1305,,"[{'action': 'opened', 'author': 'sandrastauffer', 'comment_id': None, 'datetime': '2020-08-10 06:56:34+00:00', 'masked_author': 'username_0', 'text': 'It is the most difficult part to make a final decision as to what kind of watch suits you well. Even if you have been wearing watches for a very long time, you will always have a very hard time choosing the best one for you from the choices of millions. The most popular and common ones in modern days are undoubtedly quartz watches. Because these watches are easy to understand and not very expensive as compared to mechanical and automatic watches. Moreover, the market places whether online or physical has a plethora of quartz watches, for only one reason as they are battery operated and once if it ever stops working then you only need to replace the tiny battery then you are good to go. It doesn’t require more maintenance and displays accurate time. When you are getting this much ease then there is no question of it being preferred highly among the masses. Watch Wish also tries to manufacture watches that are the favorite of many, but at the same time, we also care for that small number who likes automatic and mechanical watches. We have got a large stock for our special customers who are interested in the watches other than quartz. Now, from these three kinds, you should know which one goes fine with you. If you are the kind of person who doesn’t want to waste time on petty matters and wants to remain focused on routine more, then quartz will fit just right for you, as it doesn’t ask for your attention now and then. But if you are a watch freak and are willing to give more attention to the watch you wear, then both mechanical and automatic will go well with you. Now, you have to decide in which category you fall.\xa0\r\n\r\nYou just cannot buy a new watch for every single occasion. So, you have to study the watch closely and see whether it is going to be okay with your dressing style for every event you usually attend. If you feel slightly negative inside you, then you should change your decision because your will is very important before buying any kind of product not just watches. Why you can’t buy so many of them together is just because every single watch costs you a lot if you are looking for a big brand, wearing watches that are of low quality will ruin you from head to toe. That is why Watch Wish wants you to\xa0[buy Rolex first copy online](https://watchwish.pk/shop/?filter_brand=audemars-piguet      )\xa0and get the perks of a real original\xa0Rolex by paying less than half the amount of original and getting the same looks and design. What more would you want? People just won’t be asking you to hand the watch over to them so they can check whether it is even the real one or not. They would just see you from a distance and will compliment you for sure. They will be wondering afterward that you got a style that you carry with you everywhere you go. What adds more to the beauty is the fact you will have made your trade-mark and if you continue with this style then it won’t take long when you will be recognized more with your style than your name.\xa0\r\n\r\nWatch Wish’s mission is to make the availability of all the copies of every single big brand possible in Pakistan. Local people here tend to spend less on watches but still want to wear them, there are just a few numbers of peeps who would love to spend more on their watches as they think wearing watches will make them look cool and it might be their long lost hobby as well that ultimately forces them to wear the best watch in town. Once we sell a particular watch, we try to keep the price as low as we can and also have the watch checked from all angles to prove that it is genuine and free of defects. It is finally sold when the customer is satisfied by doing multiple checks on their own, and we happily let them do it. There come certain seasons during the year, when we put our special items on sale, which lets you buy your favorite watches at very low cost. You could be surprised by the prices that we have to offer. We will always amaze you with the best offers we can give you. You will be pleased with our services. You can place your orders anytime online, and we will have your order delivered in a couple of days. After trying out our watches, you will also say that Watch Wish has the finest watches in town.', 'title': 'How to Select an Appropriate Watch', 'type': 'issue'}
 {'action': 'closed', 'author': 'samajammin', 'comment_id': None, 'datetime': '2020-08-12 01:17:51+00:00', 'masked_author': 'username_1', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'created', 'author': 'samajammin', 'comment_id': 672426161.0, 'datetime': '2020-08-12 01:17:51+00:00', 'masked_author': 'username_1', 'text': '?', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: How to Select an Appropriate Watch
username_0: It is the most difficult part to make a final decision as to what kind of watch suits you well. Even if you have been wearing watches for a very long time, you will always have a very hard time choosing the best one for you from the choices of millions. The most popular and common ones in modern days are undoubtedly quartz watches. Because these watches are easy to understand and not very expensive as compared to mechanical and automatic watches. Moreover, the market places whether online or physical has a plethora of quartz watches, for only one reason as they are battery operated and once if it ever stops working then you only need to replace the tiny battery then you are good to go. It doesn’t require more maintenance and displays accurate time. When you are getting this much ease then there is no question of it being preferred highly among the masses. Watch Wish also tries to manufacture watches that are the favorite of many, but at the same time, we also care for that small number who likes automatic and mechanical watches. We have got a large stock for our special customers who are interested in the watches other than quartz. Now, from these three kinds, you should know which one goes fine with you. If you are the kind of person who doesn’t want to waste time on petty matters and wants to remain focused on routine more, then quartz will fit just right for you, as it doesn’t ask for your attention now and then. But if you are a watch freak and are willing to give more attention to the watch you wear, then both mechanical and automatic will go well with you. Now, you have to decide in which category you fall. 

You just cannot buy a new watch for every single occasion. So, you have to study the watch closely and see whether it is going to be okay with your dressing style for every event you usually attend. If you feel slightly negative inside you, then you should change your decision because your will is very important before buying any kind of product not just watches. Why you can’t buy so many of them together is just because every single watch costs you a lot if you are looking for a big brand, wearing watches that are of low quality will ruin you from head to toe. That is why Watch Wish wants you to [buy Rolex first copy online](https://watchwish.pk/shop/?filter_brand=audemars-piguet      ) and get the perks of a real original Rolex by paying less than half the amount of original and getting the same looks and design. What more would you want? People just won’t be asking you to hand the watch over to them so they can check whether it is even the real one or not. They would just see you from a distance and will compliment you for sure. They will be wondering afterward that you got a style that you carry with you everywhere you go. What adds more to the beauty is the fact you will have made your trade-mark and if you continue with this style then it won’t take long when you will be recognized more with your style than your name. 

Watch Wish’s mission is to make the availability of all the copies of every single big brand possible in Pakistan. Local people here tend to spend less on watches but still want to wear them, there are just a few numbers of peeps who would love to spend more on their watches as they think wearing watches will make them look cool and it might be their long lost hobby as well that ultimately forces them to wear the best watch in town. Once we sell a particular watch, we try to keep the price as low as we can and also have the watch checked from all angles to prove that it is genuine and free of defects. It is finally sold when the customer is satisfied by doing multiple checks on their own, and we happily let them do it. There come certain seasons during the year, when we put our special items on sale, which lets you buy your favorite watches at very low cost. You could be surprised by the prices that we have to offer. We will always amaze you with the best offers we can give you. You will be pleased with our services. You can place your orders anytime online, and we will have your order delivered in a couple of days. After trying out our watches, you will also say that Watch Wish has the finest watches in town.<issue_closed>
<issue_comment>username_1: ?"
RSS-Bridge/rss-bridge,615251755,1562,,"[{'action': 'opened', 'author': 'VerifiedJoseph', 'comment_id': None, 'datetime': '2020-05-09 20:13:57+00:00', 'masked_author': 'username_0', 'text': ""Twitter is discontinuing the 'legacy' website, which currently powers this bridge, on June 1, 2020.\r\n\r\n![Capture2](https://user-images.githubusercontent.com/20118140/81483983-8de6fe00-9231-11ea-933f-ace126822f05.PNG)"", 'title': '[Twitter] Legacy website design being discontinued on June 1, 2020 ', 'type': 'issue'}
 {'action': 'created', 'author': 'em92', 'comment_id': 626264470.0, 'datetime': '2020-05-10 02:48:17+00:00', 'masked_author': 'username_1', 'text': 'Ping @pmaziere.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'triatic', 'comment_id': 637101743.0, 'datetime': '2020-06-01 21:06:05+00:00', 'masked_author': 'username_2', 'text': 'June 1 is here, about half of my twitter feeds are now returning no data.\r\n\r\n![image](https://user-images.githubusercontent.com/42704418/83454337-edf94a80-a453-11ea-9988-6e4e0e914a6b.png)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'triatic', 'comment_id': 637584387.0, 'datetime': '2020-06-02 14:36:38+00:00', 'masked_author': 'username_2', 'text': 'All Twitter feeds showing zero results now. I guess the 50/50 results I saw earlier was due to some servers not having shut down legacy support.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Nono-m0le', 'comment_id': 638455316.0, 'datetime': '2020-06-03 20:52:50+00:00', 'masked_author': 'username_3', 'text': '@username_7 do you know who was responsible for this bridge? If not, any idea who can propose a PR for that?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'triatic', 'comment_id': 638458684.0, 'datetime': '2020-06-03 21:00:04+00:00', 'masked_author': 'username_2', 'text': 'The maintainer is @pmaziere , but anyone is welcome to propose a PR!', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'drego85', 'comment_id': 638654104.0, 'datetime': '2020-06-04 07:18:08+00:00', 'masked_author': 'username_4', 'text': ""I don't know how you can fix this :("", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Pofilo', 'comment_id': 638671306.0, 'datetime': '2020-06-04 07:47:38+00:00', 'masked_author': 'username_5', 'text': 'Hey @username_4, this URL seems to work with the mobile version:\r\n\r\nhttps://mobile.twitter.com/search?q=AndreaDraghetti&src=typed_query&f=live\r\n(just changed the end of the URL)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'drego85', 'comment_id': 638675799.0, 'datetime': '2020-06-04 07:55:09+00:00', 'masked_author': 'username_4', 'text': 'It absolutely works, but the results are not recent. The last result shown is from May 30th (in the desktop version it is today)..', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Pofilo', 'comment_id': 638683479.0, 'datetime': '2020-06-04 08:07:59+00:00', 'masked_author': 'username_5', 'text': 'Well, with this mobile URL (https://mobile.twitter.com/search?q=AndreaDraghetti&src=typed_query&f=live), I have the same results than on the other version:\r\n![twitter-mobile](https://user-images.githubusercontent.com/7527594/83731655-3038ac80-a64b-11ea-8cd0-a7511e0f8b8e.PNG)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'drego85', 'comment_id': 638686657.0, 'datetime': '2020-06-04 08:13:40+00:00', 'masked_author': 'username_4', 'text': ""You haven't disabled JavaScript :) \r\n\r\nThis is the graphical interface with JavaScript disabled:\r\n![Schermata 2020-06-04 alle 10 12 49](https://user-images.githubusercontent.com/2007233/83732206-003dd900-a64c-11ea-9b42-965f0f4b55d1.png)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Pofilo', 'comment_id': 638692469.0, 'datetime': '2020-06-04 08:23:44+00:00', 'masked_author': 'username_5', 'text': 'Okay my bad ..', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'drego85', 'comment_id': 638694100.0, 'datetime': '2020-06-04 08:26:15+00:00', 'masked_author': 'username_4', 'text': 'No problem, better to make multiple checks ;)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'triatic', 'comment_id': 638830863.0, 'datetime': '2020-06-04 12:58:31+00:00', 'masked_author': 'username_2', 'text': '@username_4 We can simulate the actions of Javascript, we just have to work out what the Javascript is doing and write it in PHP.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'somini', 'comment_id': 639203467.0, 'datetime': '2020-06-05 01:24:20+00:00', 'masked_author': 'username_6', 'text': ""This is a bummer.\r\n\r\nThere's always Nitter for a quick hack, until this is solved: https://github.com/zedeus/nitter"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'teromene', 'comment_id': 639333390.0, 'datetime': '2020-06-05 08:21:18+00:00', 'masked_author': 'username_7', 'text': 'I have pushed an update to TwitterBridge.\r\nIt required a major rewrite, and probably still has problems that needs to be quelled.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Nono-m0le', 'comment_id': 639342739.0, 'datetime': '2020-06-05 08:40:14+00:00', 'masked_author': 'username_3', 'text': ""Thanks @username_7 but, I can't seems to make it works ..."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'drego85', 'comment_id': 639347430.0, 'datetime': '2020-06-05 08:47:43+00:00', 'masked_author': 'username_4', 'text': 'Thanks @username_7 great workaround, I didn\'t know that ""tokens"" would be released to guest users.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'teromene', 'comment_id': 639348261.0, 'datetime': '2020-06-05 08:49:26+00:00', 'masked_author': 'username_7', 'text': 'Can you share your input parameters as well as eventually your log @username_3 ?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'triatic', 'comment_id': 639383292.0, 'datetime': '2020-06-05 10:05:01+00:00', 'masked_author': 'username_2', 'text': 'Excellent work @username_7 , I can confirm successful operation in cli mode.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kinoushe', 'comment_id': 639393175.0, 'datetime': '2020-06-05 10:25:44+00:00', 'masked_author': 'username_8', 'text': ""Glad it's working again! Thanks @username_7\r\n\r\nOne problem is that `display_url` doesn't appear to be the correct usage for the img `src` - it results in broken images.\r\n\r\nThe `media_url_https` works correctly for the enclosures, and I think this should be used for `$display_image` also.\r\n\r\nFor the enclosures could we instead retain the 'orig' tag as before to retrieve the original sized images here?\r\n\r\nThe following works correctly for me:\r\n\r\n`$image = $media->media_url_https . '?name=orig';`\r\n`$display_image = $media->media_url_https;`"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'doowruc', 'comment_id': 639447730.0, 'datetime': '2020-06-05 12:21:03+00:00', 'masked_author': 'username_9', 'text': 'It\'s not working in my heroku instance. \r\n\r\nI did my usual process of pull from here, push to heroku, and heroku triggered a deploy.\r\n\r\nI get an error: Bridge returned error 429! (18418)\r\n\r\nwith detail in HTML mode:\r\n\r\nTwitter @github was unable to receive or process the remote website\'s content!\r\nError message: `The requested resource cannot be found!\r\nPlease make sure your input parameters are correct!\r\ncUrl error: (0)\r\nPHP error: `\r\nQuery string: `action=display&bridge=Twitter&context=By+username&u=github&noimgscaling=on&format=Html`\r\nVersion: `dev.2020-02-26`\r\n\r\nor in plaintext mode:\r\n\r\n<p class=""exception-message""><strong>Twitter @github</strong> was unable to receive or process the\r\nremote website\'s content!<br>\r\nError message: `The requested resource cannot be found!<br />\r\nPlease make sure your input parameters are correct!<br />\r\ncUrl error:  (0)<br />\r\nPHP error: `<br />\r\nQuery string: `action=display&bridge=Twitter&context=By+username&u=github&format=Mrss`<br />\r\nVersion: `dev.2020-02-26`</p>\r\n\r\nAll modes in all formats give the same error', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'doowruc', 'comment_id': 639450459.0, 'datetime': '2020-06-05 12:25:03+00:00', 'masked_author': 'username_9', 'text': 'I just deployed to a new heroku app using the button on the repo front page and the new instance also has the same error', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'teromene', 'comment_id': 639458908.0, 'datetime': '2020-06-05 12:45:58+00:00', 'masked_author': 'username_7', 'text': '429 response is when twitter considers that you have made too many requests\r\nI will look into it', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'drego85', 'comment_id': 639460317.0, 'datetime': '2020-06-05 12:49:23+00:00', 'masked_author': 'username_4', 'text': '@username_9  I think to avoid this limitation, you can customize the code by adding two valid API tokens generated by the Twitter development site.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'doowruc', 'comment_id': 639460890.0, 'datetime': '2020-06-05 12:50:55+00:00', 'masked_author': 'username_9', 'text': '@username_4 add them where?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'drego85', 'comment_id': 639462600.0, 'datetime': '2020-06-05 12:54:45+00:00', 'masked_author': 'username_4', 'text': ""[Line 346 and 347](https://github.com/RSS-Bridge/rss-bridge/blob/master/bridges/TwitterBridge.php#L346) and you can find more info of bearer tokens [here](https://developer.twitter.com/en/docs/basics/authentication/oauth-2-0/bearer-tokens).\r\n\r\nHowever I haven't personally tried."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Pofilo', 'comment_id': 639489755.0, 'datetime': '2020-06-05 13:46:26+00:00', 'masked_author': 'username_5', 'text': 'The last commit fixes the Bridge, thanks ! :)\r\nBut I have some remarks:\r\n\r\n- https://github.com/RSS-Bridge/rss-bridge/commit/06891ae35f0947d8f2a8daa0094b25e2db862226#diff-f82ed36085a4ed36bb827ac4e6db7b25R234: the id of the user is now its id as a number : `54932564` against `Canardpcredac` -> an entry with the old version will have a different `id` than with this entry\r\n- https://github.com/RSS-Bridge/rss-bridge/commit/06891ae35f0947d8f2a8daa0094b25e2db862226#diff-f82ed36085a4ed36bb827ac4e6db7b25R230: the `author` field is inversed: `Canardpcredac (@Canard PC)` against `Canard PC (@Canardpcredac)` \r\n\r\nI may have the time this weekend for a MR, not sure.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'triatic', 'comment_id': 639714970.0, 'datetime': '2020-06-05 18:55:09+00:00', 'masked_author': 'username_2', 'text': 'It worked for a while and now I see `failed to open stream: HTTP request failed! HTTP/1.0 403 Forbidden`\r\n\r\nHow long are the `authorization` and `x-guest-token` headers cached for? Do they need to be periodically refreshed?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'danielsale', 'comment_id': 639733928.0, 'datetime': '2020-06-05 19:17:43+00:00', 'masked_author': 'username_10', 'text': ""Mine updated once, this morning. I am following lists and now get:\r\n\r\nBridge returned error 403! (18418)\r\nTwitter list by danielleesale&lt;/strong&gt; was unable to receive or process the\r\nremote website's content!&lt;br&gt;\r\nError message: `The requested resource cannot be found!&lt;br /&gt;\r\nPlease make sure your input parameters are correct!"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'triatic', 'comment_id': 639739780.0, 'datetime': '2020-06-05 19:22:41+00:00', 'masked_author': 'username_2', 'text': ""@username_10 try deleting the TwitterBridge folder in the cache directory. Worked for me, but you'll need to keep doing it until the cache expiry time for the headers is reduced."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'markwaters', 'comment_id': 639979807.0, 'datetime': '2020-06-06 04:31:45+00:00', 'masked_author': 'username_11', 'text': 'Thank you @username_7 for fixing this , I was surprised and disappointed by how much of my news comes in via Twitter these days.\r\nThanks @username_2 for the cache clearing suggestion , I was using MemCacheD and getting the 4XX errors , switched back to the FileCache for now and seeing tweets again.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'doowruc', 'comment_id': 640103416.0, 'datetime': '2020-06-06 18:54:46+00:00', 'masked_author': 'username_9', 'text': 'ok, thats odd... 2 of my many bridge feeds in feedly just refreshed and pulled in more tweets. But if I try and add a new feed in my bridge UI, I;m still getting the 429 error', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'akkiverma', 'comment_id': 640105086.0, 'datetime': '2020-06-06 19:08:51+00:00', 'masked_author': 'username_12', 'text': ""Getting error in twitter feed:\r\n\r\nTwitter search test was unable to receive or process the remote website's content!\r\n\\nError message: `The requested resource cannot be found!\r\n\\nPlease make sure your input parameters are correct!\r\n\\ncUrl error: (0)\r\n\\nPHP error: `"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'akkiverma', 'comment_id': 640106663.0, 'datetime': '2020-06-06 19:22:34+00:00', 'masked_author': 'username_12', 'text': 'aah I emptied the `cache` folder and it started working.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Tintwo', 'comment_id': 640169473.0, 'datetime': '2020-06-07 07:16:55+00:00', 'masked_author': 'username_13', 'text': ""Yes, it works for a time. I don't know yet what is the condition to have this problem, bug actually it cost me to flush cache files twice a day."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'akkiverma', 'comment_id': 640181476.0, 'datetime': '2020-06-07 09:08:02+00:00', 'masked_author': 'username_12', 'text': 'Yes the error is returning back again and again. It works once when I clear the cache but never updates. I have enabled debug too yet it makes the cache.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'nousernameavailableanymore', 'comment_id': 640219887.0, 'datetime': '2020-06-07 13:32:31+00:00', 'masked_author': 'username_14', 'text': 'Is there any way to automate this (clearing the cache) with the docker installation?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'triatic', 'comment_id': 640224819.0, 'datetime': '2020-06-07 14:10:54+00:00', 'masked_author': 'username_2', 'text': ""I don't know about docker, but a cron can be set to delete cache/TwitterBridge/* once an hour."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'nousernameavailableanymore', 'comment_id': 640227851.0, 'datetime': '2020-06-07 14:32:45+00:00', 'masked_author': 'username_14', 'text': 'Yes, that was my thought as well. But there is no cron in the docker container.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'akkiverma', 'comment_id': 640232363.0, 'datetime': '2020-06-07 15:03:36+00:00', 'masked_author': 'username_12', 'text': 'Why the need to create a cron to clear cache? I have enabled debug yet the cache gets formed. I think that need to be fixed.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'triatic', 'comment_id': 640233068.0, 'datetime': '2020-06-07 15:08:33+00:00', 'masked_author': 'username_2', 'text': ""It's a temporary fix until someone corrects the cache code in the bridge."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'nousernameavailableanymore', 'comment_id': 640268435.0, 'datetime': '2020-06-07 19:34:12+00:00', 'masked_author': 'username_14', 'text': 'The twitter rss-bridge suddenly started working again for me. Except for the still broken images. Is this a known issue as well?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kinoushe', 'comment_id': 640293949.0, 'datetime': '2020-06-07 23:11:48+00:00', 'masked_author': 'username_8', 'text': 'Yes, the broken images is a known issue @username_14, see https://github.com/RSS-Bridge/rss-bridge/issues/1562#issuecomment-639393175 for the fix.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'nousernameavailableanymore', 'comment_id': 640298560.0, 'datetime': '2020-06-07 23:52:09+00:00', 'masked_author': 'username_14', 'text': 'I have no clue what that means?\r\nAssume that someone had no clue whatsoever about webdevelopment.\r\nHow would this person fix the issue?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kinoushe', 'comment_id': 640299255.0, 'datetime': '2020-06-07 23:58:53+00:00', 'masked_author': 'username_8', 'text': '@username_14 just wait for the bridge to be updated with the fix then.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'somini', 'comment_id': 640309828.0, 'datetime': '2020-06-08 01:04:03+00:00', 'masked_author': 'username_6', 'text': '@username_7 Many thanks for updating the bridge, I appreciated it very much.\r\n\r\nI opened #1591 to include the fix @username_8 mentioned above. Another regression is that `t.co` links are no longer resolved, and if they refer to another tweet, that tweet would be shown in the item contents.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kinoushe', 'comment_id': 640320688.0, 'datetime': '2020-06-08 01:58:26+00:00', 'masked_author': 'username_8', 'text': ""Since we're now using the Twitter API it's possible to include videos:\r\n` $media->video_info->variants[0]->url`\r\n\r\nWe would need to loop through the `variants[]` to find the highest bitrate:\r\nhttps://developer.twitter.com/en/docs/tweets/data-dictionary/overview/extended-entities-object#tweet-video\r\n\r\nAnd then render video HTML instead of the image HTML, with the `url` as `src` and `media_url_https` as the video poster."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'nousernameavailableanymore', 'comment_id': 640330905.0, 'datetime': '2020-06-08 02:45:51+00:00', 'masked_author': 'username_14', 'text': 'Will there be a new docker image with these changes?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'teromene', 'comment_id': 640484152.0, 'datetime': '2020-06-08 09:23:56+00:00', 'masked_author': 'username_7', 'text': 'I have pushed a new update.\r\nThis should fix images, profile names as well as introduce a new caching strategy for guest tokens.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kinoushe', 'comment_id': 640497975.0, 'datetime': '2020-06-08 09:49:32+00:00', 'masked_author': 'username_8', 'text': ""@username_7 are we able to keep the `?name=orig` size on the enclosure images as before?\r\n\r\n`$image = $media->media_url_https . '?name=orig';`\r\n\r\n`media_url_https` and `media_url` bring in a downsized image from my testing."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'danielsale', 'comment_id': 640723596.0, 'datetime': '2020-06-08 16:06:42+00:00', 'masked_author': 'username_10', 'text': 'Getting a 403 on lists again.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'somini', 'comment_id': 640973268.0, 'datetime': '2020-06-09 01:26:02+00:00', 'masked_author': 'username_6', 'text': 'Note the `video_info` object might not exist.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kinoushe', 'comment_id': 640978795.0, 'datetime': '2020-06-09 01:46:32+00:00', 'masked_author': 'username_8', 'text': '@username_6 oops, I missed that disclaimer. But I think conditionally displaying most/non advertiser videos would be better than nothing at all as current.\r\n\r\nFrom my limited testing the past few days `video_info` works well.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'somini', 'comment_id': 640979382.0, 'datetime': '2020-06-09 01:48:50+00:00', 'masked_author': 'username_6', 'text': 'I\'ll include a first pass on this on #1595 . It also supports ""animated GIF"", exposed as videos.\r\n\r\nThanks for digging into the API.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'kinoushe', 'comment_id': 640980192.0, 'datetime': '2020-06-09 01:52:01+00:00', 'masked_author': 'username_8', 'text': 'Excellent, thanks @username_6!', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'triatic', 'comment_id': 641391449.0, 'datetime': '2020-06-09 15:46:09+00:00', 'masked_author': 'username_2', 'text': '@username_7 the caching strategy is better now but I think we need to expire tokens based on time as well as usage.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'nousernameavailableanymore', 'comment_id': 641429382.0, 'datetime': '2020-06-09 16:44:29+00:00', 'masked_author': 'username_14', 'text': 'I updated to the latest docker image yesterday. For some reason the version it still shows RSS-Bridge as version ""dev.2020-02-26"".\r\nUnfortuantely I still get 403s for the most part. Sometimes it seems to work sporadically but I still got the broken images.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'teromene', 'comment_id': 641491319.0, 'datetime': '2020-06-09 18:24:04+00:00', 'masked_author': 'username_7', 'text': '@username_2 It should expire at the same time as the default cache expiration time', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'triatic', 'comment_id': 641509229.0, 'datetime': '2020-06-09 19:00:15+00:00', 'masked_author': 'username_2', 'text': ""@username_7 are you saying the token should last no longer than CACHE_TIMEOUT in the bridge (normally 5 minutes) when it is used under 100 times? Because I'm not seeing that behaviour here."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'ShaneZampire', 'comment_id': 660707361.0, 'datetime': '2020-07-19 20:52:08+00:00', 'masked_author': 'username_15', 'text': 'I use to have #Breaking tweets displayed on my web page till the new Twitter came out and it stopped working. I just replaced the old Twitter Bridge with the new one and now I get the image below. Do I need to replace other files or is this still being worked on?  Thanks\r\n![Twitterbridge](https://user-images.githubusercontent.com/45672375/87884970-28a54b00-c9e0-11ea-82f4-bbdc82ed47fc.png)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'em92', 'comment_id': 663398281.0, 'datetime': '2020-07-24 08:02:06+00:00', 'masked_author': 'username_1', 'text': '@username_15 pull latest version of TwitterBridge. It is probably fixed already', 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'em92', 'comment_id': None, 'datetime': '2020-07-24 08:02:06+00:00', 'masked_author': 'username_1', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'created', 'author': 'ShaneZampire', 'comment_id': 666097644.0, 'datetime': '2020-07-30 04:29:39+00:00', 'masked_author': 'username_15', 'text': ""I just tried the latest as of 4 days ago. I guess Twitter's new version has broke it for good for us :(   I am thankful for all the hard work that went into this project. Before Twitter broke it, it worked awesome and I am super grateful for the months I did get to use it.\r\n![Twitterbridge](https://user-images.githubusercontent.com/45672375/88880597-2cfd0f80-d1fb-11ea-8105-4d33ec6e827b.png)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'em92', 'comment_id': 666112996.0, 'datetime': '2020-07-30 05:00:20+00:00', 'masked_author': 'username_1', 'text': '@username_15, the screenshot you gave does not tell anything to me. You need to provide full text of error.\r\nAlso are you using Memcached?', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: [Twitter] Legacy website design being discontinued on June 1, 2020 
username_0: Twitter is discontinuing the 'legacy' website, which currently powers this bridge, on June 1, 2020.

![Capture2](https://user-images.githubusercontent.com/20118140/81483983-8de6fe00-9231-11ea-933f-ace126822f05.PNG)
<issue_comment>username_1: Ping @pmaziere.
<issue_comment>username_2: June 1 is here, about half of my twitter feeds are now returning no data.

![image](https://user-images.githubusercontent.com/42704418/83454337-edf94a80-a453-11ea-9988-6e4e0e914a6b.png)
<issue_comment>username_2: All Twitter feeds showing zero results now. I guess the 50/50 results I saw earlier was due to some servers not having shut down legacy support.
<issue_comment>username_3: @username_7 do you know who was responsible for this bridge? If not, any idea who can propose a PR for that?
<issue_comment>username_2: The maintainer is @pmaziere , but anyone is welcome to propose a PR!
<issue_comment>username_4: I don't know how you can fix this :(
<issue_comment>username_5: Hey @username_4, this URL seems to work with the mobile version:

https://mobile.twitter.com/search?q=AndreaDraghetti&src=typed_query&f=live
(just changed the end of the URL)
<issue_comment>username_4: It absolutely works, but the results are not recent. The last result shown is from May 30th (in the desktop version it is today)..
<issue_comment>username_5: Well, with this mobile URL (https://mobile.twitter.com/search?q=AndreaDraghetti&src=typed_query&f=live), I have the same results than on the other version:
![twitter-mobile](https://user-images.githubusercontent.com/7527594/83731655-3038ac80-a64b-11ea-8cd0-a7511e0f8b8e.PNG)
<issue_comment>username_4: You haven't disabled JavaScript :) 

This is the graphical interface with JavaScript disabled:
![Schermata 2020-06-04 alle 10 12 49](https://user-images.githubusercontent.com/2007233/83732206-003dd900-a64c-11ea-9b42-965f0f4b55d1.png)
<issue_comment>username_5: Okay my bad ..
<issue_comment>username_4: No problem, better to make multiple checks ;)
<issue_comment>username_2: @username_4 We can simulate the actions of Javascript, we just have to work out what the Javascript is doing and write it in PHP.
<issue_comment>username_6: This is a bummer.

There's always Nitter for a quick hack, until this is solved: https://github.com/zedeus/nitter
<issue_comment>username_7: I have pushed an update to TwitterBridge.
It required a major rewrite, and probably still has problems that needs to be quelled.
<issue_comment>username_3: Thanks @username_7 but, I can't seems to make it works ...
<issue_comment>username_4: Thanks @username_7 great workaround, I didn't know that ""tokens"" would be released to guest users.
<issue_comment>username_7: Can you share your input parameters as well as eventually your log @username_3 ?
<issue_comment>username_2: Excellent work @username_7 , I can confirm successful operation in cli mode.
<issue_comment>username_8: Glad it's working again! Thanks @username_7

One problem is that `display_url` doesn't appear to be the correct usage for the img `src` - it results in broken images.

The `media_url_https` works correctly for the enclosures, and I think this should be used for `$display_image` also.

For the enclosures could we instead retain the 'orig' tag as before to retrieve the original sized images here?

The following works correctly for me:

`$image = $media->media_url_https . '?name=orig';`
`$display_image = $media->media_url_https;`
<issue_comment>username_9: It's not working in my heroku instance. 

I did my usual process of pull from here, push to heroku, and heroku triggered a deploy.

I get an error: Bridge returned error 429! (18418)

with detail in HTML mode:

Twitter @github was unable to receive or process the remote website's content!
Error message: `The requested resource cannot be found!
Please make sure your input parameters are correct!
cUrl error: (0)
PHP error: `
Query string: `action=display&bridge=Twitter&context=By+username&u=github&noimgscaling=on&format=Html`
Version: `dev.2020-02-26`

or in plaintext mode:

<p class=""exception-message""><strong>Twitter @github</strong> was unable to receive or process the
remote website's content!<br>
Error message: `The requested resource cannot be found!<br />
Please make sure your input parameters are correct!<br />
cUrl error:  (0)<br />
PHP error: `<br />
Query string: `action=display&bridge=Twitter&context=By+username&u=github&format=Mrss`<br />
Version: `dev.2020-02-26`</p>

All modes in all formats give the same error
<issue_comment>username_9: I just deployed to a new heroku app using the button on the repo front page and the new instance also has the same error
<issue_comment>username_7: 429 response is when twitter considers that you have made too many requests
I will look into it
<issue_comment>username_4: @username_9  I think to avoid this limitation, you can customize the code by adding two valid API tokens generated by the Twitter development site.
<issue_comment>username_9: @username_4 add them where?
<issue_comment>username_4: [Line 346 and 347](https://github.com/RSS-Bridge/rss-bridge/blob/master/bridges/TwitterBridge.php#L346) and you can find more info of bearer tokens [here](https://developer.twitter.com/en/docs/basics/authentication/oauth-2-0/bearer-tokens).

However I haven't personally tried.
<issue_comment>username_5: The last commit fixes the Bridge, thanks ! :)
But I have some remarks:

- https://github.com/RSS-Bridge/rss-bridge/commit/06891ae35f0947d8f2a8daa0094b25e2db862226#diff-f82ed36085a4ed36bb827ac4e6db7b25R234: the id of the user is now its id as a number : `54932564` against `Canardpcredac` -> an entry with the old version will have a different `id` than with this entry
- https://github.com/RSS-Bridge/rss-bridge/commit/06891ae35f0947d8f2a8daa0094b25e2db862226#diff-f82ed36085a4ed36bb827ac4e6db7b25R230: the `author` field is inversed: `Canardpcredac (@Canard PC)` against `Canard PC (@Canardpcredac)` 

I may have the time this weekend for a MR, not sure.
<issue_comment>username_2: It worked for a while and now I see `failed to open stream: HTTP request failed! HTTP/1.0 403 Forbidden`

How long are the `authorization` and `x-guest-token` headers cached for? Do they need to be periodically refreshed?
<issue_comment>username_10: Mine updated once, this morning. I am following lists and now get:

Bridge returned error 403! (18418)
Twitter list by danielleesale&lt;/strong&gt; was unable to receive or process the
remote website's content!&lt;br&gt;
Error message: `The requested resource cannot be found!&lt;br /&gt;
Please make sure your input parameters are correct!
<issue_comment>username_2: @username_10 try deleting the TwitterBridge folder in the cache directory. Worked for me, but you'll need to keep doing it until the cache expiry time for the headers is reduced.
<issue_comment>username_11: Thank you @username_7 for fixing this , I was surprised and disappointed by how much of my news comes in via Twitter these days.
Thanks @username_2 for the cache clearing suggestion , I was using MemCacheD and getting the 4XX errors , switched back to the FileCache for now and seeing tweets again.
<issue_comment>username_9: ok, thats odd... 2 of my many bridge feeds in feedly just refreshed and pulled in more tweets. But if I try and add a new feed in my bridge UI, I;m still getting the 429 error
<issue_comment>username_12: Getting error in twitter feed:

Twitter search test was unable to receive or process the remote website's content!
\nError message: `The requested resource cannot be found!
\nPlease make sure your input parameters are correct!
\ncUrl error: (0)
\nPHP error: `
<issue_comment>username_12: aah I emptied the `cache` folder and it started working.
<issue_comment>username_13: Yes, it works for a time. I don't know yet what is the condition to have this problem, bug actually it cost me to flush cache files twice a day.
<issue_comment>username_12: Yes the error is returning back again and again. It works once when I clear the cache but never updates. I have enabled debug too yet it makes the cache.
<issue_comment>username_14: Is there any way to automate this (clearing the cache) with the docker installation?
<issue_comment>username_2: I don't know about docker, but a cron can be set to delete cache/TwitterBridge/* once an hour.
<issue_comment>username_14: Yes, that was my thought as well. But there is no cron in the docker container.
<issue_comment>username_12: Why the need to create a cron to clear cache? I have enabled debug yet the cache gets formed. I think that need to be fixed.
<issue_comment>username_2: It's a temporary fix until someone corrects the cache code in the bridge.
<issue_comment>username_14: The twitter rss-bridge suddenly started working again for me. Except for the still broken images. Is this a known issue as well?
<issue_comment>username_8: Yes, the broken images is a known issue @username_14, see https://github.com/RSS-Bridge/rss-bridge/issues/1562#issuecomment-639393175 for the fix.
<issue_comment>username_14: I have no clue what that means?
Assume that someone had no clue whatsoever about webdevelopment.
How would this person fix the issue?
<issue_comment>username_8: @username_14 just wait for the bridge to be updated with the fix then.
<issue_comment>username_6: @username_7 Many thanks for updating the bridge, I appreciated it very much.

I opened #1591 to include the fix @username_8 mentioned above. Another regression is that `t.co` links are no longer resolved, and if they refer to another tweet, that tweet would be shown in the item contents.
<issue_comment>username_8: Since we're now using the Twitter API it's possible to include videos:
` $media->video_info->variants[0]->url`

We would need to loop through the `variants[]` to find the highest bitrate:
https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/extended-entities-object#tweet-video

And then render video HTML instead of the image HTML, with the `url` as `src` and `media_url_https` as the video poster.
<issue_comment>username_14: Will there be a new docker image with these changes?
<issue_comment>username_7: I have pushed a new update.
This should fix images, profile names as well as introduce a new caching strategy for guest tokens.
<issue_comment>username_8: @username_7 are we able to keep the `?name=orig` size on the enclosure images as before?

`$image = $media->media_url_https . '?name=orig';`

`media_url_https` and `media_url` bring in a downsized image from my testing.
<issue_comment>username_10: Getting a 403 on lists again.
<issue_comment>username_6: Note the `video_info` object might not exist.
<issue_comment>username_8: @username_6 oops, I missed that disclaimer. But I think conditionally displaying most/non advertiser videos would be better than nothing at all as current.

From my limited testing the past few days `video_info` works well.
<issue_comment>username_6: I'll include a first pass on this on #1595 . It also supports ""animated GIF"", exposed as videos.

Thanks for digging into the API.
<issue_comment>username_8: Excellent, thanks @username_6!
<issue_comment>username_2: @username_7 the caching strategy is better now but I think we need to expire tokens based on time as well as usage.
<issue_comment>username_14: I updated to the latest docker image yesterday. For some reason the version it still shows RSS-Bridge as version ""dev.2020-02-26"".
Unfortuantely I still get 403s for the most part. Sometimes it seems to work sporadically but I still got the broken images.
<issue_comment>username_7: @username_2 It should expire at the same time as the default cache expiration time
<issue_comment>username_2: @username_7 are you saying the token should last no longer than CACHE_TIMEOUT in the bridge (normally 5 minutes) when it is used under 100 times? Because I'm not seeing that behaviour here.
<issue_comment>username_15: I use to have #Breaking tweets displayed on my web page till the new Twitter came out and it stopped working. I just replaced the old Twitter Bridge with the new one and now I get the image below. Do I need to replace other files or is this still being worked on?  Thanks
![Twitterbridge](https://user-images.githubusercontent.com/45672375/87884970-28a54b00-c9e0-11ea-82f4-bbdc82ed47fc.png)
<issue_comment>username_1: @username_15 pull latest version of TwitterBridge. It is probably fixed already<issue_closed>
<issue_comment>username_15: I just tried the latest as of 4 days ago. I guess Twitter's new version has broke it for good for us :(   I am thankful for all the hard work that went into this project. Before Twitter broke it, it worked awesome and I am super grateful for the months I did get to use it.
![Twitterbridge](https://user-images.githubusercontent.com/45672375/88880597-2cfd0f80-d1fb-11ea-8105-4d33ec6e827b.png)
<issue_comment>username_1: @username_15, the screenshot you gave does not tell anything to me. You need to provide full text of error.
Also are you using Memcached?"
jaspervdj/hakyll,663916578,786,,"[{'action': 'opened', 'author': 'gwern', 'comment_id': None, 'datetime': '2020-07-22 17:07:30+00:00', 'masked_author': 'username_0', 'text': ""I would link `symlinkCompiler` which does symbolic links (or hard links) as a dropin replacement for a standard static file copying routine like `let static = route idRoute >> compile copyFileCompiler`, which would be a performance optimization for compiling many large static files.\r\n\r\nAs username_0.net gets larger, particularly with audio/images/videos generated for my deep learning experiments, compiling it spends increasingly more time and disk space creating `_site/`. Even with a NVMe SSD, the time starts to add up; more problematically, I'm starting to run out of disk space for creating 30GB `_site/` folders just to upload a few modified files & then delete it. Almost all of that disk space & IO is going to copying things like PDFs or MP4s from one folder to another. There's no particular reason those copies couldn't just be symbolic or hard links back to the original file and then I can use rsync with `--copy-links` to have rsync follow the links when it syncs with my username_0.net server.\r\n\r\nLooking at the `File.hs` module which defines `copyFileCompiler`, it seems to be mostly wrappers around a single call to `System.Directory`'s `copyFileWithMetadata`. Is there any reason a symbolic link version couldn't be defined by swapping out that for `createFileLink` like below:\r\n\r\n```.diff\r\ndiff --git a/lib/Hakyll/Core/File.hs b/lib/Hakyll/Core/File.hs\r\nindex 49af659..6a5775e 100644\r\n--- a/lib/Hakyll/Core/File.hs\r\n+++ b/lib/Hakyll/Core/File.hs\r\n@@ -8,6 +8,8 @@ module Hakyll.Core.File\r\n     , copyFileCompiler\r\n     , TmpFile (..)\r\n     , newTmpFile\r\n+    , SymlinkFile (..)\r\n+    , symlinkFileCompiler\r\n     ) where\r\n \r\n \r\n@@ -20,6 +22,7 @@ import           System.Directory              (copyFileWithMetadata)\r\n import           System.Directory              (copyFile)\r\n #endif\r\n import           System.Directory              (doesFileExist,\r\n+                                                createFileLink,\r\n                                                 renameFile)\r\n import           System.FilePath               ((</>))\r\n import           System.Random                 (randomIO)\r\n@@ -56,6 +59,19 @@ copyFileCompiler = do\r\n     provider   <- compilerProvider <$> compilerAsk\r\n     makeItem $ CopyFile $ resourceFilePath provider identifier\r\n \r\n+--------------------------------------------------------------------------------\r\n+-- | This will not copy a file but create a symlink, which can save space & time for static sites with many large static files which would normally be handled by copyFileCompiler. (Note: the user will need to make sure their sync method handles symbolic links correctly!)\r\n+newtype SymlinkFile = SymlinkFile FilePath\r\n+    deriving (Binary, Eq, Ord, Show, Typeable)\r\n+--------------------------------------------------------------------------------\r\n+instance Writable SymlinkFile where\r\n+    write dst (Item _ (SymlinkFile src)) = createFileLink src dst\r\n+--------------------------------------------------------------------------------\r\n+symlinkFileCompiler :: Compiler (Item SymlinkFile)\r\n+symlinkFileCompiler = do\r\n+    identifier <- getUnderlying\r\n+    provider   <- compilerProvider <$> compilerAsk\r\n+    makeItem $ SymlinkFile $ resourceFilePath provider identifier\r\n```"", 'title': 'Feature request: symlink/symbolic link for faster/smaller compiled site versions', 'type': 'issue'}
 {'action': 'created', 'author': 'gwern', 'comment_id': 719981056.0, 'datetime': '2020-10-31 20:01:39+00:00', 'masked_author': 'username_0', 'text': ""Any feedback on this? I'd particularly like this upstreamed because my attempts to define it inside my own hakyll.hs have foundered on type issues with the deriving Binary & Item; they work inside `File.hs` but not elsewhere, requiring me to keep a forked Hakyll installed. (At this point, I'm low enough on disk space that I wouldn't be able to compile username_0.net without this optimization.)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Minoru', 'comment_id': 725701054.0, 'datetime': '2020-11-11 22:40:08+00:00', 'masked_author': 'username_1', 'text': ""Please submit this as PR, I'll merge it."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'gwern', 'comment_id': 725733675.0, 'datetime': '2020-11-12 00:06:16+00:00', 'masked_author': 'username_0', 'text': '[0002-File.hs-symlink-based-static-file-compiler-for-multi.patch.txt](https://github.com/jaspervdj/hakyll/files/5527460/0002-File.hs-symlink-based-static-file-compiler-for-multi.patch.txt)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Minoru', 'comment_id': 726100945.0, 'datetime': '2020-11-12 14:09:56+00:00', 'masked_author': 'username_1', 'text': 'Thanks @username_0!', 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'Minoru', 'comment_id': None, 'datetime': '2020-11-12 14:23:29+00:00', 'masked_author': 'username_1', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'created', 'author': 'gwern', 'comment_id': 794745136.0, 'datetime': '2021-03-10 02:13:11+00:00', 'masked_author': 'username_0', 'text': ""So I happened to undo my local patch while doing a reinstall of my Pandoc toolchain to pull in a fix related to `<figure>` handling, and I think there was a misunderstanding here: my patch above is *not* correct. It results in symbolic self-links which are totally broken, eg\r\n\r\n~~~\r\n...\r\nls: cannot access '_site/Zeo.page': Too many levels of symbolic links\r\n$ ls -l _site/*.page\r\nlrwxrwxrwx 1 username_0 username_0 32 Mar  9 21:01 _site/2012-election-predictions.page -> ./2012-election-predictions.page\r\n...\r\n~~~\r\n\r\nThat is what I was referring to in my discussion of hacking `src` to make it point to a correct filepath like '_site/2012-election-predictions.page -> /home/username_0/wiki/2012-election-predictions.page`. It needs some relatively small but unknown to me tweak to make it correct and point to `../`.\r\n\r\nI thought when you committed you'd fixed that, but trying just now it seems that is not the case?"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Minoru', 'comment_id': 795650991.0, 'datetime': '2021-03-10 15:59:18+00:00', 'masked_author': 'username_1', 'text': 'From my reading of the code, that\'s *exactly* how it works. The problem is that relative symlinks are resolved relatively to the directory in which they reside, so ""./docs/foo.pdf"", when resolved from inside ""_site/docs/"", points to ""_site/docs/docs/foo.pdf"".\r\n\r\nOne way to fix it would be to use [`System.Directory.makeAbsolute`](https://hackage.haskell.org/package/directory-1.3.6.1/docs/System-Directory.html#v:makeAbsolute) in `symlinkFileCompiler`. But I don\'t like this, because then the _site directory can\'t be moved to another place without breaking the links.\r\n\r\nThe other option is to make `src` relative to `dst`, but I don\'t see a function in System.Directory that does this. The only candidate, [`System.FilePath.makeRelative`](https://hackage.haskell.org/package/filepath-1.4.1.2/docs/System-FilePath-Posix.html#v:makeRelative), explains that it doesn\'t introduce `..` into the paths, because one of the parent directories might be itself a symlink, and going up from it might lead us to a different place altogether.\r\n\r\nWe can write our own ""relativization"" function: 1) take `destinationDirectory`, replace all components with `..`; 2) take the item route, drop the filename, replace directory components with `..`; 3) concatenate (1), (2), and the route. This still suffers from the same problem that\'s outlined in the doc for `makeRelative`, but I think it\'s on the user if they copy something into a directory which is itself a symlink. (But I think this situation is impossible, because Hakyll executes rules in arbitrary order, and if the directory doesn\'t exist, it\'ll be created.)\r\n\r\nAlternatively, use hard links. But that\'ll require separate code for *nix and Windows, I believe.\r\n\r\nI don\'t have the energy to work on this myself. If you want to push this to completion, I\'m open to further discussions, you can bounce ideas off me if you want. Otherwise I can just revert the current version, re-open this issue, and wait until someone gets motivated to finish this off.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Minoru', 'comment_id': 798903617.0, 'datetime': '2021-03-14 13:05:47+00:00', 'masked_author': 'username_1', 'text': ""Okay, the patch is now reverted. Sorry for the mess I've caused here >_<\r\n\r\nLet's wait until someone has energy to brush this up and submit a new one."", 'title': None, 'type': 'comment'}
 {'action': 'reopened', 'author': 'Minoru', 'comment_id': None, 'datetime': '2021-03-14 13:05:48+00:00', 'masked_author': 'username_1', 'text': 'I would link `symlinkCompiler` which does symbolic links (or hard links) as a dropin replacement for a standard static file copying routine like [my](https://www.username_0.net/hakyll.hs) `let static = route idRoute >> compile copyFileCompiler`, which would be a performance optimization for compiling many large static files.\r\n\r\nAs username_0.net gets larger, particularly with audio/images/videos generated for my deep learning experiments, compiling it spends increasingly more time and disk space creating `_site/`. Even with a NVMe SSD, the time starts to add up; more problematically, I\'m starting to run out of disk space for creating 40GB `_site/` folders just to upload a few modified files & then delete it. Almost all of that disk space & IO is going to copying things like PDFs or MP4s from one folder to another. There\'s no particular reason those copies couldn\'t just be symbolic or hard links back to the original file and then I can use rsync with `--copy-links` to have rsync follow the links when it syncs with my username_0.net server.\r\n\r\nLooking at the `File.hs` module which defines `copyFileCompiler`, it seems to be mostly wrappers around a single call to `System.Directory`\'s `copyFileWithMetadata`. Is there any reason a symbolic link version couldn\'t be defined by swapping out that for `createFileLink` like below:\r\n\r\n```.diff\r\ndiff --git a/lib/Hakyll/Core/File.hs b/lib/Hakyll/Core/File.hs\r\nindex 49af659..6a5775e 100644\r\n--- a/lib/Hakyll/Core/File.hs\r\n+++ b/lib/Hakyll/Core/File.hs\r\n@@ -8,6 +8,8 @@ module Hakyll.Core.File\r\n     , copyFileCompiler\r\n     , TmpFile (..)\r\n     , newTmpFile\r\n+    , SymlinkFile (..)\r\n+    , symlinkFileCompiler\r\n     ) where\r\n \r\n \r\n@@ -20,6 +22,7 @@ import           System.Directory              (copyFileWithMetadata)\r\n import           System.Directory              (copyFile)\r\n #endif\r\n import           System.Directory              (doesFileExist,\r\n+                                                createFileLink,\r\n                                                 renameFile)\r\n import           System.FilePath               ((</>))\r\n import           System.Random                 (randomIO)\r\n@@ -56,6 +59,19 @@ copyFileCompiler = do\r\n     provider   <- compilerProvider <$> compilerAsk\r\n     makeItem $ CopyFile $ resourceFilePath provider identifier\r\n \r\n+--------------------------------------------------------------------------------\r\n+-- | This will not copy a file but create a symlink, which can save space & time for static sites with many large static files which would normally be handled by copyFileCompiler. (Note: the user will need to make sure their sync method handles symbolic links correctly!)\r\n+newtype SymlinkFile = SymlinkFile FilePath\r\n+    deriving (Binary, Eq, Ord, Show, Typeable)\r\n+--------------------------------------------------------------------------------\r\n+instance Writable SymlinkFile where\r\n+    write dst (Item _ (SymlinkFile src)) = createFileLink src dst\r\n+--------------------------------------------------------------------------------\r\n+symlinkFileCompiler :: Compiler (Item SymlinkFile)\r\n+symlinkFileCompiler = do\r\n+    identifier <- getUnderlying\r\n+    provider   <- compilerProvider <$> compilerAsk\r\n+    makeItem $ SymlinkFile $ resourceFilePath provider identifier\r\n```\r\n\r\nThe one part that puzzles me is that `createFileLink src dst` creates self-links. I can try something like prepending the absolute path like `(""/home/username_0/wiki/""++src)` but I don\'t understand where the correct relative/absolute path prefix comes from since I thought `src dst` would look like `docs/foo.pdf _site/docs/foo.pdf` but that\'s obviously not how it works...\r\n\r\n(While a hack, prepending does work: I go from a `_site/` of 41GB to <0.2GB. A good 10 minutes faster too.)', 'title': 'Feature request: symlink/symbolic link for faster/smaller compiled site versions', 'type': 'issue'}
 {'action': 'created', 'author': 'gwern', 'comment_id': 803115099.0, 'datetime': '2021-03-19 20:44:33+00:00', 'masked_author': 'username_0', 'text': 'If it\'s unclear which function to use, perhaps we can push it onto the user. Right now my hack is to add in a `/home/username_0/wiki/` prefix to make the symlink paths absolute (and then it rsyncs fine to the actual server). Perhaps the function can be parameterized to take such a prefix? Defaulting to the current working directory. So then I\'d write `compile (symlinkFileCompiler Nothing)` or to be explicit, `compile (symlinkFileCompiler $ Just ""/home/username_0/wiki/"")`.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Minoru', 'comment_id': 808894264.0, 'datetime': '2021-03-28 13:03:12+00:00', 'masked_author': 'username_1', 'text': ""Sorry for such a delay replying, I got buried under some life stuff.\r\n\r\nUpon re-reading the thread, I think the easiest way forward is to use hard links, and implement them just for the OS that you, @username_0, are using. If somebody needs it on a different OS, they can submit a patch later. If somebody absolutely needs *symbolic* links (e.g. because their destination directory is on a different disk), they can re-visit this issue and see what they can come up with. What do you think of that?\r\n\r\nIn case you're against that, I'll also comment on parameterising `symlinkFileCompiler`: I think it's better to have a separate function for this, like `symlinkFileCompilerWithBasePath` or something. Once the path-relativization kinks are worked out, we can provide a shorter `symlinkFileCompiler` that doesn't need a path."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'gwern', 'comment_id': 808899550.0, 'datetime': '2021-03-28 13:47:45+00:00', 'masked_author': 'username_0', 'text': ""I have not tried using hardlinks before, but I'm willing to give it a try."", 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Feature request: symlink/symbolic link for faster/smaller compiled site versions
username_0: I would link `symlinkCompiler` which does symbolic links (or hard links) as a dropin replacement for a standard static file copying routine like `let static = route idRoute >> compile copyFileCompiler`, which would be a performance optimization for compiling many large static files.

As username_0.net gets larger, particularly with audio/images/videos generated for my deep learning experiments, compiling it spends increasingly more time and disk space creating `_site/`. Even with a NVMe SSD, the time starts to add up; more problematically, I'm starting to run out of disk space for creating 30GB `_site/` folders just to upload a few modified files & then delete it. Almost all of that disk space & IO is going to copying things like PDFs or MP4s from one folder to another. There's no particular reason those copies couldn't just be symbolic or hard links back to the original file and then I can use rsync with `--copy-links` to have rsync follow the links when it syncs with my username_0.net server.

Looking at the `File.hs` module which defines `copyFileCompiler`, it seems to be mostly wrappers around a single call to `System.Directory`'s `copyFileWithMetadata`. Is there any reason a symbolic link version couldn't be defined by swapping out that for `createFileLink` like below:

```.diff
diff --git a/lib/Hakyll/Core/File.hs b/lib/Hakyll/Core/File.hs
index 49af659..6a5775e 100644
--- a/lib/Hakyll/Core/File.hs
+++ b/lib/Hakyll/Core/File.hs
@@ -8,6 +8,8 @@ module Hakyll.Core.File
     , copyFileCompiler
     , TmpFile (..)
     , newTmpFile
+    , SymlinkFile (..)
+    , symlinkFileCompiler
     ) where
 
 
@@ -20,6 +22,7 @@ import           System.Directory              (copyFileWithMetadata)
 import           System.Directory              (copyFile)
 #endif
 import           System.Directory              (doesFileExist,
+                                                createFileLink,
                                                 renameFile)
 import           System.FilePath               ((</>))
 import           System.Random                 (randomIO)
@@ -56,6 +59,19 @@ copyFileCompiler = do
     provider   <- compilerProvider <$> compilerAsk
     makeItem $ CopyFile $ resourceFilePath provider identifier
 
+--------------------------------------------------------------------------------
+-- | This will not copy a file but create a symlink, which can save space & time for static sites with many large static files which would normally be handled by copyFileCompiler. (Note: the user will need to make sure their sync method handles symbolic links correctly!)
+newtype SymlinkFile = SymlinkFile FilePath
+    deriving (Binary, Eq, Ord, Show, Typeable)
+--------------------------------------------------------------------------------
+instance Writable SymlinkFile where
+    write dst (Item _ (SymlinkFile src)) = createFileLink src dst
+--------------------------------------------------------------------------------
+symlinkFileCompiler :: Compiler (Item SymlinkFile)
+symlinkFileCompiler = do
+    identifier <- getUnderlying
+    provider   <- compilerProvider <$> compilerAsk
+    makeItem $ SymlinkFile $ resourceFilePath provider identifier
```
<issue_comment>username_0: Any feedback on this? I'd particularly like this upstreamed because my attempts to define it inside my own hakyll.hs have foundered on type issues with the deriving Binary & Item; they work inside `File.hs` but not elsewhere, requiring me to keep a forked Hakyll installed. (At this point, I'm low enough on disk space that I wouldn't be able to compile username_0.net without this optimization.)
<issue_comment>username_1: Please submit this as PR, I'll merge it.
<issue_comment>username_0: [0002-File.hs-symlink-based-static-file-compiler-for-multi.patch.txt](https://github.com/jaspervdj/hakyll/files/5527460/0002-File.hs-symlink-based-static-file-compiler-for-multi.patch.txt)
<issue_comment>username_1: Thanks @username_0!<issue_closed>
<issue_comment>username_0: So I happened to undo my local patch while doing a reinstall of my Pandoc toolchain to pull in a fix related to `<figure>` handling, and I think there was a misunderstanding here: my patch above is *not* correct. It results in symbolic self-links which are totally broken, eg

~~~
...
ls: cannot access '_site/Zeo.page': Too many levels of symbolic links
$ ls -l _site/*.page
lrwxrwxrwx 1 username_0 username_0 32 Mar  9 21:01 _site/2012-election-predictions.page -> ./2012-election-predictions.page
...
~~~

That is what I was referring to in my discussion of hacking `src` to make it point to a correct filepath like '_site/2012-election-predictions.page -> /home/username_0/wiki/2012-election-predictions.page`. It needs some relatively small but unknown to me tweak to make it correct and point to `../`.

I thought when you committed you'd fixed that, but trying just now it seems that is not the case?
<issue_comment>username_1: From my reading of the code, that's *exactly* how it works. The problem is that relative symlinks are resolved relatively to the directory in which they reside, so ""./docs/foo.pdf"", when resolved from inside ""_site/docs/"", points to ""_site/docs/docs/foo.pdf"".

One way to fix it would be to use [`System.Directory.makeAbsolute`](https://hackage.haskell.org/package/directory-1.3.6.1/docs/System-Directory.html#v:makeAbsolute) in `symlinkFileCompiler`. But I don't like this, because then the _site directory can't be moved to another place without breaking the links.

The other option is to make `src` relative to `dst`, but I don't see a function in System.Directory that does this. The only candidate, [`System.FilePath.makeRelative`](https://hackage.haskell.org/package/filepath-1.4.1.2/docs/System-FilePath-Posix.html#v:makeRelative), explains that it doesn't introduce `..` into the paths, because one of the parent directories might be itself a symlink, and going up from it might lead us to a different place altogether.

We can write our own ""relativization"" function: 1) take `destinationDirectory`, replace all components with `..`; 2) take the item route, drop the filename, replace directory components with `..`; 3) concatenate (1), (2), and the route. This still suffers from the same problem that's outlined in the doc for `makeRelative`, but I think it's on the user if they copy something into a directory which is itself a symlink. (But I think this situation is impossible, because Hakyll executes rules in arbitrary order, and if the directory doesn't exist, it'll be created.)

Alternatively, use hard links. But that'll require separate code for *nix and Windows, I believe.

I don't have the energy to work on this myself. If you want to push this to completion, I'm open to further discussions, you can bounce ideas off me if you want. Otherwise I can just revert the current version, re-open this issue, and wait until someone gets motivated to finish this off.
<issue_comment>username_1: Okay, the patch is now reverted. Sorry for the mess I've caused here >_<

Let's wait until someone has energy to brush this up and submit a new one.
<issue_comment>username_1: I would link `symlinkCompiler` which does symbolic links (or hard links) as a dropin replacement for a standard static file copying routine like [my](https://www.username_0.net/hakyll.hs) `let static = route idRoute >> compile copyFileCompiler`, which would be a performance optimization for compiling many large static files.

As username_0.net gets larger, particularly with audio/images/videos generated for my deep learning experiments, compiling it spends increasingly more time and disk space creating `_site/`. Even with a NVMe SSD, the time starts to add up; more problematically, I'm starting to run out of disk space for creating 40GB `_site/` folders just to upload a few modified files & then delete it. Almost all of that disk space & IO is going to copying things like PDFs or MP4s from one folder to another. There's no particular reason those copies couldn't just be symbolic or hard links back to the original file and then I can use rsync with `--copy-links` to have rsync follow the links when it syncs with my username_0.net server.

Looking at the `File.hs` module which defines `copyFileCompiler`, it seems to be mostly wrappers around a single call to `System.Directory`'s `copyFileWithMetadata`. Is there any reason a symbolic link version couldn't be defined by swapping out that for `createFileLink` like below:

```.diff
diff --git a/lib/Hakyll/Core/File.hs b/lib/Hakyll/Core/File.hs
index 49af659..6a5775e 100644
--- a/lib/Hakyll/Core/File.hs
+++ b/lib/Hakyll/Core/File.hs
@@ -8,6 +8,8 @@ module Hakyll.Core.File
     , copyFileCompiler
     , TmpFile (..)
     , newTmpFile
+    , SymlinkFile (..)
+    , symlinkFileCompiler
     ) where
 
 
@@ -20,6 +22,7 @@ import           System.Directory              (copyFileWithMetadata)
 import           System.Directory              (copyFile)
 #endif
 import           System.Directory              (doesFileExist,
+                                                createFileLink,
                                                 renameFile)
 import           System.FilePath               ((</>))
 import           System.Random                 (randomIO)
@@ -56,6 +59,19 @@ copyFileCompiler = do
     provider   <- compilerProvider <$> compilerAsk
     makeItem $ CopyFile $ resourceFilePath provider identifier
 
+--------------------------------------------------------------------------------
+-- | This will not copy a file but create a symlink, which can save space & time for static sites with many large static files which would normally be handled by copyFileCompiler. (Note: the user will need to make sure their sync method handles symbolic links correctly!)
+newtype SymlinkFile = SymlinkFile FilePath
+    deriving (Binary, Eq, Ord, Show, Typeable)
+--------------------------------------------------------------------------------
+instance Writable SymlinkFile where
+    write dst (Item _ (SymlinkFile src)) = createFileLink src dst
+--------------------------------------------------------------------------------
+symlinkFileCompiler :: Compiler (Item SymlinkFile)
+symlinkFileCompiler = do
+    identifier <- getUnderlying
+    provider   <- compilerProvider <$> compilerAsk
+    makeItem $ SymlinkFile $ resourceFilePath provider identifier
```

The one part that puzzles me is that `createFileLink src dst` creates self-links. I can try something like prepending the absolute path like `(""/home/username_0/wiki/""++src)` but I don't understand where the correct relative/absolute path prefix comes from since I thought `src dst` would look like `docs/foo.pdf _site/docs/foo.pdf` but that's obviously not how it works...

(While a hack, prepending does work: I go from a `_site/` of 41GB to <0.2GB. A good 10 minutes faster too.)
<issue_comment>username_0: If it's unclear which function to use, perhaps we can push it onto the user. Right now my hack is to add in a `/home/username_0/wiki/` prefix to make the symlink paths absolute (and then it rsyncs fine to the actual server). Perhaps the function can be parameterized to take such a prefix? Defaulting to the current working directory. So then I'd write `compile (symlinkFileCompiler Nothing)` or to be explicit, `compile (symlinkFileCompiler $ Just ""/home/username_0/wiki/"")`.
<issue_comment>username_1: Sorry for such a delay replying, I got buried under some life stuff.

Upon re-reading the thread, I think the easiest way forward is to use hard links, and implement them just for the OS that you, @username_0, are using. If somebody needs it on a different OS, they can submit a patch later. If somebody absolutely needs *symbolic* links (e.g. because their destination directory is on a different disk), they can re-visit this issue and see what they can come up with. What do you think of that?

In case you're against that, I'll also comment on parameterising `symlinkFileCompiler`: I think it's better to have a separate function for this, like `symlinkFileCompilerWithBasePath` or something. Once the path-relativization kinks are worked out, we can provide a shorter `symlinkFileCompiler` that doesn't need a path.
<issue_comment>username_0: I have not tried using hardlinks before, but I'm willing to give it a try."
kubernetes/website,292608208,7133,"{'number': 7133.0, 'repo': 'website', 'user_login': 'kubernetes'}","[{'action': 'opened', 'author': 'heckj', 'comment_id': None, 'datetime': '2018-01-30T00:12:30Z', 'masked_author': 'username_0', 'text': 'PR for feedback purposes - putting a WIP/hold on the PR just in case.\r\n\r\nCobbled per what I’ve dug up of the teams and my current impressions of expectations, with several things being unsaid explicitly, but likely worthy of a chat at least amongst the current approver set:\r\n\r\n1) set of the folks listed as “maintainers” is much larger than the set of folks actually reviewing PRs from what I’ve seen over the past few months. That’s cool/normal, but we ought to consider why they have write bit access if they’re not reviewing PRs or issues.\r\n\r\n2) assignment of a PR for review is a social construct, and generally if assigned - the rest of us “won’t touch it” unless it’s something that one of us considers a “trivial matter” - and we’ll approve/merge regardless of who’s assigned. Approvers discretion for the “yeah, I’m just merging this now” is trusted - and we don’t seem to have needed to back out anything as yet that was inappropriately merged.\r\n\r\n3) we’re not doing an incredibly good job of always reviewing “on time”, and probably ought to at least set some informal expectations - if you’re assigned a PR to review, when should you at least give feedback by? Goal being to encourage others to contribute and provide them with feedback in a “reasonably timely” fashion. To my mind, that means at least some response or acknowledgment within a week, maybe two - beyond that it getting a bit long in the tooth by my expectation, but we also haven’t said or set anything to this respect.\r\n\r\n4) I’m viewing PR reviews frankly as more important than issue review, maybe a third or quarter of which are actually support requests disguised (or not) as a reported docs issue. I think that’s the right focus for betterment of ourselves and the community, along with an implicit “We’d love to have your PR” response which we might consider putting into the issue submission form at some point.\r\n\r\nLast - all this is my opinion, and mine alone - please view this as a strawman on guy fauwkes day and have at. Everyone loves a good fire3, and this is great kindling. ;-)\n\n<!-- Reviewable:start -->\n---\nThis change is\u2002[<img src=""https://reviewable.kubernetes.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.kubernetes.io/reviews/kubernetes/website/7133)\n<!-- Reviewable:end -->', 'title': 'Roles sigdocs', 'type': 'issue'}
 {'action': 'created', 'author': 'heckj', 'comment_id': 361432643.0, 'datetime': '2018-01-30 00:18:09+00:00', 'masked_author': 'username_0', 'text': '/hold WIP', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'heckj', 'comment_id': 361432834.0, 'datetime': '2018-01-30 00:19:11+00:00', 'masked_author': 'username_0', 'text': '/assign username_1', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'heckj', 'comment_id': 361432923.0, 'datetime': '2018-01-30 00:19:39+00:00', 'masked_author': 'username_0', 'text': '/hold', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'heckj', 'comment_id': 361432994.0, 'datetime': '2018-01-30 00:20:07+00:00', 'masked_author': 'username_0', 'text': '/assign username_2', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bradamant3', 'comment_id': 361437734.0, 'datetime': '2018-01-30 00:45:41+00:00', 'masked_author': 'username_1', 'text': ""+100 to the points in the commit message, too. Will ponder further and add more comments here when I'm fresher."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'zacharysarah', 'comment_id': 361713726.0, 'datetime': '2018-01-30 19:52:17+00:00', 'masked_author': 'username_2', 'text': ""I think that's a fair assessment of our functional reality. I don't want to abandon issue review entirely, because some good information is surfaced in open issues, but yes--we get far more suggestions than we can ever act on. I'd rather devote our energy to ensuring that merged PRs have the highest possible quality, rather than making sure we understand every issue opened."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'heckj', 'comment_id': 362604819.0, 'datetime': '2018-02-02 14:43:04+00:00', 'masked_author': 'username_0', 'text': "":wave: @username_1 @username_2 @tengqm \r\n\r\nApologies for the delay in the edits, and thank you for the clarifications, links, and improvements in wording! I'll leave the `hold` on this PR through our meeting next week and for any further reviews."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Bradamant3', 'comment_id': 363544187.0, 'datetime': '2018-02-06 19:51:50+00:00', 'masked_author': 'username_1', 'text': 'It occurs to me that clarification about reviewer responsibility is also related to the reviewers list in the OWNERS file and the way the bot automatically assigns reviewers. Same goes for SLO/SLA and assignee responsibilities (discussed also in sig-docs meeting 2/6/18)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'steveperry-53', 'comment_id': 363564836.0, 'datetime': '2018-02-06 21:07:37+00:00', 'masked_author': 'username_3', 'text': 'I think we should say ""Kubernetes organization"" instead of ""Kubernetes project"".\r\n\r\n* https://help.github.com/articles/about-organizations/\r\n* https://github.com/blog/2272-introducing-projects-for-organizations\r\n* https://help.github.com/articles/creating-a-project-board/', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'steveperry-53', 'comment_id': 363565229.0, 'datetime': '2018-02-06 21:09:10+00:00', 'masked_author': 'username_3', 'text': 'I think using ""within"" instead of ""in"" goes against our style guideline about using simple and direct language.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'steveperry-53', 'comment_id': 363566142.0, 'datetime': '2018-02-06 21:12:40+00:00', 'masked_author': 'username_3', 'text': ""I think we need this distinction:\r\n\r\n* You can be a member of the Kubernetes organization.\r\n* You can be a reviewer in the kubernetes/website repository.\r\n* You can be an approver in the kubernetes/website repository.\r\n\r\nI haven't studied this in detail, but that's how it seems to me. An OWNERS file, which lists reviewers and approvers, is specific to a repository."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'steveperry-53', 'comment_id': 363567467.0, 'datetime': '2018-02-06 21:17:38+00:00', 'masked_author': 'username_3', 'text': ""In general, this document doesn't make the distinction between /lgtm and /approve clear.\r\n\r\n* /lgtm = tech approval\r\n* /approve = writing approval"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'steveperry-53', 'comment_id': 363570087.0, 'datetime': '2018-02-06 21:27:07+00:00', 'masked_author': 'username_3', 'text': ""Suggestion: Write this topic as if we're going to have the option to set `lgtmActsAsApprove` to `false`. That will keep the story clean for now. If we have to add the caveat about LGTM having two meanings, we can do that later."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'steveperry-53', 'comment_id': 363571891.0, 'datetime': '2018-02-06 21:33:31+00:00', 'masked_author': 'username_3', 'text': ""If you say pull request (PR), the usual convention is to say PR for all other instances in the document. In other words, once you have given the acronym, don't spell out the term any more."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'steveperry-53', 'comment_id': 363572275.0, 'datetime': '2018-02-06 21:34:46+00:00', 'masked_author': 'username_3', 'text': 'github -> GitHub\r\ngroup -> team\r\ntag -> label\r\nSIG-DOCS -> SIG Docs (not sure about this one)', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'steveperry-53', 'comment_id': 363584798.0, 'datetime': '2018-02-06 22:20:55+00:00', 'masked_author': 'username_3', 'text': ""In [test-infra Issue 6589](https://github.com/kubernetes/test-infra/issues/6589), there's a fair amount of resistance to our idea of using /lgtm for tech review and /approve for writer review. So we probably shouldn't put too much effort into clarifying these commands just yet."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'liggitt', 'comment_id': 363592968.0, 'datetime': '2018-02-06 22:52:54+00:00', 'masked_author': 'username_4', 'text': ""I'd expect that to harmonize with https://github.com/kubernetes/community/blob/master/community-membership.md#community-membership"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'zacharysarah', 'comment_id': 366075100.0, 'datetime': '2018-02-15 21:57:25+00:00', 'masked_author': 'username_2', 'text': ""@username_3 With https://github.com/kubernetes/test-infra/pull/6851 in play, I think it's good to clarify `/lgtm` and `/approve`. \r\n\r\n@username_0 It would be great to merge this soon. How can I help?"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'heckj', 'comment_id': 366084730.0, 'datetime': '2018-02-15 22:34:57+00:00', 'masked_author': 'username_0', 'text': ""I am on other editing/writing duties today, but I'm hoping to tackle a rewrite of this tomorrow (Friday Feb16). I've made sure that maintainers can all update this branch, so if I loose track and don't make progress, feel free to update the branch directly, or snag and edit and put up an alternate PR and close this one."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'heckj', 'comment_id': 366366179.0, 'datetime': '2018-02-16 21:41:07+00:00', 'masked_author': 'username_0', 'text': '@username_1 @username_3 @username_2 update the PR with feedback, and I believe it\'s fairly ready to merge barring additional comments.\r\n\r\n@username_4 made sure to explicitly talk to the membership requirements and linked to the relevant files in kubernetes/community\r\n\r\n@bradtopol I thought about adding something on the whole purple ""Reviewable"" button that lurks and eats unwitting reviewers, but I don\'t have a recommendation other that ""OMG FLEE"" that\'s more personal opinion based than consensus, so I\'m leaving that off this pass as a problem to tackle separately.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'heckj', 'comment_id': 366380559.0, 'datetime': '2018-02-16 22:48:45+00:00', 'masked_author': 'username_0', 'text': '@username_2 updated', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'steveperry-53', 'comment_id': 366396890.0, 'datetime': '2018-02-17 00:26:52+00:00', 'masked_author': 'username_3', 'text': 'I don\'t think this document is ready to be merged yet.\r\n\r\n* We need to agree on our convention for lgtm versus approve. After we have agreed on what our convention is, we need to make the convention clear in this document. My understanding is that we have a convention of lgtm=tech and approve=writing. (The more I think about it, I don\'t like that convention, because I think we will constantly have to explain it to people. I think we probably should have a couple new commands: lgtm-tech and lgtm-writing)\r\n\r\n* We need to make the distinction that a members belongs to the Kubernetes organization, but reviewers and approvers belong to a particular repository. \r\n\r\n* Early in the topic, we need to give these definition:\r\n\r\n    * A reviewer is someone who appears in the reviewers list in an OWNERS file or who appears in the reviewers list in the front matter of an individual topic.\r\n\r\n    * An approver is someone who appears in the approvers list in an OWNERS file or who appears in the approvers list in the front matter of an individual topic.\r\n\r\n* In the **Reviewers** section of the topic, there are too many statements about approvers. Those should be in the **Approvers** section.\r\n\r\n* I don\'t want to go forward with the content that explains how lgtm sometimes acts as approve. I want to wait until we have hammered that out with Aaron and the other SIGs.\r\n\r\n* We need to be more precise about what causes an automatic merge. I\'m not sure I know what the rules are, but this is what I think the rules are:\r\n\r\n    * The PR has an lgtm from someone in a reviewers list or someone in an approvers list.\r\n    * The PR has an approve from someone in an approvers list.\r\n    * The PR does not have a hold.\r\n\r\n* The topic refers to ""the OWNERS file"". We need to make it clear that there are several OWNERS files and there are also approvers and reviewers lists in the front matter of individual topics.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'heckj', 'comment_id': 366414148.0, 'datetime': '2018-02-17 03:54:45+00:00', 'masked_author': 'username_0', 'text': 'thanks @username_3  - I\'ve re-organized the content a bit to address your feedback and make it more explicit about roles vs. approvers roles and intentions of those comments.\r\n\r\nFor what it\'s worth, I understand your request, but think that the combination of lgtm and approve comments that we\'ve documented here is sufficient, and I\'m not sure it\'s worth the effort to establish any more formal controls, which would generally mean someone writing a Prow plugin that would do the stuff you\'re specifically asking towards. My assessment was that consensus overall was that the informal process is sufficient, so barring any terrible grammar regressions, I think this PR is ready to go as documenting the current state of how we do business.\r\n\r\n@username_2 I re-added the **Note:** about approver /lgtm, as the PR that Steve merged into the `infra-test` repo *did not* change that behavior (I validated that earlier this afternoon), so I thought it warranted calling out the special case. The PR that Steve merged does stop the ""automatically approved"" mechanism, but not the ""approver issuing /lgtm gets both tags"" thing.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'steveperry-53', 'comment_id': 366421257.0, 'datetime': '2018-02-17 06:33:28+00:00', 'masked_author': 'username_3', 'text': ""@username_0 OK, I'd say go ahead and remove the hold when you're ready."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'heckj', 'comment_id': 366425394.0, 'datetime': '2018-02-17 08:10:14+00:00', 'masked_author': 'username_0', 'text': '/hold cancel', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'zacharysarah', 'comment_id': 366833278.0, 'datetime': '2018-02-20 00:23:34+00:00', 'masked_author': 'username_2', 'text': '@username_0 Good choice—I just observed the same behavior. :+1:', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Roles sigdocs
username_0: PR for feedback purposes - putting a WIP/hold on the PR just in case.

Cobbled per what I’ve dug up of the teams and my current impressions of expectations, with several things being unsaid explicitly, but likely worthy of a chat at least amongst the current approver set:

1) set of the folks listed as “maintainers” is much larger than the set of folks actually reviewing PRs from what I’ve seen over the past few months. That’s cool/normal, but we ought to consider why they have write bit access if they’re not reviewing PRs or issues.

2) assignment of a PR for review is a social construct, and generally if assigned - the rest of us “won’t touch it” unless it’s something that one of us considers a “trivial matter” - and we’ll approve/merge regardless of who’s assigned. Approvers discretion for the “yeah, I’m just merging this now” is trusted - and we don’t seem to have needed to back out anything as yet that was inappropriately merged.

3) we’re not doing an incredibly good job of always reviewing “on time”, and probably ought to at least set some informal expectations - if you’re assigned a PR to review, when should you at least give feedback by? Goal being to encourage others to contribute and provide them with feedback in a “reasonably timely” fashion. To my mind, that means at least some response or acknowledgment within a week, maybe two - beyond that it getting a bit long in the tooth by my expectation, but we also haven’t said or set anything to this respect.

4) I’m viewing PR reviews frankly as more important than issue review, maybe a third or quarter of which are actually support requests disguised (or not) as a reported docs issue. I think that’s the right focus for betterment of ourselves and the community, along with an implicit “We’d love to have your PR” response which we might consider putting into the issue submission form at some point.

Last - all this is my opinion, and mine alone - please view this as a strawman on guy fauwkes day and have at. Everyone loves a good fire3, and this is great kindling. ;-)

<!-- Reviewable:start -->
---
This change is [<img src=""https://reviewable.kubernetes.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.kubernetes.io/reviews/kubernetes/website/7133)
<!-- Reviewable:end -->
<issue_comment>username_0: /hold WIP
<issue_comment>username_0: /assign username_1
<issue_comment>username_0: /hold
<issue_comment>username_0: /assign username_2
<issue_comment>username_1: +100 to the points in the commit message, too. Will ponder further and add more comments here when I'm fresher.
<issue_comment>username_2: I think that's a fair assessment of our functional reality. I don't want to abandon issue review entirely, because some good information is surfaced in open issues, but yes--we get far more suggestions than we can ever act on. I'd rather devote our energy to ensuring that merged PRs have the highest possible quality, rather than making sure we understand every issue opened.
<issue_comment>username_0: :wave: @username_1 @username_2 @tengqm 

Apologies for the delay in the edits, and thank you for the clarifications, links, and improvements in wording! I'll leave the `hold` on this PR through our meeting next week and for any further reviews.
<issue_comment>username_1: It occurs to me that clarification about reviewer responsibility is also related to the reviewers list in the OWNERS file and the way the bot automatically assigns reviewers. Same goes for SLO/SLA and assignee responsibilities (discussed also in sig-docs meeting 2/6/18)
<issue_comment>username_3: I think we should say ""Kubernetes organization"" instead of ""Kubernetes project"".

* https://help.github.com/articles/about-organizations/
* https://github.com/blog/2272-introducing-projects-for-organizations
* https://help.github.com/articles/creating-a-project-board/
<issue_comment>username_3: I think using ""within"" instead of ""in"" goes against our style guideline about using simple and direct language.
<issue_comment>username_3: I think we need this distinction:

* You can be a member of the Kubernetes organization.
* You can be a reviewer in the kubernetes/website repository.
* You can be an approver in the kubernetes/website repository.

I haven't studied this in detail, but that's how it seems to me. An OWNERS file, which lists reviewers and approvers, is specific to a repository.
<issue_comment>username_3: In general, this document doesn't make the distinction between /lgtm and /approve clear.

* /lgtm = tech approval
* /approve = writing approval
<issue_comment>username_3: Suggestion: Write this topic as if we're going to have the option to set `lgtmActsAsApprove` to `false`. That will keep the story clean for now. If we have to add the caveat about LGTM having two meanings, we can do that later.
<issue_comment>username_3: If you say pull request (PR), the usual convention is to say PR for all other instances in the document. In other words, once you have given the acronym, don't spell out the term any more.
<issue_comment>username_3: github -> GitHub
group -> team
tag -> label
SIG-DOCS -> SIG Docs (not sure about this one)
<issue_comment>username_3: In [test-infra Issue 6589](https://github.com/kubernetes/test-infra/issues/6589), there's a fair amount of resistance to our idea of using /lgtm for tech review and /approve for writer review. So we probably shouldn't put too much effort into clarifying these commands just yet.
<issue_comment>username_4: I'd expect that to harmonize with https://github.com/kubernetes/community/blob/master/community-membership.md#community-membership
<issue_comment>username_2: @username_3 With https://github.com/kubernetes/test-infra/pull/6851 in play, I think it's good to clarify `/lgtm` and `/approve`. 

@username_0 It would be great to merge this soon. How can I help?
<issue_comment>username_0: I am on other editing/writing duties today, but I'm hoping to tackle a rewrite of this tomorrow (Friday Feb16). I've made sure that maintainers can all update this branch, so if I loose track and don't make progress, feel free to update the branch directly, or snag and edit and put up an alternate PR and close this one.
<issue_comment>username_0: @username_1 @username_3 @username_2 update the PR with feedback, and I believe it's fairly ready to merge barring additional comments.

@username_4 made sure to explicitly talk to the membership requirements and linked to the relevant files in kubernetes/community

@bradtopol I thought about adding something on the whole purple ""Reviewable"" button that lurks and eats unwitting reviewers, but I don't have a recommendation other that ""OMG FLEE"" that's more personal opinion based than consensus, so I'm leaving that off this pass as a problem to tackle separately.
<issue_comment>username_0: @username_2 updated
<issue_comment>username_3: I don't think this document is ready to be merged yet.

* We need to agree on our convention for lgtm versus approve. After we have agreed on what our convention is, we need to make the convention clear in this document. My understanding is that we have a convention of lgtm=tech and approve=writing. (The more I think about it, I don't like that convention, because I think we will constantly have to explain it to people. I think we probably should have a couple new commands: lgtm-tech and lgtm-writing)

* We need to make the distinction that a members belongs to the Kubernetes organization, but reviewers and approvers belong to a particular repository. 

* Early in the topic, we need to give these definition:

    * A reviewer is someone who appears in the reviewers list in an OWNERS file or who appears in the reviewers list in the front matter of an individual topic.

    * An approver is someone who appears in the approvers list in an OWNERS file or who appears in the approvers list in the front matter of an individual topic.

* In the **Reviewers** section of the topic, there are too many statements about approvers. Those should be in the **Approvers** section.

* I don't want to go forward with the content that explains how lgtm sometimes acts as approve. I want to wait until we have hammered that out with Aaron and the other SIGs.

* We need to be more precise about what causes an automatic merge. I'm not sure I know what the rules are, but this is what I think the rules are:

    * The PR has an lgtm from someone in a reviewers list or someone in an approvers list.
    * The PR has an approve from someone in an approvers list.
    * The PR does not have a hold.

* The topic refers to ""the OWNERS file"". We need to make it clear that there are several OWNERS files and there are also approvers and reviewers lists in the front matter of individual topics.
<issue_comment>username_0: thanks @username_3  - I've re-organized the content a bit to address your feedback and make it more explicit about roles vs. approvers roles and intentions of those comments.

For what it's worth, I understand your request, but think that the combination of lgtm and approve comments that we've documented here is sufficient, and I'm not sure it's worth the effort to establish any more formal controls, which would generally mean someone writing a Prow plugin that would do the stuff you're specifically asking towards. My assessment was that consensus overall was that the informal process is sufficient, so barring any terrible grammar regressions, I think this PR is ready to go as documenting the current state of how we do business.

@username_2 I re-added the **Note:** about approver /lgtm, as the PR that Steve merged into the `infra-test` repo *did not* change that behavior (I validated that earlier this afternoon), so I thought it warranted calling out the special case. The PR that Steve merged does stop the ""automatically approved"" mechanism, but not the ""approver issuing /lgtm gets both tags"" thing.
<issue_comment>username_3: @username_0 OK, I'd say go ahead and remove the hold when you're ready.
<issue_comment>username_0: /hold cancel
<issue_comment>username_2: @username_0 Good choice—I just observed the same behavior. :+1:"
gohugoio/hugo,505408237,6412,,"[{'action': 'opened', 'author': 'bep', 'comment_id': None, 'datetime': '2019-10-10 17:27:25+00:00', 'masked_author': 'username_0', 'text': 'There is certainly a risk adding new top-level front matter keywords, but if we come up some distinctive enough ...\r\n\r\nGiven my naming suggestion in the title:\r\n\r\n* `nolist`:  The page will be rendered and will have a `.RelPermalink`, but will not show up in any of the page collections (`.RegularPages`). If you set this on sections, they will still be reachable via `.Parent` and similar.\r\n* `norender`: The page will not be rendered and will not have a `.RelPermalink`, but will show up in page collections.\r\n\r\nA page with both of the above set will behave like a `headless` bundle.\r\n\r\nBetter names for the above? /cc @username_1 @username_2 and gang.', 'title': 'Add nolist and norender', 'type': 'issue'}
 {'action': 'created', 'author': 'kaushalmodi', 'comment_id': 541044925.0, 'datetime': '2019-10-11 12:31:47+00:00', 'masked_author': 'username_1', 'text': 'I am a bit confused thinking of all options together.. will need to come up with a table that differentiates:\r\n\r\n1. draft = false (default)\r\n2. draft = true\r\n3. nolist\r\n4. norender\r\n\r\nIn what combinations can those 3 switches be used? We first need to spec that out. \r\n\r\nOnce that is clear, we can think of better names.\r\n\r\nMy first reaction is that we should not add 2 more switches, but just one switch with different possible values. That would disallow people from abusing these switches in random combinations.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'regisphilibert', 'comment_id': 541048982.0, 'datetime': '2019-10-11 12:44:58+00:00', 'masked_author': 'username_2', 'text': ""Has anybody has a use case for `nolist`?\r\n\r\nI can think of several, but for all of them, I would still need to grab those pages as a collection for some other use.\r\nEx:  using their data to build a graph, listing them in a different output format, render a list on another page which refers them etc...\r\nAnd if no collection can produce them, then you're better off using a headless bundle.\r\n\r\nMy take on this is, if you don't want pages to surface in your collection, you should content with applying the proper `where` clauses when needed.\r\n\r\nBut then again, some unforeseen use cases might enlighten me."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'mcdee', 'comment_id': 541051060.0, 'datetime': '2019-10-11 12:50:14+00:00', 'masked_author': 'username_3', 'text': 'These were discussed in #6316', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'regisphilibert', 'comment_id': 541053032.0, 'datetime': '2019-10-11 12:56:01+00:00', 'masked_author': 'username_2', 'text': 'Oh yes, just remember now. I made my point there already it seems :) I will reiterate though:\r\n\r\n`nolist` will prevent them from being found by Hugo outside of a `.GetPage` which exclude the possibility of finding them ""in batch"". \r\nTo mention @username_3\'s use case, even dynamically producing a list of ""private"" pages for the client\'s consumption will not impossible.\r\n\r\nSo I for one, will never be able to use `nolist`.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'bep', 'comment_id': 541098963.0, 'datetime': '2019-10-11 14:56:32+00:00', 'masked_author': 'username_0', 'text': 'I bet you want to use nolist+norender. Which would be similar to what a `headless` bundle (which I eventually will ""hide from the docs"", so to speak).\r\n\r\n* So, `draft` and the other ways to _not build_ pages (expiryDate etc.) tells Hugo _if_ it should be published.\r\n* These 2 new flags tells Hugo _how_ they should be published.\r\n\r\nSo while certainly related, I think it muddles the discussion to combine them ...\r\n\r\nI bring these to new flags into one discussion just because of that, some of the power comes from the combinations.\r\n\r\n* nolist+norender = ""headless page"", you can reach it from `.Site.GetPage` (and also the structural methods like `.Parent`), but they will have no `.RelPermalink`.\r\n* nolist:  Same as any page, but is hidden from any page collection, e.g. `RegularPages`.\r\n* norender: Will not be rendered on its own, and will not have `.RelPermalink` but can be reached from `.Site.GetPage` and is also listed in `RegularPages` etc.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'regisphilibert', 'comment_id': 541100312.0, 'datetime': '2019-10-11 14:59:56+00:00', 'masked_author': 'username_2', 'text': 'Nope. As I will not be able to build a collection with those content files contrary to the headless bundle where I can `{{\xa0range $headlessBundle.ResourcesByType ""page"" }}`', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'bep', 'comment_id': 573446730.0, 'datetime': '2020-01-12 19:07:42+00:00', 'masked_author': 'username_0', 'text': 'Revisiting this, I think I will add a third flag, but putting this into below `_build`, e.g.:\r\n\r\n```yaml\r\n_build:\r\n    list: true\r\n    render: true\r\n    publishResources: true\r\n```\r\n\r\nThe `headless` option will still work, but the above is obviously more flexible and will work for any page. A `headless` page can then also be configured as:\r\n\r\n```yaml\r\n_build:\r\n    list: false\r\n    render: false\r\n    publishResources: true\r\n```\r\n\r\n`publishResources` is mostly added here to get rid of lot of special source code for handling of the ""headless pages"", but I have seen many requesting it -- this is especially useful for sites with big image originals where you only use the resized variants.\r\n\r\n/cc @username_2 @username_1 and gang.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'regisphilibert', 'comment_id': 573455684.0, 'datetime': '2020-01-12 20:48:59+00:00', 'masked_author': 'username_2', 'text': 'I think the homepage\'s cascade is a good place to assign global Front Matter defaults. This enables users to globally assign any Front Matter value without having to add any new `keys` to the config file and the documentation that goes with it.\r\n\r\nI would add though, and sorry for taking this thread a wee bit astray:\r\nMy only reservation about this as a general rule is that currently the `cascade` settings are applied to the current page, and not only the pages below it. This mean such ""defaults"" in cascade often have to be overwritten from the origin ""content file"", especially when in the homepage.\r\n\r\nIf other agree with my statements about using the homepage\'s cascade to set defaults for everything ""front matter"". I\'ll create an issue to revert cascade applying to self.', 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'bep', 'comment_id': None, 'datetime': '2020-02-18 10:17:10+00:00', 'masked_author': 'username_0', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'closed', 'author': 'bep', 'comment_id': None, 'datetime': '2020-02-18 10:17:10+00:00', 'masked_author': 'username_0', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'created', 'author': 'tristan957', 'comment_id': 621017400.0, 'datetime': '2020-04-29 06:37:37+00:00', 'masked_author': 'username_4', 'text': 'Could someone point me to the documentation where this is talked about? I am struggling to find it. Searching for it on the docs site comes up empty. Would really like to publish unlisted content for peer review. I saw a way to do it in a discourse page, but that was 2 years before this implementation.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'regisphilibert', 'comment_id': 621170881.0, 'datetime': '2020-04-29 12:28:35+00:00', 'masked_author': 'username_2', 'text': 'look for Build Options', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'tristan957', 'comment_id': 621265413.0, 'datetime': '2020-04-29 14:56:23+00:00', 'masked_author': 'username_4', 'text': ""@username_2 you're a lifesaver"", 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Add nolist and norender
username_0: There is certainly a risk adding new top-level front matter keywords, but if we come up some distinctive enough ...

Given my naming suggestion in the title:

* `nolist`:  The page will be rendered and will have a `.RelPermalink`, but will not show up in any of the page collections (`.RegularPages`). If you set this on sections, they will still be reachable via `.Parent` and similar.
* `norender`: The page will not be rendered and will not have a `.RelPermalink`, but will show up in page collections.

A page with both of the above set will behave like a `headless` bundle.

Better names for the above? /cc @username_1 @username_2 and gang.
<issue_comment>username_1: I am a bit confused thinking of all options together.. will need to come up with a table that differentiates:

1. draft = false (default)
2. draft = true
3. nolist
4. norender

In what combinations can those 3 switches be used? We first need to spec that out. 

Once that is clear, we can think of better names.

My first reaction is that we should not add 2 more switches, but just one switch with different possible values. That would disallow people from abusing these switches in random combinations.
<issue_comment>username_2: Has anybody has a use case for `nolist`?

I can think of several, but for all of them, I would still need to grab those pages as a collection for some other use.
Ex:  using their data to build a graph, listing them in a different output format, render a list on another page which refers them etc...
And if no collection can produce them, then you're better off using a headless bundle.

My take on this is, if you don't want pages to surface in your collection, you should content with applying the proper `where` clauses when needed.

But then again, some unforeseen use cases might enlighten me.
<issue_comment>username_3: These were discussed in #6316
<issue_comment>username_2: Oh yes, just remember now. I made my point there already it seems :) I will reiterate though:

`nolist` will prevent them from being found by Hugo outside of a `.GetPage` which exclude the possibility of finding them ""in batch"". 
To mention @username_3's use case, even dynamically producing a list of ""private"" pages for the client's consumption will not impossible.

So I for one, will never be able to use `nolist`.
<issue_comment>username_0: I bet you want to use nolist+norender. Which would be similar to what a `headless` bundle (which I eventually will ""hide from the docs"", so to speak).

* So, `draft` and the other ways to _not build_ pages (expiryDate etc.) tells Hugo _if_ it should be published.
* These 2 new flags tells Hugo _how_ they should be published.

So while certainly related, I think it muddles the discussion to combine them ...

I bring these to new flags into one discussion just because of that, some of the power comes from the combinations.

* nolist+norender = ""headless page"", you can reach it from `.Site.GetPage` (and also the structural methods like `.Parent`), but they will have no `.RelPermalink`.
* nolist:  Same as any page, but is hidden from any page collection, e.g. `RegularPages`.
* norender: Will not be rendered on its own, and will not have `.RelPermalink` but can be reached from `.Site.GetPage` and is also listed in `RegularPages` etc.
<issue_comment>username_2: Nope. As I will not be able to build a collection with those content files contrary to the headless bundle where I can `{{ range $headlessBundle.ResourcesByType ""page"" }}`
<issue_comment>username_0: Revisiting this, I think I will add a third flag, but putting this into below `_build`, e.g.:

```yaml
_build:
    list: true
    render: true
    publishResources: true
```

The `headless` option will still work, but the above is obviously more flexible and will work for any page. A `headless` page can then also be configured as:

```yaml
_build:
    list: false
    render: false
    publishResources: true
```

`publishResources` is mostly added here to get rid of lot of special source code for handling of the ""headless pages"", but I have seen many requesting it -- this is especially useful for sites with big image originals where you only use the resized variants.

/cc @username_2 @username_1 and gang.
<issue_comment>username_2: I think the homepage's cascade is a good place to assign global Front Matter defaults. This enables users to globally assign any Front Matter value without having to add any new `keys` to the config file and the documentation that goes with it.

I would add though, and sorry for taking this thread a wee bit astray:
My only reservation about this as a general rule is that currently the `cascade` settings are applied to the current page, and not only the pages below it. This mean such ""defaults"" in cascade often have to be overwritten from the origin ""content file"", especially when in the homepage.

If other agree with my statements about using the homepage's cascade to set defaults for everything ""front matter"". I'll create an issue to revert cascade applying to self.<issue_closed><issue_closed>
<issue_comment>username_4: Could someone point me to the documentation where this is talked about? I am struggling to find it. Searching for it on the docs site comes up empty. Would really like to publish unlisted content for peer review. I saw a way to do it in a discourse page, but that was 2 years before this implementation.
<issue_comment>username_2: look for Build Options
<issue_comment>username_4: @username_2 you're a lifesaver"
gohugoio/hugo,803972205,8219,,"[{'action': 'opened', 'author': 'hacdias', 'comment_id': None, 'datetime': '2021-02-08 21:12:41+00:00', 'masked_author': 'username_0', 'text': '### What version of Hugo are you using (`hugo version`)?\r\n\r\n<pre>\r\n$ hugo version\r\nHugo Static Site\r\n Generator v0.80.0/extended darwin/amd64 BuildDate: unknown\r\n</pre>\r\n\r\n### Does this issue reproduce with the latest release?\r\n\r\nYes.\r\n\r\n---\r\n\r\nThe YAML frontmatter is not being correctly parsed. When there are "" (quotes) in a string, it fails with:\r\n\r\n```\r\nERROR 2021/02/08 22:06:53 JSON parse error: expected comma character or an array or object ending on line 22 and column 822\r\n   22: ...ashboard and saw a ""Web Hooks"" button, wh...\r\n\r\n```\r\n\r\nThe YAML is below:\r\n\r\n```\r\n---\r\naliases:\r\n- /replies/2020/02/29/1/\r\ndate: ""2020-02-29T22:19:56.901Z""\r\nreplyTo:\r\n  url: https://www.jvt.me/posts/2020/01/12/webmention-notifications/\r\n  content: \'Since I set up Webmentions in January 2018 using Webmention.io, I\'\'ve\r\n    been starting to receive more interactions with my site across the social web.However,\r\n    up until today, the only way I\'\'d be able to see what Webmentions I\'\'d received\r\n    was to go and actively check. I\'\'d, many times a day, open Indigenous for Android,\r\n    the Indie reader I use, and refresh it to look at what\'\'s in my notifications.This\r\n    isn\'\'t quite as interactive as you\'\'d want, especially as these could be used\r\n    for near-realtime communication across websites. While thinking about it, I started\r\n    looking through the documentation for Webmention.io, but found no mention of it.\r\n    Failing that, I logged into the dashboard and saw a ""Web Hooks"" button, which\r\n    was exactly what I wanted!This Webhook hits the newly created https://www-api.jvt.me/notifications/webmention\r\n    endpoint with a shared secret (to prevent spam) and then sends a push notification\r\n    via PushBullet, which I currently use to notify me when my site has deployed.You\r\n    can see the code changes required on the Merge Request on GitLab.com: Add webhook\r\n    for mapping Webmention.io to push notifications.Update 2020-01-28: Since finding\r\n    out I can only send 100 messages a month with Pushbullet, I have since replaced\r\n    it with Pushover, after getting some good recommendations for it. You can see\r\n    the code changes required to add Pushover Merge Request on GitLab.com: Use Pushover\r\n    for Webmention notifications.\'\r\n  date: 2020-01-12T18:21:43Z\r\n  author:\r\n    name: Jamie Tanna\r\n    url: https://www.jvt.me\r\n    photo: https://www.jvt.me/img/profile.png\r\ntags:\r\n- telegram\r\n- notifications\r\n- webmentions\r\n---\r\n\r\nThat\'s a lovely idea. I\'m personally using Telegram\'s [Bot API](https://telegram.org/blog/bot-revolution) which is quite powerful!\r\n```\r\n\r\nThe YAML is produced by the exact same library Hugo uses (https://github.com/go-yaml/yaml) and it is valid as per http://www.yamllint.com/.\r\n\r\nHope it helps and that it gets solved soon!', 'title': 'Error parsing YAML frontmatter with quotes', 'type': 'issue'}
 {'action': 'created', 'author': 'moorereason', 'comment_id': 775493290.0, 'datetime': '2021-02-08 22:03:16+00:00', 'masked_author': 'username_1', 'text': 'Where does JSON come into the picture?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'hacdias', 'comment_id': 775700661.0, 'datetime': '2021-02-09 06:20:48+00:00', 'masked_author': 'username_0', 'text': ""@username_1 very interesting question indeed! I don't think it's related to my templates, as it does not mention anything from my templates."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'hacdias', 'comment_id': 775702119.0, 'datetime': '2021-02-09 06:23:53+00:00', 'masked_author': 'username_0', 'text': 'Nevermind. It was actually related to my templates. However, I think it would be better if the error said so from the beginning. Thanks!', 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'hacdias', 'comment_id': None, 'datetime': '2021-02-09 06:23:53+00:00', 'masked_author': 'username_0', 'text': '', 'title': None, 'type': 'issue'}]","<issue_start><issue_comment>Title: Error parsing YAML frontmatter with quotes
username_0: ### What version of Hugo are you using (`hugo version`)?

<pre>
$ hugo version
Hugo Static Site
 Generator v0.80.0/extended darwin/amd64 BuildDate: unknown
</pre>

### Does this issue reproduce with the latest release?

Yes.

---

The YAML frontmatter is not being correctly parsed. When there are "" (quotes) in a string, it fails with:

```
ERROR 2021/02/08 22:06:53 JSON parse error: expected comma character or an array or object ending on line 22 and column 822
   22: ...ashboard and saw a ""Web Hooks"" button, wh...

```

The YAML is below:

```
---
aliases:
- /replies/2020/02/29/1/
date: ""2020-02-29T22:19:56.901Z""
replyTo:
  url: https://www.jvt.me/posts/2020/01/12/webmention-notifications/
  content: 'Since I set up Webmentions in January 2018 using Webmention.io, I''ve
    been starting to receive more interactions with my site across the social web.However,
    up until today, the only way I''d be able to see what Webmentions I''d received
    was to go and actively check. I''d, many times a day, open Indigenous for Android,
    the Indie reader I use, and refresh it to look at what''s in my notifications.This
    isn''t quite as interactive as you''d want, especially as these could be used
    for near-realtime communication across websites. While thinking about it, I started
    looking through the documentation for Webmention.io, but found no mention of it.
    Failing that, I logged into the dashboard and saw a ""Web Hooks"" button, which
    was exactly what I wanted!This Webhook hits the newly created https://www-api.jvt.me/notifications/webmention
    endpoint with a shared secret (to prevent spam) and then sends a push notification
    via PushBullet, which I currently use to notify me when my site has deployed.You
    can see the code changes required on the Merge Request on GitLab.com: Add webhook
    for mapping Webmention.io to push notifications.Update 2020-01-28: Since finding
    out I can only send 100 messages a month with Pushbullet, I have since replaced
    it with Pushover, after getting some good recommendations for it. You can see
    the code changes required to add Pushover Merge Request on GitLab.com: Use Pushover
    for Webmention notifications.'
  date: 2020-01-12T18:21:43Z
  author:
    name: Jamie Tanna
    url: https://www.jvt.me
    photo: https://www.jvt.me/img/profile.png
tags:
- telegram
- notifications
- webmentions
---

That's a lovely idea. I'm personally using Telegram's [Bot API](https://telegram.org/blog/bot-revolution) which is quite powerful!
```

The YAML is produced by the exact same library Hugo uses (https://github.com/go-yaml/yaml) and it is valid as per http://www.yamllint.com/.

Hope it helps and that it gets solved soon!
<issue_comment>username_1: Where does JSON come into the picture?
<issue_comment>username_0: @username_1 very interesting question indeed! I don't think it's related to my templates, as it does not mention anything from my templates.
<issue_comment>username_0: Nevermind. It was actually related to my templates. However, I think it would be better if the error said so from the beginning. Thanks!<issue_closed>"
gohugoio/hugo,287069603,4243,,"[{'action': 'opened', 'author': 'bep', 'comment_id': None, 'datetime': '2018-01-09 12:18:52+00:00', 'masked_author': 'username_0', 'text': 'This is a discussion. Thinking out loud.\r\n\r\nWith the Chroma for highlighting and the image processing added in `0.32` you have an almost complete super-fast web dev environment.\r\n\r\nBut there is one other common task that forces people to use Gulp and friends (there are of course other requirements, too, but this is the most common); to compile your CSS. With Bootstrap 4 I guess the most common one is SASS.\r\n\r\nThere is no SASS compiler in native Go, and I suspect that it will take a decade before that happens.\r\nBut there is one in C/C++ with many language wrappers:\r\n\r\nhttps://github.com/wellington/go-libsass\r\n\r\nThis will, sadly, complicate the build setup. But it is doable, the question is: Is it worth it?\r\n\r\nHow to integrate this is not important for this discussion. I\'m not envisioning any ""asset pipeline"" for this ... Maybe we could just add `SASS´ as a new resource type:\r\n\r\n```html\r\n{{ .Resources.ByType(""sass"").ConvertTo(""css"").RelPermalink }} \r\n```\r\n\r\nOr something.\r\n\r\nThoughts?\r\n\r\n/cc @spf13', 'title': 'Add SASS support', 'type': 'issue'}
 {'action': 'created', 'author': 'RealOrangeOne', 'comment_id': 356278745.0, 'datetime': '2018-01-09 13:06:45+00:00', 'masked_author': 'username_1', 'text': 'Assuming the resources were able to sit in the `static/` rather than in `content/`. This sounds like a great idea. \r\n\r\nI can\'t see this adding any additional _runtime_ dependencies (Go should statically link the `libsass` library at compile time?). Build dependencies arent a massive issue, as installing libraries like `libsass` is often very easy. It might also be possible to only require `libsass` to be linked if youre calling `.ConvertTo ""css"" (very possible I believe).\r\n\r\nAgreed this should be considered after plugins, as if plugins are decided as a good course of action, I think something this shouldn\'t be in Hugo core.\r\n\r\n`</TwoCents>`', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'Jos512', 'comment_id': 356347044.0, 'datetime': '2018-01-09 17:00:46+00:00', 'masked_author': 'username_2', 'text': ""Without an asset pipeline, I doubt adding SASS support is worth the work. That is, I think that most people using SASS also perform other front-end tooling tasks. So they can port one task to Hugo (SASS), but use their toolchain for the others.\r\n\r\n(This is not me saying it's a bad idea. I just respond to the question of 'is it worth it?', which from my personal perspective I doubt. Is perhaps a poll on the Discourse forum an option to estimate the interest? I'm of course responding from my biased perspective.)"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'RealOrangeOne', 'comment_id': 356359046.0, 'datetime': '2018-01-09 17:42:01+00:00', 'masked_author': 'username_1', 'text': ""@username_2 I hadn't thought about other build lines (even though I use them myself -_- ). I think the plugin interface would solve this though? Plugins could then be created to support the different files."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'rdwatters', 'comment_id': 356383254.0, 'datetime': '2018-01-09 19:09:12+00:00', 'masked_author': 'username_3', 'text': 'I don’t think it’s worth it since SASS is most commonly one step in frontend builds along with JS. \r\n\r\nI like the clean separation between Hugo with *content* (HTML, MD, JSON, images, any other text File, etc) and users picking whatever toolchain they want for *presentation* and *behavior*. Most Jekyll users I have talked to (Jekyll ships with SASS and Coffeescript support, I believe) don’t use the built-in asset pipeline, but this isn’t a data-based comment and might have to do with the Ruby implementations being slow. \r\n\r\nI think the JS world here (Webpack CS vs Gulp, PostCSS vs SASS, etc) is really difficult to keep up with. \r\n\r\ncc/ @budparr', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'biodranik', 'comment_id': 356651120.0, 'datetime': '2018-01-10 16:13:26+00:00', 'masked_author': 'username_4', 'text': '1. Supporting SASS is a good idea, almost everyone uses it.\r\n2. Is go-libsass well supported? SASS is actively developing, and it would be sad to stick with an outdated implementation.\r\n3. Plugins are the way to go. And it should be very easy in the basic implementation: just provide an easy way for authors to call any pre- and post-processing external tools they want. And disable it by-default for themes for security.\r\n4. Some of the tools should be run on a file change (e.g. SASS, autoprefixer, etc.), and it would be great to expose `hugo server` watch functionality to external tools, by simply binding a custom command line to modifications of specific files. This solution is not a fully flexible plugin, but it solves the most painful issues during development. Build-time functionality can be solved now by a custom shell/cmd script.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'devjack', 'comment_id': 357846119.0, 'datetime': '2018-01-16 03:43:48+00:00', 'masked_author': 'username_5', 'text': 'Hugo is, for me, a fantastic generation tool that plays an important part in my publishing pipeline. I use it in combination with webpack/gulp/sass etc. to produce sites. My gut tells me documentation/examples/ecosystem around combined tooling is more beneficial than replicating existing community functionality in hugo.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'fbnlsr', 'comment_id': 357914261.0, 'datetime': '2018-01-16 10:14:19+00:00', 'masked_author': 'username_6', 'text': 'SASS support would be a great addition to Hugo. I agree with @username_5 though, focus should be on documentation and ecosystem, as it\'s rather simple to set up a Webpack / Gulp tooling when working with Hugo. Especially when considering the first post stating that even if it\'s doable, it\'s something that would be hard to implement and complicate the build setup.\r\n\r\nOne thing that could be more beneficial though is a hook system to trigger commands before and after building. At the moment I\'m using NPM tasks to run my build/serve/watch tasks, which look like this:\r\n\r\n```json\r\n""scripts"": {\r\n    ""build"": ""webpack && hugo"",\r\n    ""serve"": ""webpack && hugo serve"",\r\n    ""watch"": ""parallelshell \'hugo serve\' \'webpack --watch\'""\r\n  }\r\n```\r\nA simple built-in hook system in Hugo could help users set up a more streamlined development environment and be more flexible imho. It\'d also help reduce the number of dependencies needed.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'biodranik', 'comment_id': 357922299.0, 'datetime': '2018-01-16 10:45:38+00:00', 'masked_author': 'username_4', 'text': ""It would be great to reuse hugo's *watch* functionality and add custom hooks on file changes for more flexibility. In this case it would be very easy to call any external script/tool/sass/webpack/anything to preprocess files.\r\n\r\nThere is no any easy/cross-platform/no-filesystem-polling solution available, and golang portability can solve it."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'andi1984', 'comment_id': 358792872.0, 'datetime': '2018-01-18 21:49:16+00:00', 'masked_author': 'username_7', 'text': ""@username_0 I'm with @username_5 opinion: static assets like images, audio, video etc. is in general fine for me when Hugo optimizes them. But I think it is not worth effort trying to build something others already do. I'm using Sass and Gulp myself. But might be that in few months it will be grunt, postcss or whatever else is out there.\r\n\r\nI think Hugo should not care about that."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'nfisher', 'comment_id': 359867230.0, 'datetime': '2018-01-23 17:28:53+00:00', 'masked_author': 'username_8', 'text': '@username_0 I think I could probably add some rudimentary SASS capabilities with PR #4278.\r\n\r\n`{{ sass OUTFILE, INFILE }}`\r\n\r\nThe main bit I need to figure out is the best way to hook into memory server/http handler. Which I need to do anyway for that PR.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'comaldave', 'comment_id': 389039207.0, 'datetime': '2018-05-15 04:29:13+00:00', 'masked_author': 'username_9', 'text': '', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'fbnlsr', 'comment_id': 389096985.0, 'datetime': '2018-05-15 09:05:04+00:00', 'masked_author': 'username_6', 'text': ""Same here. I ended up using Webpack as well. I've got an npm script which launches webpack and hugo in parallel with the watch flag and it's working like a charm.\r\n\r\nYou can see it here: https://github.com/username_6/primative.net"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'xzyfer', 'comment_id': 397642067.0, 'datetime': '2018-06-15 14:36:52+00:00', 'masked_author': 'username_10', 'text': 'LibSass maintainer here 👋 happy to help out or answer any questions', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jhabdas', 'comment_id': 399362887.0, 'datetime': '2018-06-22 08:21:28+00:00', 'masked_author': 'username_11', 'text': ""@username_10 I noticed Discourse is using Sass. Do you know offhand if they're using LibSass or Rust?"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jhabdas', 'comment_id': 399459205.0, 'datetime': '2018-06-22 14:21:52+00:00', 'masked_author': 'username_11', 'text': ""Thanks for the info. And I apologize for getting my four-letter languages mixed up. I actually meant DART and not Rust. The reason I asked is because the [Ruby implementation](https://github.com/sass/ruby-sass) is now deprecated (tentatively) and I see the [Dart implementation ](https://github.com/sass/dart-sass) picking up a lot of steam.\r\n\r\nI'm actually quite thrilled to see the move to Dart as it may breathe new life into Sass and, as a result, lead Discourse to start porting away from the Ruby implementation to either LibSass or DartSass."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jhabdas', 'comment_id': 399462413.0, 'datetime': '2018-06-22 14:30:52+00:00', 'masked_author': 'username_11', 'text': ""@username_3 I want to play Devil's advocate and just suggest one of the best parts of Hugo is the opinion which comes along with it. Sass may not have the newest, shiniest stuff but it's been battle tested by 10,000 angry Ruby developers, is also the language being used in Discourse 2 and intuition tells me it's going to see renewed interest soon as a result of a) the Dart implementation which is seeing some heavy development right now and b) [JavaScript developer frustration](https://medium.com/@username_11/webpack-is-your-achilles-heel-d3cd80821a4f).\r\n\r\nThat said, there is such a thing as too much opinion but having the ability to use a preprocessor like Sass to Hugo would add quite a bit of power and allow Hugo to slurp up a lot more Jekyll sites."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'bep', 'comment_id': 399467980.0, 'datetime': '2018-06-22 14:47:27+00:00', 'masked_author': 'username_0', 'text': ""@username_11 is right; this is an opinionated choice, but it's very useful to a bunch of people (me included), and even if is opinionated it is also really the only choice we could make if we wanted to add a fast CSS preprocessor in Hugo.\r\n\r\nI have said it before, but I will say this again: I'm willing to give away lots of flexibility and modern buzz word components in my workflow I that means that I can use `hugo` for all of it."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'jhabdas', 'comment_id': 399473893.0, 'datetime': '2018-06-22 15:05:33+00:00', 'masked_author': 'username_11', 'text': 'sorry couldn\'t help it ^^\r\n<img width=""263"" alt=""screen shot 2018-06-22 at 11 04 32 pm"" src=""https://user-images.githubusercontent.com/440298/41783928-b8ea976c-7670-11e8-8690-8f9d9d8750e6.png"">\r\n\r\nthis message will self-destruct in 30 seconds…', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'bep', 'comment_id': 401048381.0, 'datetime': '2018-06-28 14:10:46+00:00', 'masked_author': 'username_0', 'text': '@username_10 are these WARNINGs familiar?\r\n\r\n```bash\r\n# github.com/gohugoio/hugo/vendor/github.com/wellington/go-libsass/libs\r\nIn file included from cencode.c:2:\r\n../vendor/github.com/wellington/go-libsass/libs/../libsass-build/cencode.c:50:5: warning: declaration does not declare anything [-Wmissing-declarations]\r\n../vendor/github.com/wellington/go-libsass/libs/../libsass-build/cencode.c:64:5: warning: declaration does not declare anything [-Wmissing-declarations]\r\n```\r\n\r\nI assume ""no harm"", but they are annoying to get every time I build. Know any magic flag I can set to turn these warnings off?', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'xzyfer', 'comment_id': 401216457.0, 'datetime': '2018-06-29 00:58:30+00:00', 'masked_author': 'username_10', 'text': ""I don't but I can take a look. A bunch of compiler warning were introduced in a recent major refactor I wasn't involved in. Safe to ignore these for now but we'll continue to address these as time permits."", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'bep', 'comment_id': 403000975.0, 'datetime': '2018-07-06 10:54:46+00:00', 'masked_author': 'username_0', 'text': 'FIxed in dea71670c059ab4d5a42bd22503f18c087dd22d4', 'title': None, 'type': 'comment'}
 {'action': 'closed', 'author': 'bep', 'comment_id': None, 'datetime': '2018-07-06 10:54:46+00:00', 'masked_author': 'username_0', 'text': '', 'title': None, 'type': 'issue'}
 {'action': 'created', 'author': 'xzyfer', 'comment_id': 403001417.0, 'datetime': '2018-07-06 10:57:03+00:00', 'masked_author': 'username_10', 'text': ':tada:', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Add SASS support
username_0: This is a discussion. Thinking out loud.

With the Chroma for highlighting and the image processing added in `0.32` you have an almost complete super-fast web dev environment.

But there is one other common task that forces people to use Gulp and friends (there are of course other requirements, too, but this is the most common); to compile your CSS. With Bootstrap 4 I guess the most common one is SASS.

There is no SASS compiler in native Go, and I suspect that it will take a decade before that happens.
But there is one in C/C++ with many language wrappers:

https://github.com/wellington/go-libsass

This will, sadly, complicate the build setup. But it is doable, the question is: Is it worth it?

How to integrate this is not important for this discussion. I'm not envisioning any ""asset pipeline"" for this ... Maybe we could just add `SASS´ as a new resource type:

```html
{{ .Resources.ByType(""sass"").ConvertTo(""css"").RelPermalink }} 
```

Or something.

Thoughts?

/cc @spf13
<issue_comment>username_1: Assuming the resources were able to sit in the `static/` rather than in `content/`. This sounds like a great idea. 

I can't see this adding any additional _runtime_ dependencies (Go should statically link the `libsass` library at compile time?). Build dependencies arent a massive issue, as installing libraries like `libsass` is often very easy. It might also be possible to only require `libsass` to be linked if youre calling `.ConvertTo ""css"" (very possible I believe).

Agreed this should be considered after plugins, as if plugins are decided as a good course of action, I think something this shouldn't be in Hugo core.

`</TwoCents>`
<issue_comment>username_2: Without an asset pipeline, I doubt adding SASS support is worth the work. That is, I think that most people using SASS also perform other front-end tooling tasks. So they can port one task to Hugo (SASS), but use their toolchain for the others.

(This is not me saying it's a bad idea. I just respond to the question of 'is it worth it?', which from my personal perspective I doubt. Is perhaps a poll on the Discourse forum an option to estimate the interest? I'm of course responding from my biased perspective.)
<issue_comment>username_1: @username_2 I hadn't thought about other build lines (even though I use them myself -_- ). I think the plugin interface would solve this though? Plugins could then be created to support the different files.
<issue_comment>username_3: I don’t think it’s worth it since SASS is most commonly one step in frontend builds along with JS. 

I like the clean separation between Hugo with *content* (HTML, MD, JSON, images, any other text File, etc) and users picking whatever toolchain they want for *presentation* and *behavior*. Most Jekyll users I have talked to (Jekyll ships with SASS and Coffeescript support, I believe) don’t use the built-in asset pipeline, but this isn’t a data-based comment and might have to do with the Ruby implementations being slow. 

I think the JS world here (Webpack CS vs Gulp, PostCSS vs SASS, etc) is really difficult to keep up with. 

cc/ @budparr
<issue_comment>username_4: 1. Supporting SASS is a good idea, almost everyone uses it.
2. Is go-libsass well supported? SASS is actively developing, and it would be sad to stick with an outdated implementation.
3. Plugins are the way to go. And it should be very easy in the basic implementation: just provide an easy way for authors to call any pre- and post-processing external tools they want. And disable it by-default for themes for security.
4. Some of the tools should be run on a file change (e.g. SASS, autoprefixer, etc.), and it would be great to expose `hugo server` watch functionality to external tools, by simply binding a custom command line to modifications of specific files. This solution is not a fully flexible plugin, but it solves the most painful issues during development. Build-time functionality can be solved now by a custom shell/cmd script.
<issue_comment>username_5: Hugo is, for me, a fantastic generation tool that plays an important part in my publishing pipeline. I use it in combination with webpack/gulp/sass etc. to produce sites. My gut tells me documentation/examples/ecosystem around combined tooling is more beneficial than replicating existing community functionality in hugo.
<issue_comment>username_6: SASS support would be a great addition to Hugo. I agree with @username_5 though, focus should be on documentation and ecosystem, as it's rather simple to set up a Webpack / Gulp tooling when working with Hugo. Especially when considering the first post stating that even if it's doable, it's something that would be hard to implement and complicate the build setup.

One thing that could be more beneficial though is a hook system to trigger commands before and after building. At the moment I'm using NPM tasks to run my build/serve/watch tasks, which look like this:

```json
""scripts"": {
    ""build"": ""webpack && hugo"",
    ""serve"": ""webpack && hugo serve"",
    ""watch"": ""parallelshell 'hugo serve' 'webpack --watch'""
  }
```
A simple built-in hook system in Hugo could help users set up a more streamlined development environment and be more flexible imho. It'd also help reduce the number of dependencies needed.
<issue_comment>username_4: It would be great to reuse hugo's *watch* functionality and add custom hooks on file changes for more flexibility. In this case it would be very easy to call any external script/tool/sass/webpack/anything to preprocess files.

There is no any easy/cross-platform/no-filesystem-polling solution available, and golang portability can solve it.
<issue_comment>username_7: @username_0 I'm with @username_5 opinion: static assets like images, audio, video etc. is in general fine for me when Hugo optimizes them. But I think it is not worth effort trying to build something others already do. I'm using Sass and Gulp myself. But might be that in few months it will be grunt, postcss or whatever else is out there.

I think Hugo should not care about that.
<issue_comment>username_8: @username_0 I think I could probably add some rudimentary SASS capabilities with PR #4278.

`{{ sass OUTFILE, INFILE }}`

The main bit I need to figure out is the best way to hook into memory server/http handler. Which I need to do anyway for that PR.
<issue_comment>username_6: Same here. I ended up using Webpack as well. I've got an npm script which launches webpack and hugo in parallel with the watch flag and it's working like a charm.

You can see it here: https://github.com/username_6/primative.net
<issue_comment>username_10: LibSass maintainer here 👋 happy to help out or answer any questions
<issue_comment>username_11: @username_10 I noticed Discourse is using Sass. Do you know offhand if they're using LibSass or Rust?
<issue_comment>username_11: Thanks for the info. And I apologize for getting my four-letter languages mixed up. I actually meant DART and not Rust. The reason I asked is because the [Ruby implementation](https://github.com/sass/ruby-sass) is now deprecated (tentatively) and I see the [Dart implementation ](https://github.com/sass/dart-sass) picking up a lot of steam.

I'm actually quite thrilled to see the move to Dart as it may breathe new life into Sass and, as a result, lead Discourse to start porting away from the Ruby implementation to either LibSass or DartSass.
<issue_comment>username_11: @username_3 I want to play Devil's advocate and just suggest one of the best parts of Hugo is the opinion which comes along with it. Sass may not have the newest, shiniest stuff but it's been battle tested by 10,000 angry Ruby developers, is also the language being used in Discourse 2 and intuition tells me it's going to see renewed interest soon as a result of a) the Dart implementation which is seeing some heavy development right now and b) [JavaScript developer frustration](https://medium.com/@username_11/webpack-is-your-achilles-heel-d3cd80821a4f).

That said, there is such a thing as too much opinion but having the ability to use a preprocessor like Sass to Hugo would add quite a bit of power and allow Hugo to slurp up a lot more Jekyll sites.
<issue_comment>username_0: @username_11 is right; this is an opinionated choice, but it's very useful to a bunch of people (me included), and even if is opinionated it is also really the only choice we could make if we wanted to add a fast CSS preprocessor in Hugo.

I have said it before, but I will say this again: I'm willing to give away lots of flexibility and modern buzz word components in my workflow I that means that I can use `hugo` for all of it.
<issue_comment>username_11: sorry couldn't help it ^^
<img width=""263"" alt=""screen shot 2018-06-22 at 11 04 32 pm"" src=""https://user-images.githubusercontent.com/440298/41783928-b8ea976c-7670-11e8-8690-8f9d9d8750e6.png"">

this message will self-destruct in 30 seconds…
<issue_comment>username_0: @username_10 are these WARNINGs familiar?

```bash
# github.com/gohugoio/hugo/vendor/github.com/wellington/go-libsass/libs
In file included from cencode.c:2:
../vendor/github.com/wellington/go-libsass/libs/../libsass-build/cencode.c:50:5: warning: declaration does not declare anything [-Wmissing-declarations]
../vendor/github.com/wellington/go-libsass/libs/../libsass-build/cencode.c:64:5: warning: declaration does not declare anything [-Wmissing-declarations]
```

I assume ""no harm"", but they are annoying to get every time I build. Know any magic flag I can set to turn these warnings off?
<issue_comment>username_10: I don't but I can take a look. A bunch of compiler warning were introduced in a recent major refactor I wasn't involved in. Safe to ignore these for now but we'll continue to address these as time permits.
<issue_comment>username_0: FIxed in dea71670c059ab4d5a42bd22503f18c087dd22d4<issue_closed>
<issue_comment>username_10: :tada:"
cdnjs/new-website,51192116,21,"{'number': 21.0, 'repo': 'new-website', 'user_login': 'cdnjs'}","[{'action': 'opened', 'author': 'redox', 'comment_id': None, 'datetime': '2014-12-06T18:52:11Z', 'masked_author': 'username_0', 'text': ""Hey guys/@username_1,\r\n\r\nFollowing up on https://github.com/cdnjs/cdnjs/pull/4078#issuecomment-65888765, I've added an Algolia-powered searchbar to the cdnjs.com website. Let me know if you like it!\r\n\r\n![realtime search](http://g.recordit.co/ouGcK8wrxZ.gif)\r\n\r\nPS: I'll then share with you the Algolia.com credentials + add some [DSN](http://www.algolia.com/dsn) locations."", 'title': 'Algolia-powered realtime search', 'type': 'issue'}
 {'action': 'created', 'author': 'PeterDaveHello', 'comment_id': 219201673.0, 'datetime': '2016-05-14 05:22:07+00:00', 'masked_author': 'username_1', 'text': 'Hello @username_0 , is it possible that give us an account to view the analytics on algolia? Thank you :smile:', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'thomasdavis', 'comment_id': 219201863.0, 'datetime': '2016-05-14 05:27:11+00:00', 'masked_author': 'username_2', 'text': '@username_1 I have the account creds, checking now to see if I can share', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'PeterDaveHello', 'comment_id': 219201874.0, 'datetime': '2016-05-14 05:27:31+00:00', 'masked_author': 'username_1', 'text': '@username_2 Oh nice!', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'thomasdavis', 'comment_id': 219201963.0, 'datetime': '2016-05-14 05:30:10+00:00', 'masked_author': 'username_2', 'text': '@username_1 emailed', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'PeterDaveHello', 'comment_id': 219201973.0, 'datetime': '2016-05-14 05:30:30+00:00', 'masked_author': 'username_1', 'text': '@username_2 Thanks, let me check it now.', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'redox', 'comment_id': 219206105.0, 'datetime': '2016-05-14 07:33:55+00:00', 'masked_author': 'username_0', 'text': ""I've just added more days of Analytics retention to your plan (was 1 day only), analytics will look better in a few days because based on more queries 👍"", 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'thomasdavis', 'comment_id': 219206229.0, 'datetime': '2016-05-14 07:37:40+00:00', 'masked_author': 'username_2', 'text': '@username_0 gods work!', 'title': None, 'type': 'comment'}
 {'action': 'created', 'author': 'PeterDaveHello', 'comment_id': 219207364.0, 'datetime': '2016-05-14 08:06:47+00:00', 'masked_author': 'username_1', 'text': '@username_0 Thanks 😄', 'title': None, 'type': 'comment'}]","<issue_start><issue_comment>Title: Algolia-powered realtime search
username_0: Hey guys/@username_1,

Following up on https://github.com/cdnjs/cdnjs/pull/4078#issuecomment-65888765, I've added an Algolia-powered searchbar to the cdnjs.com website. Let me know if you like it!

![realtime search](http://g.recordit.co/ouGcK8wrxZ.gif)

PS: I'll then share with you the Algolia.com credentials + add some [DSN](http://www.algolia.com/dsn) locations.
<issue_comment>username_1: Hello @username_0 , is it possible that give us an account to view the analytics on algolia? Thank you :smile:
<issue_comment>username_2: @username_1 I have the account creds, checking now to see if I can share
<issue_comment>username_1: @username_2 Oh nice!
<issue_comment>username_2: @username_1 emailed
<issue_comment>username_1: @username_2 Thanks, let me check it now.
<issue_comment>username_0: I've just added more days of Analytics retention to your plan (was 1 day only), analytics will look better in a few days because based on more queries 👍
<issue_comment>username_2: @username_0 gods work!
<issue_comment>username_1: @username_0 Thanks 😄"
